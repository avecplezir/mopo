Can't load '/usr/local/software/slurm/slurm-20.11.9-rhel8/lib64/perl5/auto/Slurm/Slurm.so' for module Slurm: libperl.so.5.26: cannot open shared object file: No such file or directory at /usr/lib64/perl5/DynaLoader.pm line 190, <DATA> line 602.
 at /usr/local/software/slurm/current-rhel8/bin/generate_pbs_nodefile line 18.
Compilation failed in require at /usr/local/software/slurm/current-rhel8/bin/generate_pbs_nodefile line 18, <DATA> line 602.
BEGIN failed--compilation aborted at /usr/local/software/slurm/current-rhel8/bin/generate_pbs_nodefile line 18, <DATA> line 602.
WARNING: Logging before flag parsing goes to stderr.
W0519 08:53:19.653723 47606115558272 lazy_loader.py:50] 
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

Warning: Flow failed to import. Set the environment variable D4RL_SUPPRESS_IMPORT_ERROR=1 to suppress this message.
No module named 'flow'
Warning: CARLA failed to import. Set the environment variable D4RL_SUPPRESS_IMPORT_ERROR=1 to suppress this message.
No module named 'carla'
2022-05-19 08:53:22,053	INFO node.py:498 -- Process STDOUT and STDERR is being redirected to /tmp/ray/session_2022-05-19_08-53-22_052899_9196/logs.
2022-05-19 08:53:22,161	INFO services.py:409 -- Waiting for redis server at 127.0.0.1:41099 to respond...
2022-05-19 08:53:22,273	INFO services.py:409 -- Waiting for redis server at 127.0.0.1:29356 to respond...
2022-05-19 08:53:22,274	INFO services.py:806 -- Starting Redis shard with 10.0 GB max memory.
2022-05-19 08:53:22,293	INFO node.py:512 -- Process STDOUT and STDERR is being redirected to /tmp/ray/session_2022-05-19_08-53-22_052899_9196/logs.
2022-05-19 08:53:22,294	WARNING services.py:1294 -- Warning: Capping object memory store to 20.0GB. To increase this further, specify `object_store_memory` when calling ray.init() or ray start.
2022-05-19 08:53:22,294	INFO services.py:1442 -- Starting the Plasma object store with 20.0 GB memory using /dev/shm.
2022-05-19 08:53:22,464	INFO tune.py:65 -- Did not find checkpoint file in ./ray_mopo/halfcheetah/halfcheetah_medium_replay_local_101e3.
2022-05-19 08:53:22,465	INFO tune.py:232 -- Starting a new experiment.
W0519 08:53:22.534234 47606115558272 deprecation_wrapper.py:119] From /rds/user/ajc348/hpc-work/mopo/.env/lib/python3.6/site-packages/ray/tune/logger.py:131: The name tf.VERSION is deprecated. Please use tf.version.VERSION instead.

W0519 08:53:22.534610 47606115558272 deprecation_wrapper.py:119] From /rds/user/ajc348/hpc-work/mopo/.env/lib/python3.6/site-packages/ray/tune/logger.py:136: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.

2022-05-19 08:53:22,586	WARNING util.py:64 -- The `start_trial` operation took 0.10528063774108887 seconds to complete, which may be a performance bottleneck.
W0519 09:01:24.923490 47606115558272 deprecation_wrapper.py:119] From /rds/user/ajc348/hpc-work/mopo/.env/lib/python3.6/site-packages/ray/tune/logger.py:114: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.

2022-05-19 09:08:22,379	WARNING util.py:64 -- The `save_to_disk` operation took 0.8305542469024658 seconds to complete, which may be a performance bottleneck.
2022-05-19 09:08:22,383	WARNING util.py:64 -- The `process_trial` operation took 0.8427729606628418 seconds to complete, which may be a performance bottleneck.
2022-05-19 09:16:02,275	WARNING util.py:64 -- The `save_to_disk` operation took 0.49578285217285156 seconds to complete, which may be a performance bottleneck.
2022-05-19 09:16:02,277	WARNING util.py:64 -- The `process_trial` operation took 0.5073096752166748 seconds to complete, which may be a performance bottleneck.
2022-05-19 09:23:41,743	WARNING util.py:64 -- The `save_to_disk` operation took 0.5003838539123535 seconds to complete, which may be a performance bottleneck.
2022-05-19 09:23:41,747	WARNING util.py:64 -- The `process_trial` operation took 0.5128226280212402 seconds to complete, which may be a performance bottleneck.
2022-05-19 09:31:21,567	WARNING util.py:64 -- The `save_to_disk` operation took 0.5061118602752686 seconds to complete, which may be a performance bottleneck.
2022-05-19 09:31:21,569	WARNING util.py:64 -- The `process_trial` operation took 0.517845869064331 seconds to complete, which may be a performance bottleneck.
2022-05-19 09:39:00,517	WARNING util.py:64 -- The `save_to_disk` operation took 0.5091238021850586 seconds to complete, which may be a performance bottleneck.
2022-05-19 09:39:00,520	WARNING util.py:64 -- The `process_trial` operation took 0.5213623046875 seconds to complete, which may be a performance bottleneck.
2022-05-19 09:46:40,324	WARNING util.py:64 -- The `save_to_disk` operation took 0.9454264640808105 seconds to complete, which may be a performance bottleneck.
2022-05-19 09:46:40,326	WARNING util.py:64 -- The `process_trial` operation took 0.9578959941864014 seconds to complete, which may be a performance bottleneck.
slurmstepd: error: *** JOB 61382294 ON gpu-e-17 CANCELLED AT 2022-05-19T09:53:43 DUE TO TIME LIMIT ***
