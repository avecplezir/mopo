Q-avg,Q-std,Q_loss,alpha,policy/shifts-mean,policy/shifts-std,policy/log_scale_diags-mean,policy/log_scale_diags-std,policy/-log-pis-mean,policy/-log-pis-std,policy/raw-actions-mean,policy/raw-actions-std,policy/actions-mean,policy/actions-std,evaluation/env_infos/reward_ctrl-first-mean,evaluation/env_infos/reward_ctrl-last-mean,evaluation/env_infos/reward_ctrl-mean-mean,evaluation/env_infos/reward_ctrl-median-mean,evaluation/env_infos/reward_ctrl-range-mean,evaluation/env_infos/reward_run-first-mean,evaluation/env_infos/reward_run-last-mean,evaluation/env_infos/reward_run-mean-mean,evaluation/env_infos/reward_run-median-mean,evaluation/env_infos/reward_run-range-mean,evaluation/episode-length-avg,evaluation/episode-length-max,evaluation/episode-length-min,evaluation/episode-length-std,evaluation/return-average,evaluation/return-max,evaluation/return-min,evaluation/return-std,times/epoch_after_hook,times/epoch_before_hook,times/epoch_rollout_model,times/evaluation_metrics,times/evaluation_paths,times/timestep_after_hook,times/timestep_before_hook,times/train,sampler/episodes,sampler/last-path-return,sampler/max-path-return,sampler/pool-size,sampler/total-samples,model/mean_rollout_length,model/val_loss,epoch,timestep,timesteps_total,train-steps,done,episodes_total,training_iteration,experiment_id,date,timestamp,time_this_iter_s,time_total_s,pid,hostname,node_ip,config,time_since_restore,timesteps_since_restore,iterations_since_restore
18.320892333984375,3.861133098602295,0.8122752904891968,0.7408841252326965,0.22076189517974854,0.3672531843185425,-0.17865115404129028,0.11915697902441025,3.183096170425415,1.1983094215393066,0.24380506575107574,0.9300749897956848,0.1473841518163681,0.6037527918815613,-0.0027667821571230886,-0.0022696254774928096,-0.002293022638708353,-0.0022696254774928096,0.005213530976325273,0.09316765229128214,2.2551405187698492e-17,-0.0002456196251934523,-4.5102810375396984e-17,0.39026551860358427,1000.0,1000,1000,0.0,-2.538642406463623,-1.6346526145935059,-4.295312404632568,0.7549729347229004,1.735985279083252e-06,4.733400419354439e-05,9.220532889012247,0.006173910107463598,21.073473835363984,0.0021078591234982014,0.005190790165215731,14.959742420352995,0,0,-inf,101000,0,5.0,0.11965973675251007,0,1000,1000,1000,False,,1,e70dcb782c5a4d21a122288b7f76519f,2022-05-19_13-46-53,1652964413,675.348058462143,675.348058462143,19432,gpu-e-17,10.43.6.17,"{'environment_params': {'training': {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}}, 'evaluation': {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}}}, 'policy_params': {'type': 'GaussianPolicy', 'kwargs': {'hidden_layer_sizes': (256, 256), 'squash': True}}, 'Q_params': {'type': 'double_feedforward_Q_function', 'kwargs': {'hidden_layer_sizes': (256, 256)}}, 'algorithm_params': OrderedDict([('type', 'MOPO'), ('universe', 'gym'), ('log_dir', './ray_mopo/'), ('kwargs', OrderedDict([('epoch_length', 1000), ('train_every_n_steps', 1), ('n_train_repeat', 1), ('eval_render_mode', None), ('eval_n_episodes', 10), ('eval_deterministic', True), ('discount', 0.99), ('tau', 0.005), ('reward_scale', 1.0), ('model_train_freq', 1000), ('model_retain_epochs', 5), ('rollout_batch_size', 50000.0), ('deterministic', False), ('num_networks', 7), ('num_elites', 5), ('real_ratio', 0.05), ('target_entropy', -3), ('max_model_t', None), ('separate_mean_var', True), ('penalty_learned_var', True), ('pool_load_path', '/home/ajc348/rds/hpc-work/mopo/rollouts/D3RLPY-PEP1.npy'), ('pool_load_max_size', 101000), ('rollout_length', 5), ('penalty_coeff', 1.0), ('n_epochs', 500), ('n_initial_exploration_steps', 5000), ('reparameterize', True), ('lr', 0.0003), ('target_update_interval', 1), ('store_extra_policy_info', False), ('action_prior', 'uniform')])), ('domain', 'HalfCheetah'), ('task', 'v2'), ('exp_name', 'halfcheetah_d3rlpy')]), 'replay_pool_params': {'type': 'SimpleReplayPool', 'kwargs': {'max_size': 1000000}}, 'sampler_params': {'type': 'SimpleSampler', 'kwargs': {'max_path_length': 1000, 'min_pool_size': 1000, 'batch_size': 256}}, 'run_params': {'seed': 1443, 'checkpoint_at_end': True, 'checkpoint_frequency': 10, 'checkpoint_replay_pool': False}, 'restore': None}",675.348058462143,0,1
29.644052505493164,6.2426018714904785,1.4191792011260986,0.555325448513031,0.2674897015094757,0.5139174461364746,-0.2193681001663208,0.11107955127954483,2.773813247680664,1.6300753355026245,0.28641074895858765,0.9739629626274109,0.17681507766246796,0.6048994064331055,-0.008349188268184662,-0.008623437434434892,-0.008651671195924282,-0.008623439818620682,0.007010717839002608,0.10889094785900963,-2.084295440060724e-08,2.765568095436807e-05,-1.0655415057236883e-08,0.2773034747794484,1000.0,1000,1000,0.0,-8.624014854431152,-7.587291240692139,-9.309505462646484,0.5410550236701965,1.5702098608016968e-06,4.219915717840195e-05,9.008482159115374,0.0063168019987642765,20.749302584677935,0.0021064304746687412,0.005171298515051603,14.306066261138767,0,0,-inf,101000,0,5.0,0.11965973675251007,1,1000,2000,2000,False,,2,e70dcb782c5a4d21a122288b7f76519f,2022-05-19_13-47-37,1652964457,44.108826875686646,719.4568853378296,19432,gpu-e-17,10.43.6.17,"{'environment_params': {'training': {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}}, 'evaluation': {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}}}, 'policy_params': {'type': 'GaussianPolicy', 'kwargs': {'hidden_layer_sizes': (256, 256), 'squash': True}}, 'Q_params': {'type': 'double_feedforward_Q_function', 'kwargs': {'hidden_layer_sizes': (256, 256)}}, 'algorithm_params': OrderedDict([('type', 'MOPO'), ('universe', 'gym'), ('log_dir', './ray_mopo/'), ('kwargs', OrderedDict([('epoch_length', 1000), ('train_every_n_steps', 1), ('n_train_repeat', 1), ('eval_render_mode', None), ('eval_n_episodes', 10), ('eval_deterministic', True), ('discount', 0.99), ('tau', 0.005), ('reward_scale', 1.0), ('model_train_freq', 1000), ('model_retain_epochs', 5), ('rollout_batch_size', 50000.0), ('deterministic', False), ('num_networks', 7), ('num_elites', 5), ('real_ratio', 0.05), ('target_entropy', -3), ('max_model_t', None), ('separate_mean_var', True), ('penalty_learned_var', True), ('pool_load_path', '/home/ajc348/rds/hpc-work/mopo/rollouts/D3RLPY-PEP1.npy'), ('pool_load_max_size', 101000), ('rollout_length', 5), ('penalty_coeff', 1.0), ('n_epochs', 500), ('n_initial_exploration_steps', 5000), ('reparameterize', True), ('lr', 0.0003), ('target_update_interval', 1), ('store_extra_policy_info', False), ('action_prior', 'uniform')])), ('domain', 'HalfCheetah'), ('task', 'v2'), ('exp_name', 'halfcheetah_d3rlpy')]), 'replay_pool_params': {'type': 'SimpleReplayPool', 'kwargs': {'max_size': 1000000}}, 'sampler_params': {'type': 'SimpleSampler', 'kwargs': {'max_path_length': 1000, 'min_pool_size': 1000, 'batch_size': 256}}, 'run_params': {'seed': 1443, 'checkpoint_at_end': True, 'checkpoint_frequency': 10, 'checkpoint_replay_pool': False}, 'restore': None}",719.4568853378296,0,2
38.75928497314453,7.128468990325928,2.9280753135681152,0.4248014986515045,0.26215946674346924,0.7050153613090515,-0.28599774837493896,0.12742756307125092,1.6858205795288086,2.3151514530181885,0.25687429308891296,1.037778615951538,0.15521736443042755,0.6440568566322327,-0.019278851449489594,-0.021705016195774078,-0.021799212233498694,-0.02170501813292503,0.016138334274291993,0.18837669061140197,2.2301022344767274e-08,0.001630213979245303,-3.890771095582668e-08,0.3528444254347978,1000.0,1000,1000,0.0,-20.16900062561035,-18.12108612060547,-21.407276153564453,1.0821799039840698,1.6759149730205536e-06,4.9944035708904266e-05,8.836817712988704,0.0065408432856202126,20.7388154999353,0.0020924541167914867,0.005166963674128056,14.294334770180285,0,0,-inf,101000,0,5.0,0.11965973675251007,2,1000,3000,3000,False,,3,e70dcb782c5a4d21a122288b7f76519f,2022-05-19_13-48-21,1652964501,43.914228677749634,763.3711140155792,19432,gpu-e-17,10.43.6.17,"{'environment_params': {'training': {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}}, 'evaluation': {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}}}, 'policy_params': {'type': 'GaussianPolicy', 'kwargs': {'hidden_layer_sizes': (256, 256), 'squash': True}}, 'Q_params': {'type': 'double_feedforward_Q_function', 'kwargs': {'hidden_layer_sizes': (256, 256)}}, 'algorithm_params': OrderedDict([('type', 'MOPO'), ('universe', 'gym'), ('log_dir', './ray_mopo/'), ('kwargs', OrderedDict([('epoch_length', 1000), ('train_every_n_steps', 1), ('n_train_repeat', 1), ('eval_render_mode', None), ('eval_n_episodes', 10), ('eval_deterministic', True), ('discount', 0.99), ('tau', 0.005), ('reward_scale', 1.0), ('model_train_freq', 1000), ('model_retain_epochs', 5), ('rollout_batch_size', 50000.0), ('deterministic', False), ('num_networks', 7), ('num_elites', 5), ('real_ratio', 0.05), ('target_entropy', -3), ('max_model_t', None), ('separate_mean_var', True), ('penalty_learned_var', True), ('pool_load_path', '/home/ajc348/rds/hpc-work/mopo/rollouts/D3RLPY-PEP1.npy'), ('pool_load_max_size', 101000), ('rollout_length', 5), ('penalty_coeff', 1.0), ('n_epochs', 500), ('n_initial_exploration_steps', 5000), ('reparameterize', True), ('lr', 0.0003), ('target_update_interval', 1), ('store_extra_policy_info', False), ('action_prior', 'uniform')])), ('domain', 'HalfCheetah'), ('task', 'v2'), ('exp_name', 'halfcheetah_d3rlpy')]), 'replay_pool_params': {'type': 'SimpleReplayPool', 'kwargs': {'max_size': 1000000}}, 'sampler_params': {'type': 'SimpleSampler', 'kwargs': {'max_path_length': 1000, 'min_pool_size': 1000, 'batch_size': 256}}, 'run_params': {'seed': 1443, 'checkpoint_at_end': True, 'checkpoint_frequency': 10, 'checkpoint_replay_pool': False}, 'restore': None}",763.3711140155792,0,3
43.59687805175781,9.849924087524414,2.8298304080963135,0.3390346169471741,0.25992968678474426,0.9334107637405396,-0.40027526021003723,0.13286015391349792,-0.06573612242937088,3.1267712116241455,0.2534780204296112,1.1583305597305298,0.1571425050497055,0.6969417333602905,-0.034868423938751225,-0.36957936048507695,-0.3766693186233938,-0.39890660405159,0.4419830799102783,0.3064458908861701,3.5879082982415866,3.103097435336463,3.1735910176620408,6.806509289637127,1000.0,1000,1000,0.0,2726.42822265625,3289.6630859375,2168.266845703125,298.094482421875,1.5618279576301575e-06,3.710296005010605e-05,8.828387037850916,0.00670009758323431,20.61810588091612,0.0020598149858415127,0.0052294605411589146,14.312955869361758,0,0,-inf,101000,0,5.0,0.11965973675251007,3,1000,4000,4000,False,,4,e70dcb782c5a4d21a122288b7f76519f,2022-05-19_13-49-04,1652964544,43.80418515205383,807.175299167633,19432,gpu-e-17,10.43.6.17,"{'environment_params': {'training': {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}}, 'evaluation': {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}}}, 'policy_params': {'type': 'GaussianPolicy', 'kwargs': {'hidden_layer_sizes': (256, 256), 'squash': True}}, 'Q_params': {'type': 'double_feedforward_Q_function', 'kwargs': {'hidden_layer_sizes': (256, 256)}}, 'algorithm_params': OrderedDict([('type', 'MOPO'), ('universe', 'gym'), ('log_dir', './ray_mopo/'), ('kwargs', OrderedDict([('epoch_length', 1000), ('train_every_n_steps', 1), ('n_train_repeat', 1), ('eval_render_mode', None), ('eval_n_episodes', 10), ('eval_deterministic', True), ('discount', 0.99), ('tau', 0.005), ('reward_scale', 1.0), ('model_train_freq', 1000), ('model_retain_epochs', 5), ('rollout_batch_size', 50000.0), ('deterministic', False), ('num_networks', 7), ('num_elites', 5), ('real_ratio', 0.05), ('target_entropy', -3), ('max_model_t', None), ('separate_mean_var', True), ('penalty_learned_var', True), ('pool_load_path', '/home/ajc348/rds/hpc-work/mopo/rollouts/D3RLPY-PEP1.npy'), ('pool_load_max_size', 101000), ('rollout_length', 5), ('penalty_coeff', 1.0), ('n_epochs', 500), ('n_initial_exploration_steps', 5000), ('reparameterize', True), ('lr', 0.0003), ('target_update_interval', 1), ('store_extra_policy_info', False), ('action_prior', 'uniform')])), ('domain', 'HalfCheetah'), ('task', 'v2'), ('exp_name', 'halfcheetah_d3rlpy')]), 'replay_pool_params': {'type': 'SimpleReplayPool', 'kwargs': {'max_size': 1000000}}, 'sampler_params': {'type': 'SimpleSampler', 'kwargs': {'max_path_length': 1000, 'min_pool_size': 1000, 'batch_size': 256}}, 'run_params': {'seed': 1443, 'checkpoint_at_end': True, 'checkpoint_frequency': 10, 'checkpoint_replay_pool': False}, 'restore': None}",807.175299167633,0,4
47.81687927246094,11.209712028503418,2.9701037406921387,0.2917458713054657,0.3706788122653961,1.0718103647232056,-0.46622157096862793,0.12934742867946625,-1.4426716566085815,3.20796537399292,0.35256877541542053,1.2305916547775269,0.21530713140964508,0.716340184211731,-0.05687709987163543,-0.4401960039138794,-0.4317578669208289,-0.447752583026886,0.4420164304971695,0.36616094379243647,3.4290583315825813,2.88531604209218,2.927420715328884,7.426622762733527,1000.0,1000,1000,0.0,2453.55810546875,2976.661865234375,1739.380859375,395.87872314453125,1.7648562788963318e-06,3.545498475432396e-05,8.82955393474549,0.006902489345520735,20.648649633396417,0.00206541595980525,0.00529195461422205,14.308448998723179,0,0,-inf,101000,0,5.0,0.11965973675251007,4,1000,5000,5000,False,,5,e70dcb782c5a4d21a122288b7f76519f,2022-05-19_13-49-48,1652964588,43.83209991455078,851.0073990821838,19432,gpu-e-17,10.43.6.17,"{'environment_params': {'training': {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}}, 'evaluation': {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}}}, 'policy_params': {'type': 'GaussianPolicy', 'kwargs': {'hidden_layer_sizes': (256, 256), 'squash': True}}, 'Q_params': {'type': 'double_feedforward_Q_function', 'kwargs': {'hidden_layer_sizes': (256, 256)}}, 'algorithm_params': OrderedDict([('type', 'MOPO'), ('universe', 'gym'), ('log_dir', './ray_mopo/'), ('kwargs', OrderedDict([('epoch_length', 1000), ('train_every_n_steps', 1), ('n_train_repeat', 1), ('eval_render_mode', None), ('eval_n_episodes', 10), ('eval_deterministic', True), ('discount', 0.99), ('tau', 0.005), ('reward_scale', 1.0), ('model_train_freq', 1000), ('model_retain_epochs', 5), ('rollout_batch_size', 50000.0), ('deterministic', False), ('num_networks', 7), ('num_elites', 5), ('real_ratio', 0.05), ('target_entropy', -3), ('max_model_t', None), ('separate_mean_var', True), ('penalty_learned_var', True), ('pool_load_path', '/home/ajc348/rds/hpc-work/mopo/rollouts/D3RLPY-PEP1.npy'), ('pool_load_max_size', 101000), ('rollout_length', 5), ('penalty_coeff', 1.0), ('n_epochs', 500), ('n_initial_exploration_steps', 5000), ('reparameterize', True), ('lr', 0.0003), ('target_update_interval', 1), ('store_extra_policy_info', False), ('action_prior', 'uniform')])), ('domain', 'HalfCheetah'), ('task', 'v2'), ('exp_name', 'halfcheetah_d3rlpy')]), 'replay_pool_params': {'type': 'SimpleReplayPool', 'kwargs': {'max_size': 1000000}}, 'sampler_params': {'type': 'SimpleSampler', 'kwargs': {'max_path_length': 1000, 'min_pool_size': 1000, 'batch_size': 256}}, 'run_params': {'seed': 1443, 'checkpoint_at_end': True, 'checkpoint_frequency': 10, 'checkpoint_replay_pool': False}, 'restore': None}",851.0073990821838,0,5
56.38322448730469,11.26340389251709,2.5610899925231934,0.28140971064567566,0.34889769554138184,1.2185348272323608,-0.5475977063179016,0.10585696995258331,-3.0522379875183105,3.232196569442749,0.3541073799133301,1.3456426858901978,0.21240633726119995,0.7555441856384277,-0.06963181376457214,-0.41866157770156864,-0.43888378524005417,-0.4481596302986145,0.44644138693809515,0.34752702589448237,3.3802449853012604,2.664918166697407,2.676493778693981,7.787413599685971,1000.0,1000,1000,0.0,2226.034423828125,2502.6279296875,1786.8623046875,234.58311462402344,1.5897676348686218e-06,3.544101491570473e-05,8.845648104790598,0.006913159973919392,20.708609575871378,0.002045628149062395,0.005119686014950275,14.304299622308463,0,0,-inf,101000,0,5.0,0.11965973675251007,5,1000,6000,6000,False,,6,e70dcb782c5a4d21a122288b7f76519f,2022-05-19_13-50-32,1652964632,43.9028480052948,894.9102470874786,19432,gpu-e-17,10.43.6.17,"{'environment_params': {'training': {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}}, 'evaluation': {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}}}, 'policy_params': {'type': 'GaussianPolicy', 'kwargs': {'hidden_layer_sizes': (256, 256), 'squash': True}}, 'Q_params': {'type': 'double_feedforward_Q_function', 'kwargs': {'hidden_layer_sizes': (256, 256)}}, 'algorithm_params': OrderedDict([('type', 'MOPO'), ('universe', 'gym'), ('log_dir', './ray_mopo/'), ('kwargs', OrderedDict([('epoch_length', 1000), ('train_every_n_steps', 1), ('n_train_repeat', 1), ('eval_render_mode', None), ('eval_n_episodes', 10), ('eval_deterministic', True), ('discount', 0.99), ('tau', 0.005), ('reward_scale', 1.0), ('model_train_freq', 1000), ('model_retain_epochs', 5), ('rollout_batch_size', 50000.0), ('deterministic', False), ('num_networks', 7), ('num_elites', 5), ('real_ratio', 0.05), ('target_entropy', -3), ('max_model_t', None), ('separate_mean_var', True), ('penalty_learned_var', True), ('pool_load_path', '/home/ajc348/rds/hpc-work/mopo/rollouts/D3RLPY-PEP1.npy'), ('pool_load_max_size', 101000), ('rollout_length', 5), ('penalty_coeff', 1.0), ('n_epochs', 500), ('n_initial_exploration_steps', 5000), ('reparameterize', True), ('lr', 0.0003), ('target_update_interval', 1), ('store_extra_policy_info', False), ('action_prior', 'uniform')])), ('domain', 'HalfCheetah'), ('task', 'v2'), ('exp_name', 'halfcheetah_d3rlpy')]), 'replay_pool_params': {'type': 'SimpleReplayPool', 'kwargs': {'max_size': 1000000}}, 'sampler_params': {'type': 'SimpleSampler', 'kwargs': {'max_path_length': 1000, 'min_pool_size': 1000, 'batch_size': 256}}, 'run_params': {'seed': 1443, 'checkpoint_at_end': True, 'checkpoint_frequency': 10, 'checkpoint_replay_pool': False}, 'restore': None}",894.9102470874786,0,6
62.34326171875,12.923386573791504,4.889163970947266,0.2974715828895569,0.40203842520713806,1.235548973083496,-0.5842617154121399,0.0923447236418724,-3.6399121284484863,2.976503849029541,0.4036608636379242,1.3592561483383179,0.23938298225402832,0.7614035606384277,-0.07768637597560883,-0.441778531074524,-0.43190521800994874,-0.4398475956916809,0.45218876004219055,0.4561595480778027,3.9352867559290985,3.0386084061881813,3.0598149547158986,7.676133048918194,1000.0,1000,1000,0.0,2606.703369140625,2981.16748046875,2207.512451171875,242.96981811523438,1.6130506992340088e-06,6.752368062734604e-05,8.822120265103877,0.006896611303091049,20.662267830222845,0.0020728278905153275,0.005095766857266426,14.29554287623614,0,0,-inf,101000,0,5.0,0.11965973675251007,6,1000,7000,7000,False,,7,e70dcb782c5a4d21a122288b7f76519f,2022-05-19_13-51-16,1652964676,43.82391428947449,938.7341613769531,19432,gpu-e-17,10.43.6.17,"{'environment_params': {'training': {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}}, 'evaluation': {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}}}, 'policy_params': {'type': 'GaussianPolicy', 'kwargs': {'hidden_layer_sizes': (256, 256), 'squash': True}}, 'Q_params': {'type': 'double_feedforward_Q_function', 'kwargs': {'hidden_layer_sizes': (256, 256)}}, 'algorithm_params': OrderedDict([('type', 'MOPO'), ('universe', 'gym'), ('log_dir', './ray_mopo/'), ('kwargs', OrderedDict([('epoch_length', 1000), ('train_every_n_steps', 1), ('n_train_repeat', 1), ('eval_render_mode', None), ('eval_n_episodes', 10), ('eval_deterministic', True), ('discount', 0.99), ('tau', 0.005), ('reward_scale', 1.0), ('model_train_freq', 1000), ('model_retain_epochs', 5), ('rollout_batch_size', 50000.0), ('deterministic', False), ('num_networks', 7), ('num_elites', 5), ('real_ratio', 0.05), ('target_entropy', -3), ('max_model_t', None), ('separate_mean_var', True), ('penalty_learned_var', True), ('pool_load_path', '/home/ajc348/rds/hpc-work/mopo/rollouts/D3RLPY-PEP1.npy'), ('pool_load_max_size', 101000), ('rollout_length', 5), ('penalty_coeff', 1.0), ('n_epochs', 500), ('n_initial_exploration_steps', 5000), ('reparameterize', True), ('lr', 0.0003), ('target_update_interval', 1), ('store_extra_policy_info', False), ('action_prior', 'uniform')])), ('domain', 'HalfCheetah'), ('task', 'v2'), ('exp_name', 'halfcheetah_d3rlpy')]), 'replay_pool_params': {'type': 'SimpleReplayPool', 'kwargs': {'max_size': 1000000}}, 'sampler_params': {'type': 'SimpleSampler', 'kwargs': {'max_path_length': 1000, 'min_pool_size': 1000, 'batch_size': 256}}, 'run_params': {'seed': 1443, 'checkpoint_at_end': True, 'checkpoint_frequency': 10, 'checkpoint_replay_pool': False}, 'restore': None}",938.7341613769531,0,7
69.8885498046875,10.910080909729004,3.48744535446167,0.32142341136932373,0.36078378558158875,1.2143288850784302,-0.5845392346382141,0.09688368439674377,-3.235372304916382,2.94614839553833,0.3614640235900879,1.3650290966033936,0.2115369290113449,0.7668848633766174,-0.06246732175350189,-0.3803564882278443,-0.39798474136322737,-0.4057286536693573,0.4623470667004585,0.2005183362985322,2.859735314548942,3.081815672739352,3.1425876243627835,7.189019848916418,1000.0,1000,1000,0.0,2683.830810546875,3348.161376953125,1769.958251953125,437.82647705078125,1.6521662473678589e-06,3.445800393819809e-05,8.831668043974787,0.006989839021116495,20.620387512724847,0.0020952182821929455,0.005170261487364769,14.332778408192098,0,0,-inf,101000,0,5.0,0.11965973675251007,7,1000,8000,8000,False,,8,e70dcb782c5a4d21a122288b7f76519f,2022-05-19_13-52-00,1652964720,43.82914090156555,982.5633022785187,19432,gpu-e-17,10.43.6.17,"{'environment_params': {'training': {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}}, 'evaluation': {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}}}, 'policy_params': {'type': 'GaussianPolicy', 'kwargs': {'hidden_layer_sizes': (256, 256), 'squash': True}}, 'Q_params': {'type': 'double_feedforward_Q_function', 'kwargs': {'hidden_layer_sizes': (256, 256)}}, 'algorithm_params': OrderedDict([('type', 'MOPO'), ('universe', 'gym'), ('log_dir', './ray_mopo/'), ('kwargs', OrderedDict([('epoch_length', 1000), ('train_every_n_steps', 1), ('n_train_repeat', 1), ('eval_render_mode', None), ('eval_n_episodes', 10), ('eval_deterministic', True), ('discount', 0.99), ('tau', 0.005), ('reward_scale', 1.0), ('model_train_freq', 1000), ('model_retain_epochs', 5), ('rollout_batch_size', 50000.0), ('deterministic', False), ('num_networks', 7), ('num_elites', 5), ('real_ratio', 0.05), ('target_entropy', -3), ('max_model_t', None), ('separate_mean_var', True), ('penalty_learned_var', True), ('pool_load_path', '/home/ajc348/rds/hpc-work/mopo/rollouts/D3RLPY-PEP1.npy'), ('pool_load_max_size', 101000), ('rollout_length', 5), ('penalty_coeff', 1.0), ('n_epochs', 500), ('n_initial_exploration_steps', 5000), ('reparameterize', True), ('lr', 0.0003), ('target_update_interval', 1), ('store_extra_policy_info', False), ('action_prior', 'uniform')])), ('domain', 'HalfCheetah'), ('task', 'v2'), ('exp_name', 'halfcheetah_d3rlpy')]), 'replay_pool_params': {'type': 'SimpleReplayPool', 'kwargs': {'max_size': 1000000}}, 'sampler_params': {'type': 'SimpleSampler', 'kwargs': {'max_path_length': 1000, 'min_pool_size': 1000, 'batch_size': 256}}, 'run_params': {'seed': 1443, 'checkpoint_at_end': True, 'checkpoint_frequency': 10, 'checkpoint_replay_pool': False}, 'restore': None}",982.5633022785187,0,8
71.2744140625,17.473846435546875,2.9821019172668457,0.3276995122432709,0.2779221832752228,1.1977159976959229,-0.6085260510444641,0.10973944514989853,-2.9562997817993164,2.9535865783691406,0.2579297125339508,1.330655813217163,0.17875750362873077,0.7525594830513,-0.07042162746191025,-0.3847368240356446,-0.3824430370649695,-0.3898740136623383,0.446185009777546,0.2756110669938521,3.7268772696911014,3.8314529309362113,3.881502807557959,7.277354465601796,1000.0,1000,1000,0.0,3449.009765625,3742.44091796875,2654.66796875,306.6719665527344,1.695007085800171e-06,3.735814243555069e-05,8.846835249103606,0.007097859866917133,20.605033098720014,0.002067350782454014,0.005190698429942131,14.298330917023122,0,0,-inf,101000,0,5.0,0.11965973675251007,8,1000,9000,9000,False,,9,e70dcb782c5a4d21a122288b7f76519f,2022-05-19_13-52-44,1652964764,43.79830265045166,1026.3616049289703,19432,gpu-e-17,10.43.6.17,"{'environment_params': {'training': {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}}, 'evaluation': {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}}}, 'policy_params': {'type': 'GaussianPolicy', 'kwargs': {'hidden_layer_sizes': (256, 256), 'squash': True}}, 'Q_params': {'type': 'double_feedforward_Q_function', 'kwargs': {'hidden_layer_sizes': (256, 256)}}, 'algorithm_params': OrderedDict([('type', 'MOPO'), ('universe', 'gym'), ('log_dir', './ray_mopo/'), ('kwargs', OrderedDict([('epoch_length', 1000), ('train_every_n_steps', 1), ('n_train_repeat', 1), ('eval_render_mode', None), ('eval_n_episodes', 10), ('eval_deterministic', True), ('discount', 0.99), ('tau', 0.005), ('reward_scale', 1.0), ('model_train_freq', 1000), ('model_retain_epochs', 5), ('rollout_batch_size', 50000.0), ('deterministic', False), ('num_networks', 7), ('num_elites', 5), ('real_ratio', 0.05), ('target_entropy', -3), ('max_model_t', None), ('separate_mean_var', True), ('penalty_learned_var', True), ('pool_load_path', '/home/ajc348/rds/hpc-work/mopo/rollouts/D3RLPY-PEP1.npy'), ('pool_load_max_size', 101000), ('rollout_length', 5), ('penalty_coeff', 1.0), ('n_epochs', 500), ('n_initial_exploration_steps', 5000), ('reparameterize', True), ('lr', 0.0003), ('target_update_interval', 1), ('store_extra_policy_info', False), ('action_prior', 'uniform')])), ('domain', 'HalfCheetah'), ('task', 'v2'), ('exp_name', 'halfcheetah_d3rlpy')]), 'replay_pool_params': {'type': 'SimpleReplayPool', 'kwargs': {'max_size': 1000000}}, 'sampler_params': {'type': 'SimpleSampler', 'kwargs': {'max_path_length': 1000, 'min_pool_size': 1000, 'batch_size': 256}}, 'run_params': {'seed': 1443, 'checkpoint_at_end': True, 'checkpoint_frequency': 10, 'checkpoint_replay_pool': False}, 'restore': None}",1026.3616049289703,0,9
74.70770263671875,11.940581321716309,4.529143810272217,0.3326933979988098,0.32898464798927307,1.177499771118164,-0.6526728272438049,0.13527147471904755,-2.8119618892669678,2.9913437366485596,0.3251888155937195,1.2686108350753784,0.2071448117494583,0.7371367812156677,-0.04931441694498062,-0.28873705148696904,-0.3230300568990409,-0.3150823152065277,0.42962373510003093,0.20721240867592744,0.1616968085585384,1.4406964144603027,0.8624491363813931,7.207144219619406,1000.0,1000,1000,0.0,1117.6663818359375,2308.548828125,160.15103149414062,701.7572021484375,1.6759149730205536e-06,4.9481168389320374e-05,8.862137005198747,0.0068895090371370316,20.940409526694566,0.002060266211628914,0.005173204001039267,14.323274844326079,0,0,-inf,101000,0,5.0,0.11965973675251007,9,1000,10000,10000,False,,10,e70dcb782c5a4d21a122288b7f76519f,2022-05-19_13-53-28,1652964808,44.17007279396057,1070.531677722931,19432,gpu-e-17,10.43.6.17,"{'environment_params': {'training': {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}}, 'evaluation': {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}}}, 'policy_params': {'type': 'GaussianPolicy', 'kwargs': {'hidden_layer_sizes': (256, 256), 'squash': True}}, 'Q_params': {'type': 'double_feedforward_Q_function', 'kwargs': {'hidden_layer_sizes': (256, 256)}}, 'algorithm_params': OrderedDict([('type', 'MOPO'), ('universe', 'gym'), ('log_dir', './ray_mopo/'), ('kwargs', OrderedDict([('epoch_length', 1000), ('train_every_n_steps', 1), ('n_train_repeat', 1), ('eval_render_mode', None), ('eval_n_episodes', 10), ('eval_deterministic', True), ('discount', 0.99), ('tau', 0.005), ('reward_scale', 1.0), ('model_train_freq', 1000), ('model_retain_epochs', 5), ('rollout_batch_size', 50000.0), ('deterministic', False), ('num_networks', 7), ('num_elites', 5), ('real_ratio', 0.05), ('target_entropy', -3), ('max_model_t', None), ('separate_mean_var', True), ('penalty_learned_var', True), ('pool_load_path', '/home/ajc348/rds/hpc-work/mopo/rollouts/D3RLPY-PEP1.npy'), ('pool_load_max_size', 101000), ('rollout_length', 5), ('penalty_coeff', 1.0), ('n_epochs', 500), ('n_initial_exploration_steps', 5000), ('reparameterize', True), ('lr', 0.0003), ('target_update_interval', 1), ('store_extra_policy_info', False), ('action_prior', 'uniform')])), ('domain', 'HalfCheetah'), ('task', 'v2'), ('exp_name', 'halfcheetah_d3rlpy')]), 'replay_pool_params': {'type': 'SimpleReplayPool', 'kwargs': {'max_size': 1000000}}, 'sampler_params': {'type': 'SimpleSampler', 'kwargs': {'max_path_length': 1000, 'min_pool_size': 1000, 'batch_size': 256}}, 'run_params': {'seed': 1443, 'checkpoint_at_end': True, 'checkpoint_frequency': 10, 'checkpoint_replay_pool': False}, 'restore': None}",1070.531677722931,0,10
78.19477844238281,14.069560050964355,5.161128044128418,0.34227582812309265,0.31585660576820374,1.2018306255340576,-0.6678704619407654,0.13339775800704956,-3.2050068378448486,2.9383604526519775,0.32834261655807495,1.2852039337158203,0.20263780653476715,0.7405900955200195,-0.04203063577413559,-0.3542834329605103,-0.36336488554477697,-0.3721563041210175,0.4681823319196702,0.17031129406570394,3.051696549105202,3.6850230515508406,3.9920142870473088,7.386228607209278,1000.0,1000,1000,0.0,3321.658203125,4136.34521484375,2306.455078125,695.101806640625,1.5962868928909302e-06,5.74188306927681e-05,8.945367619860917,0.006939135026186705,20.694528709631413,0.002051046583801508,0.005169065203517675,14.290797600056976,0,0,-inf,101000,0,5.0,0.11965973675251007,10,1000,11000,11000,False,,11,e70dcb782c5a4d21a122288b7f76519f,2022-05-19_13-54-13,1652964853,43.97506546974182,1114.5067431926727,19432,gpu-e-17,10.43.6.17,"{'environment_params': {'training': {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}}, 'evaluation': {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}}}, 'policy_params': {'type': 'GaussianPolicy', 'kwargs': {'hidden_layer_sizes': (256, 256), 'squash': True}}, 'Q_params': {'type': 'double_feedforward_Q_function', 'kwargs': {'hidden_layer_sizes': (256, 256)}}, 'algorithm_params': OrderedDict([('type', 'MOPO'), ('universe', 'gym'), ('log_dir', './ray_mopo/'), ('kwargs', OrderedDict([('epoch_length', 1000), ('train_every_n_steps', 1), ('n_train_repeat', 1), ('eval_render_mode', None), ('eval_n_episodes', 10), ('eval_deterministic', True), ('discount', 0.99), ('tau', 0.005), ('reward_scale', 1.0), ('model_train_freq', 1000), ('model_retain_epochs', 5), ('rollout_batch_size', 50000.0), ('deterministic', False), ('num_networks', 7), ('num_elites', 5), ('real_ratio', 0.05), ('target_entropy', -3), ('max_model_t', None), ('separate_mean_var', True), ('penalty_learned_var', True), ('pool_load_path', '/home/ajc348/rds/hpc-work/mopo/rollouts/D3RLPY-PEP1.npy'), ('pool_load_max_size', 101000), ('rollout_length', 5), ('penalty_coeff', 1.0), ('n_epochs', 500), ('n_initial_exploration_steps', 5000), ('reparameterize', True), ('lr', 0.0003), ('target_update_interval', 1), ('store_extra_policy_info', False), ('action_prior', 'uniform')])), ('domain', 'HalfCheetah'), ('task', 'v2'), ('exp_name', 'halfcheetah_d3rlpy')]), 'replay_pool_params': {'type': 'SimpleReplayPool', 'kwargs': {'max_size': 1000000}}, 'sampler_params': {'type': 'SimpleSampler', 'kwargs': {'max_path_length': 1000, 'min_pool_size': 1000, 'batch_size': 256}}, 'run_params': {'seed': 1443, 'checkpoint_at_end': True, 'checkpoint_frequency': 10, 'checkpoint_replay_pool': False}, 'restore': None}",1114.5067431926727,0,11
78.78594970703125,16.0275936126709,5.210080623626709,0.3621758222579956,0.32540151476860046,1.156822681427002,-0.6532211899757385,0.13740749657154083,-3.0088467597961426,2.681149482727051,0.350994735956192,1.2655872106552124,0.22227442264556885,0.7341304421424866,-0.030641082972288135,-0.3528533339500427,-0.3524319637386501,-0.363745551109314,0.4581344945728779,0.06415172212612173,4.137316631144927,4.026478340650625,4.080704430176731,7.26801901270961,1000.0,1000,1000,0.0,3674.04638671875,3877.1533203125,3318.253173828125,147.11581420898438,1.783948391675949e-06,3.4839846193790436e-05,8.843793547246605,0.007541777100414038,20.658194330055267,0.0020804754458367825,0.005223781336098909,14.271591465454549,0,0,-inf,101000,0,5.0,0.11965973675251007,11,1000,12000,12000,False,,12,e70dcb782c5a4d21a122288b7f76519f,2022-05-19_13-54-57,1652964897,43.82195997238159,1158.3287031650543,19432,gpu-e-17,10.43.6.17,"{'environment_params': {'training': {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}}, 'evaluation': {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}}}, 'policy_params': {'type': 'GaussianPolicy', 'kwargs': {'hidden_layer_sizes': (256, 256), 'squash': True}}, 'Q_params': {'type': 'double_feedforward_Q_function', 'kwargs': {'hidden_layer_sizes': (256, 256)}}, 'algorithm_params': OrderedDict([('type', 'MOPO'), ('universe', 'gym'), ('log_dir', './ray_mopo/'), ('kwargs', OrderedDict([('epoch_length', 1000), ('train_every_n_steps', 1), ('n_train_repeat', 1), ('eval_render_mode', None), ('eval_n_episodes', 10), ('eval_deterministic', True), ('discount', 0.99), ('tau', 0.005), ('reward_scale', 1.0), ('model_train_freq', 1000), ('model_retain_epochs', 5), ('rollout_batch_size', 50000.0), ('deterministic', False), ('num_networks', 7), ('num_elites', 5), ('real_ratio', 0.05), ('target_entropy', -3), ('max_model_t', None), ('separate_mean_var', True), ('penalty_learned_var', True), ('pool_load_path', '/home/ajc348/rds/hpc-work/mopo/rollouts/D3RLPY-PEP1.npy'), ('pool_load_max_size', 101000), ('rollout_length', 5), ('penalty_coeff', 1.0), ('n_epochs', 500), ('n_initial_exploration_steps', 5000), ('reparameterize', True), ('lr', 0.0003), ('target_update_interval', 1), ('store_extra_policy_info', False), ('action_prior', 'uniform')])), ('domain', 'HalfCheetah'), ('task', 'v2'), ('exp_name', 'halfcheetah_d3rlpy')]), 'replay_pool_params': {'type': 'SimpleReplayPool', 'kwargs': {'max_size': 1000000}}, 'sampler_params': {'type': 'SimpleSampler', 'kwargs': {'max_path_length': 1000, 'min_pool_size': 1000, 'batch_size': 256}}, 'run_params': {'seed': 1443, 'checkpoint_at_end': True, 'checkpoint_frequency': 10, 'checkpoint_replay_pool': False}, 'restore': None}",1158.3287031650543,0,12
78.55691528320312,20.668304443359375,7.813161373138428,0.3763299882411957,0.24710257351398468,1.1812151670455933,-0.6667159199714661,0.13126124441623688,-2.9335319995880127,2.981053352355957,0.22831730544567108,1.2995386123657227,0.16281963884830475,0.7464821934700012,-0.03850242495536805,-0.3425387763977051,-0.35026699285268786,-0.3587536823749542,0.4548731482028961,-0.04296637485996871,2.8440055693547492,3.4461645380427215,3.511023071057487,7.285046923418359,1000.0,1000,1000,0.0,3095.897705078125,4001.53466796875,387.5412902832031,1118.9102783203125,1.8910504877567291e-06,3.712670877575874e-05,8.808995677623898,0.007541236933320761,20.666676200926304,0.0020763594657182693,0.005200183019042015,14.380942679010332,0,0,-inf,101000,0,5.0,0.11965973675251007,12,1000,13000,13000,False,,13,e70dcb782c5a4d21a122288b7f76519f,2022-05-19_13-55-40,1652964940,43.90263819694519,1202.2313413619995,19432,gpu-e-17,10.43.6.17,"{'environment_params': {'training': {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}}, 'evaluation': {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}}}, 'policy_params': {'type': 'GaussianPolicy', 'kwargs': {'hidden_layer_sizes': (256, 256), 'squash': True}}, 'Q_params': {'type': 'double_feedforward_Q_function', 'kwargs': {'hidden_layer_sizes': (256, 256)}}, 'algorithm_params': OrderedDict([('type', 'MOPO'), ('universe', 'gym'), ('log_dir', './ray_mopo/'), ('kwargs', OrderedDict([('epoch_length', 1000), ('train_every_n_steps', 1), ('n_train_repeat', 1), ('eval_render_mode', None), ('eval_n_episodes', 10), ('eval_deterministic', True), ('discount', 0.99), ('tau', 0.005), ('reward_scale', 1.0), ('model_train_freq', 1000), ('model_retain_epochs', 5), ('rollout_batch_size', 50000.0), ('deterministic', False), ('num_networks', 7), ('num_elites', 5), ('real_ratio', 0.05), ('target_entropy', -3), ('max_model_t', None), ('separate_mean_var', True), ('penalty_learned_var', True), ('pool_load_path', '/home/ajc348/rds/hpc-work/mopo/rollouts/D3RLPY-PEP1.npy'), ('pool_load_max_size', 101000), ('rollout_length', 5), ('penalty_coeff', 1.0), ('n_epochs', 500), ('n_initial_exploration_steps', 5000), ('reparameterize', True), ('lr', 0.0003), ('target_update_interval', 1), ('store_extra_policy_info', False), ('action_prior', 'uniform')])), ('domain', 'HalfCheetah'), ('task', 'v2'), ('exp_name', 'halfcheetah_d3rlpy')]), 'replay_pool_params': {'type': 'SimpleReplayPool', 'kwargs': {'max_size': 1000000}}, 'sampler_params': {'type': 'SimpleSampler', 'kwargs': {'max_path_length': 1000, 'min_pool_size': 1000, 'batch_size': 256}}, 'run_params': {'seed': 1443, 'checkpoint_at_end': True, 'checkpoint_frequency': 10, 'checkpoint_replay_pool': False}, 'restore': None}",1202.2313413619995,0,13
83.38313293457031,13.421833992004395,4.163957118988037,0.39775460958480835,0.2650529146194458,1.1722948551177979,-0.6666494011878967,0.1315477043390274,-2.9838430881500244,2.8633670806884766,0.27635276317596436,1.2793922424316406,0.1783895492553711,0.7447301745414734,-0.024765135720372203,-0.3330054807662964,-0.3605759695822745,-0.3695358681678772,0.45732267670333393,0.06990783434403416,4.108183715923374,3.888969789637163,3.8362760098202457,7.452173607925074,1000.0,1000,1000,0.0,3528.393798828125,4091.97998046875,452.12603759765625,1030.448974609375,1.6363337635993958e-06,3.733998164534569e-05,8.888240466825664,0.006959795951843262,20.63748358376324,0.0020650597289204597,0.005187645088881254,14.26097130868584,0,0,-inf,101000,0,5.0,0.11965973675251007,13,1000,14000,14000,False,,14,e70dcb782c5a4d21a122288b7f76519f,2022-05-19_13-56-24,1652964984,43.83485388755798,1246.0661952495575,19432,gpu-e-17,10.43.6.17,"{'environment_params': {'training': {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}}, 'evaluation': {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}}}, 'policy_params': {'type': 'GaussianPolicy', 'kwargs': {'hidden_layer_sizes': (256, 256), 'squash': True}}, 'Q_params': {'type': 'double_feedforward_Q_function', 'kwargs': {'hidden_layer_sizes': (256, 256)}}, 'algorithm_params': OrderedDict([('type', 'MOPO'), ('universe', 'gym'), ('log_dir', './ray_mopo/'), ('kwargs', OrderedDict([('epoch_length', 1000), ('train_every_n_steps', 1), ('n_train_repeat', 1), ('eval_render_mode', None), ('eval_n_episodes', 10), ('eval_deterministic', True), ('discount', 0.99), ('tau', 0.005), ('reward_scale', 1.0), ('model_train_freq', 1000), ('model_retain_epochs', 5), ('rollout_batch_size', 50000.0), ('deterministic', False), ('num_networks', 7), ('num_elites', 5), ('real_ratio', 0.05), ('target_entropy', -3), ('max_model_t', None), ('separate_mean_var', True), ('penalty_learned_var', True), ('pool_load_path', '/home/ajc348/rds/hpc-work/mopo/rollouts/D3RLPY-PEP1.npy'), ('pool_load_max_size', 101000), ('rollout_length', 5), ('penalty_coeff', 1.0), ('n_epochs', 500), ('n_initial_exploration_steps', 5000), ('reparameterize', True), ('lr', 0.0003), ('target_update_interval', 1), ('store_extra_policy_info', False), ('action_prior', 'uniform')])), ('domain', 'HalfCheetah'), ('task', 'v2'), ('exp_name', 'halfcheetah_d3rlpy')]), 'replay_pool_params': {'type': 'SimpleReplayPool', 'kwargs': {'max_size': 1000000}}, 'sampler_params': {'type': 'SimpleSampler', 'kwargs': {'max_path_length': 1000, 'min_pool_size': 1000, 'batch_size': 256}}, 'run_params': {'seed': 1443, 'checkpoint_at_end': True, 'checkpoint_frequency': 10, 'checkpoint_replay_pool': False}, 'restore': None}",1246.0661952495575,0,14
84.76354217529297,17.705596923828125,6.196842193603516,0.4076921343803406,0.4261299669742584,1.1671524047851562,-0.6586844325065613,0.1221158504486084,-3.330169439315796,2.662837505340576,0.4264688491821289,1.2756147384643555,0.2576383352279663,0.734592616558075,-0.025485145747661593,-0.3888094878196716,-0.3842657267522812,-0.39314243793487547,0.4856248071789742,0.03947930557900835,2.2205880777892304,3.3409098736516407,3.321847095514479,7.933288053965637,1000.0,1000,1000,0.0,2956.64404296875,4087.676025390625,516.0328979492188,1330.4571533203125,1.7159618437290192e-06,3.514206036925316e-05,8.861434556078166,0.006946491543203592,20.668696973007172,0.0020949775353074074,0.005115744657814503,14.365958172362298,0,0,-inf,101000,0,5.0,0.11965973675251007,14,1000,15000,15000,False,,15,e70dcb782c5a4d21a122288b7f76519f,2022-05-19_13-57-08,1652965028,43.94024991989136,1290.0064451694489,19432,gpu-e-17,10.43.6.17,"{'environment_params': {'training': {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}}, 'evaluation': {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}}}, 'policy_params': {'type': 'GaussianPolicy', 'kwargs': {'hidden_layer_sizes': (256, 256), 'squash': True}}, 'Q_params': {'type': 'double_feedforward_Q_function', 'kwargs': {'hidden_layer_sizes': (256, 256)}}, 'algorithm_params': OrderedDict([('type', 'MOPO'), ('universe', 'gym'), ('log_dir', './ray_mopo/'), ('kwargs', OrderedDict([('epoch_length', 1000), ('train_every_n_steps', 1), ('n_train_repeat', 1), ('eval_render_mode', None), ('eval_n_episodes', 10), ('eval_deterministic', True), ('discount', 0.99), ('tau', 0.005), ('reward_scale', 1.0), ('model_train_freq', 1000), ('model_retain_epochs', 5), ('rollout_batch_size', 50000.0), ('deterministic', False), ('num_networks', 7), ('num_elites', 5), ('real_ratio', 0.05), ('target_entropy', -3), ('max_model_t', None), ('separate_mean_var', True), ('penalty_learned_var', True), ('pool_load_path', '/home/ajc348/rds/hpc-work/mopo/rollouts/D3RLPY-PEP1.npy'), ('pool_load_max_size', 101000), ('rollout_length', 5), ('penalty_coeff', 1.0), ('n_epochs', 500), ('n_initial_exploration_steps', 5000), ('reparameterize', True), ('lr', 0.0003), ('target_update_interval', 1), ('store_extra_policy_info', False), ('action_prior', 'uniform')])), ('domain', 'HalfCheetah'), ('task', 'v2'), ('exp_name', 'halfcheetah_d3rlpy')]), 'replay_pool_params': {'type': 'SimpleReplayPool', 'kwargs': {'max_size': 1000000}}, 'sampler_params': {'type': 'SimpleSampler', 'kwargs': {'max_path_length': 1000, 'min_pool_size': 1000, 'batch_size': 256}}, 'run_params': {'seed': 1443, 'checkpoint_at_end': True, 'checkpoint_frequency': 10, 'checkpoint_replay_pool': False}, 'restore': None}",1290.0064451694489,0,15
85.35631561279297,19.040937423706055,5.502039432525635,0.4063596725463867,0.2901687026023865,1.1517268419265747,-0.6489652991294861,0.12006824463605881,-2.428469657897949,2.8612027168273926,0.28016963601112366,1.2429770231246948,0.17149138450622559,0.732880175113678,-0.03817706644535065,-0.3896095895767212,-0.3791451470553875,-0.3835162377357483,0.4975344175100328,0.27514909978668006,1.7535695706623322,3.276143394814403,3.3658979768528297,7.939277924326724,1000.0,1000,1000,0.0,2896.998291015625,4199.44921875,-216.966796875,1554.6756591796875,1.8039718270301819e-06,3.768084570765495e-05,8.86115081841126,0.006939196027815342,20.712952021043748,0.002074574586004019,0.005275669973343611,14.393669061828405,0,0,-inf,101000,0,5.0,0.11965973675251007,15,1000,16000,16000,False,,16,e70dcb782c5a4d21a122288b7f76519f,2022-05-19_13-57-52,1652965072,44.012051820755005,1334.0184969902039,19432,gpu-e-17,10.43.6.17,"{'environment_params': {'training': {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}}, 'evaluation': {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}}}, 'policy_params': {'type': 'GaussianPolicy', 'kwargs': {'hidden_layer_sizes': (256, 256), 'squash': True}}, 'Q_params': {'type': 'double_feedforward_Q_function', 'kwargs': {'hidden_layer_sizes': (256, 256)}}, 'algorithm_params': OrderedDict([('type', 'MOPO'), ('universe', 'gym'), ('log_dir', './ray_mopo/'), ('kwargs', OrderedDict([('epoch_length', 1000), ('train_every_n_steps', 1), ('n_train_repeat', 1), ('eval_render_mode', None), ('eval_n_episodes', 10), ('eval_deterministic', True), ('discount', 0.99), ('tau', 0.005), ('reward_scale', 1.0), ('model_train_freq', 1000), ('model_retain_epochs', 5), ('rollout_batch_size', 50000.0), ('deterministic', False), ('num_networks', 7), ('num_elites', 5), ('real_ratio', 0.05), ('target_entropy', -3), ('max_model_t', None), ('separate_mean_var', True), ('penalty_learned_var', True), ('pool_load_path', '/home/ajc348/rds/hpc-work/mopo/rollouts/D3RLPY-PEP1.npy'), ('pool_load_max_size', 101000), ('rollout_length', 5), ('penalty_coeff', 1.0), ('n_epochs', 500), ('n_initial_exploration_steps', 5000), ('reparameterize', True), ('lr', 0.0003), ('target_update_interval', 1), ('store_extra_policy_info', False), ('action_prior', 'uniform')])), ('domain', 'HalfCheetah'), ('task', 'v2'), ('exp_name', 'halfcheetah_d3rlpy')]), 'replay_pool_params': {'type': 'SimpleReplayPool', 'kwargs': {'max_size': 1000000}}, 'sampler_params': {'type': 'SimpleSampler', 'kwargs': {'max_path_length': 1000, 'min_pool_size': 1000, 'batch_size': 256}}, 'run_params': {'seed': 1443, 'checkpoint_at_end': True, 'checkpoint_frequency': 10, 'checkpoint_replay_pool': False}, 'restore': None}",1334.0184969902039,0,16
87.28939819335938,17.140317916870117,5.157584190368652,0.402323842048645,0.3407973349094391,1.1559813022613525,-0.670466423034668,0.13759246468544006,-2.884603977203369,2.9084136486053467,0.3395223319530487,1.2729051113128662,0.21587498486042023,0.7279163599014282,-0.029947080314159397,-0.39816560029983517,-0.38682736914813515,-0.393470630645752,0.5180549862980842,0.15819867720316322,1.7327515348664946,3.0678838715034584,2.906010131485189,8.295240021786874,1000.0,1000,1000,0.0,2681.056640625,4322.41357421875,121.61151123046875,1468.379150390625,1.632142812013626e-06,3.457162529230118e-05,8.836136853322387,0.006977016571909189,20.6588347828947,0.002072119154036045,0.005225873086601496,14.396682625170797,0,0,-inf,101000,0,5.0,0.11965973675251007,16,1000,17000,17000,False,,17,e70dcb782c5a4d21a122288b7f76519f,2022-05-19_13-58-36,1652965116,43.935975313186646,1377.9544723033905,19432,gpu-e-17,10.43.6.17,"{'environment_params': {'training': {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}}, 'evaluation': {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}}}, 'policy_params': {'type': 'GaussianPolicy', 'kwargs': {'hidden_layer_sizes': (256, 256), 'squash': True}}, 'Q_params': {'type': 'double_feedforward_Q_function', 'kwargs': {'hidden_layer_sizes': (256, 256)}}, 'algorithm_params': OrderedDict([('type', 'MOPO'), ('universe', 'gym'), ('log_dir', './ray_mopo/'), ('kwargs', OrderedDict([('epoch_length', 1000), ('train_every_n_steps', 1), ('n_train_repeat', 1), ('eval_render_mode', None), ('eval_n_episodes', 10), ('eval_deterministic', True), ('discount', 0.99), ('tau', 0.005), ('reward_scale', 1.0), ('model_train_freq', 1000), ('model_retain_epochs', 5), ('rollout_batch_size', 50000.0), ('deterministic', False), ('num_networks', 7), ('num_elites', 5), ('real_ratio', 0.05), ('target_entropy', -3), ('max_model_t', None), ('separate_mean_var', True), ('penalty_learned_var', True), ('pool_load_path', '/home/ajc348/rds/hpc-work/mopo/rollouts/D3RLPY-PEP1.npy'), ('pool_load_max_size', 101000), ('rollout_length', 5), ('penalty_coeff', 1.0), ('n_epochs', 500), ('n_initial_exploration_steps', 5000), ('reparameterize', True), ('lr', 0.0003), ('target_update_interval', 1), ('store_extra_policy_info', False), ('action_prior', 'uniform')])), ('domain', 'HalfCheetah'), ('task', 'v2'), ('exp_name', 'halfcheetah_d3rlpy')]), 'replay_pool_params': {'type': 'SimpleReplayPool', 'kwargs': {'max_size': 1000000}}, 'sampler_params': {'type': 'SimpleSampler', 'kwargs': {'max_path_length': 1000, 'min_pool_size': 1000, 'batch_size': 256}}, 'run_params': {'seed': 1443, 'checkpoint_at_end': True, 'checkpoint_frequency': 10, 'checkpoint_replay_pool': False}, 'restore': None}",1377.9544723033905,0,17
89.60874938964844,16.205299377441406,4.834710121154785,0.4046201705932617,0.3685944080352783,1.1836819648742676,-0.6536823511123657,0.133946031332016,-3.2078137397766113,2.7706027030944824,0.35133907198905945,1.2813323736190796,0.21035559475421906,0.7380235195159912,-0.05585735231637955,-0.4474427199363709,-0.3945728015106917,-0.39503222107887276,0.49972047418355936,0.3727609617315961,1.1579773410047807,3.08062294763949,3.1818529136336995,8.79643794619713,1000.0,1000,1000,0.0,2686.050048828125,4481.1806640625,164.09173583984375,1576.955322265625,1.7238780856132507e-06,3.594905138015747e-05,8.830158984288573,0.006956927012652159,20.69668657472357,0.0020971004851162434,0.005143463145941496,14.296396170277148,0,0,-inf,101000,0,5.0,0.11965973675251007,17,1000,18000,18000,False,,18,e70dcb782c5a4d21a122288b7f76519f,2022-05-19_13-59-20,1652965160,43.86773729324341,1421.822209596634,19432,gpu-e-17,10.43.6.17,"{'environment_params': {'training': {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}}, 'evaluation': {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}}}, 'policy_params': {'type': 'GaussianPolicy', 'kwargs': {'hidden_layer_sizes': (256, 256), 'squash': True}}, 'Q_params': {'type': 'double_feedforward_Q_function', 'kwargs': {'hidden_layer_sizes': (256, 256)}}, 'algorithm_params': OrderedDict([('type', 'MOPO'), ('universe', 'gym'), ('log_dir', './ray_mopo/'), ('kwargs', OrderedDict([('epoch_length', 1000), ('train_every_n_steps', 1), ('n_train_repeat', 1), ('eval_render_mode', None), ('eval_n_episodes', 10), ('eval_deterministic', True), ('discount', 0.99), ('tau', 0.005), ('reward_scale', 1.0), ('model_train_freq', 1000), ('model_retain_epochs', 5), ('rollout_batch_size', 50000.0), ('deterministic', False), ('num_networks', 7), ('num_elites', 5), ('real_ratio', 0.05), ('target_entropy', -3), ('max_model_t', None), ('separate_mean_var', True), ('penalty_learned_var', True), ('pool_load_path', '/home/ajc348/rds/hpc-work/mopo/rollouts/D3RLPY-PEP1.npy'), ('pool_load_max_size', 101000), ('rollout_length', 5), ('penalty_coeff', 1.0), ('n_epochs', 500), ('n_initial_exploration_steps', 5000), ('reparameterize', True), ('lr', 0.0003), ('target_update_interval', 1), ('store_extra_policy_info', False), ('action_prior', 'uniform')])), ('domain', 'HalfCheetah'), ('task', 'v2'), ('exp_name', 'halfcheetah_d3rlpy')]), 'replay_pool_params': {'type': 'SimpleReplayPool', 'kwargs': {'max_size': 1000000}}, 'sampler_params': {'type': 'SimpleSampler', 'kwargs': {'max_path_length': 1000, 'min_pool_size': 1000, 'batch_size': 256}}, 'run_params': {'seed': 1443, 'checkpoint_at_end': True, 'checkpoint_frequency': 10, 'checkpoint_replay_pool': False}, 'restore': None}",1421.822209596634,0,18
92.35404968261719,16.93537712097168,4.67317008972168,0.4056614935398102,0.3228331506252289,1.154148817062378,-0.654000997543335,0.12721510231494904,-2.7260611057281494,2.967078685760498,0.32455289363861084,1.2468791007995605,0.20139653980731964,0.7284731268882751,-0.07325238049030305,-0.35577694416046146,-0.3693616926306486,-0.3742141652107239,0.47918533384799955,0.4704513209293272,1.6390335997404613,2.9024014339374173,2.857503948597823,8.38885618311851,1000.0,1000,1000,0.0,2533.039794921875,4531.74267578125,-79.8897705078125,1711.2896728515625,1.7629936337471008e-06,3.413017839193344e-05,8.880012107081711,0.006766662932932377,20.736716028302908,0.00210756529122591,0.005163685418665409,14.325332285370678,0,0,-inf,101000,0,5.0,0.11965973675251007,18,1000,19000,19000,False,,19,e70dcb782c5a4d21a122288b7f76519f,2022-05-19_14-00-04,1652965204,43.986090660095215,1465.8083002567291,19432,gpu-e-17,10.43.6.17,"{'environment_params': {'training': {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}}, 'evaluation': {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}}}, 'policy_params': {'type': 'GaussianPolicy', 'kwargs': {'hidden_layer_sizes': (256, 256), 'squash': True}}, 'Q_params': {'type': 'double_feedforward_Q_function', 'kwargs': {'hidden_layer_sizes': (256, 256)}}, 'algorithm_params': OrderedDict([('type', 'MOPO'), ('universe', 'gym'), ('log_dir', './ray_mopo/'), ('kwargs', OrderedDict([('epoch_length', 1000), ('train_every_n_steps', 1), ('n_train_repeat', 1), ('eval_render_mode', None), ('eval_n_episodes', 10), ('eval_deterministic', True), ('discount', 0.99), ('tau', 0.005), ('reward_scale', 1.0), ('model_train_freq', 1000), ('model_retain_epochs', 5), ('rollout_batch_size', 50000.0), ('deterministic', False), ('num_networks', 7), ('num_elites', 5), ('real_ratio', 0.05), ('target_entropy', -3), ('max_model_t', None), ('separate_mean_var', True), ('penalty_learned_var', True), ('pool_load_path', '/home/ajc348/rds/hpc-work/mopo/rollouts/D3RLPY-PEP1.npy'), ('pool_load_max_size', 101000), ('rollout_length', 5), ('penalty_coeff', 1.0), ('n_epochs', 500), ('n_initial_exploration_steps', 5000), ('reparameterize', True), ('lr', 0.0003), ('target_update_interval', 1), ('store_extra_policy_info', False), ('action_prior', 'uniform')])), ('domain', 'HalfCheetah'), ('task', 'v2'), ('exp_name', 'halfcheetah_d3rlpy')]), 'replay_pool_params': {'type': 'SimpleReplayPool', 'kwargs': {'max_size': 1000000}}, 'sampler_params': {'type': 'SimpleSampler', 'kwargs': {'max_path_length': 1000, 'min_pool_size': 1000, 'batch_size': 256}}, 'run_params': {'seed': 1443, 'checkpoint_at_end': True, 'checkpoint_frequency': 10, 'checkpoint_replay_pool': False}, 'restore': None}",1465.8083002567291,0,19
93.48155212402344,19.80619239807129,4.09505033493042,0.41364410519599915,0.3381214141845703,1.172753930091858,-0.6547704339027405,0.1409294158220291,-2.7634778022766113,2.9276552200317383,0.31073346734046936,1.263691782951355,0.19295556843280792,0.736564576625824,-0.12969784677028656,-0.3290181064605713,-0.3469469574078917,-0.3494475495815277,0.4669198682904244,0.4589061072548991,0.4871851312992419,3.089123924670809,3.331760948258008,8.7572037922308,1000.0,1000,1000,0.0,2742.177001953125,4315.9150390625,709.75390625,1150.9234619140625,1.6400590538978577e-06,3.3412594348192215e-05,8.852285250555724,0.006919983308762312,20.568146992009133,0.002064123749732971,0.005066476762294769,14.299483746755868,0,0,-inf,101000,0,5.0,0.11965973675251007,19,1000,20000,20000,False,,20,e70dcb782c5a4d21a122288b7f76519f,2022-05-19_14-00-48,1652965248,43.76464772224426,1509.5729479789734,19432,gpu-e-17,10.43.6.17,"{'environment_params': {'training': {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}}, 'evaluation': {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}}}, 'policy_params': {'type': 'GaussianPolicy', 'kwargs': {'hidden_layer_sizes': (256, 256), 'squash': True}}, 'Q_params': {'type': 'double_feedforward_Q_function', 'kwargs': {'hidden_layer_sizes': (256, 256)}}, 'algorithm_params': OrderedDict([('type', 'MOPO'), ('universe', 'gym'), ('log_dir', './ray_mopo/'), ('kwargs', OrderedDict([('epoch_length', 1000), ('train_every_n_steps', 1), ('n_train_repeat', 1), ('eval_render_mode', None), ('eval_n_episodes', 10), ('eval_deterministic', True), ('discount', 0.99), ('tau', 0.005), ('reward_scale', 1.0), ('model_train_freq', 1000), ('model_retain_epochs', 5), ('rollout_batch_size', 50000.0), ('deterministic', False), ('num_networks', 7), ('num_elites', 5), ('real_ratio', 0.05), ('target_entropy', -3), ('max_model_t', None), ('separate_mean_var', True), ('penalty_learned_var', True), ('pool_load_path', '/home/ajc348/rds/hpc-work/mopo/rollouts/D3RLPY-PEP1.npy'), ('pool_load_max_size', 101000), ('rollout_length', 5), ('penalty_coeff', 1.0), ('n_epochs', 500), ('n_initial_exploration_steps', 5000), ('reparameterize', True), ('lr', 0.0003), ('target_update_interval', 1), ('store_extra_policy_info', False), ('action_prior', 'uniform')])), ('domain', 'HalfCheetah'), ('task', 'v2'), ('exp_name', 'halfcheetah_d3rlpy')]), 'replay_pool_params': {'type': 'SimpleReplayPool', 'kwargs': {'max_size': 1000000}}, 'sampler_params': {'type': 'SimpleSampler', 'kwargs': {'max_path_length': 1000, 'min_pool_size': 1000, 'batch_size': 256}}, 'run_params': {'seed': 1443, 'checkpoint_at_end': True, 'checkpoint_frequency': 10, 'checkpoint_replay_pool': False}, 'restore': None}",1509.5729479789734,0,20
94.90705108642578,17.633285522460938,5.082423210144043,0.41344568133354187,0.33332210779190063,1.1918954849243164,-0.6526840925216675,0.13896553218364716,-3.0822267532348633,2.9055209159851074,0.3279149830341339,1.2764607667922974,0.21137170493602753,0.7376454472541809,-0.15830796122550966,-0.37215213060379027,-0.38397946164011953,-0.3928988111019135,0.3597325611114502,0.5061580664459703,4.599576323498354,5.0797113397460745,5.060429258735535,7.481429079209133,1000.0,1000,1000,0.0,4695.7314453125,4813.50390625,4387.34423828125,117.04489135742188,1.6209669411182404e-06,4.973588511347771e-05,8.942791074048728,0.00695711188018322,20.551897909026593,0.0020306771621108055,0.005136502906680107,14.357967304997146,0,0,-inf,101000,0,5.0,0.11965973675251007,20,1000,21000,21000,False,,21,e70dcb782c5a4d21a122288b7f76519f,2022-05-19_14-01-32,1652965292,43.905189752578735,1553.4781377315521,19432,gpu-e-17,10.43.6.17,"{'environment_params': {'training': {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}}, 'evaluation': {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}}}, 'policy_params': {'type': 'GaussianPolicy', 'kwargs': {'hidden_layer_sizes': (256, 256), 'squash': True}}, 'Q_params': {'type': 'double_feedforward_Q_function', 'kwargs': {'hidden_layer_sizes': (256, 256)}}, 'algorithm_params': OrderedDict([('type', 'MOPO'), ('universe', 'gym'), ('log_dir', './ray_mopo/'), ('kwargs', OrderedDict([('epoch_length', 1000), ('train_every_n_steps', 1), ('n_train_repeat', 1), ('eval_render_mode', None), ('eval_n_episodes', 10), ('eval_deterministic', True), ('discount', 0.99), ('tau', 0.005), ('reward_scale', 1.0), ('model_train_freq', 1000), ('model_retain_epochs', 5), ('rollout_batch_size', 50000.0), ('deterministic', False), ('num_networks', 7), ('num_elites', 5), ('real_ratio', 0.05), ('target_entropy', -3), ('max_model_t', None), ('separate_mean_var', True), ('penalty_learned_var', True), ('pool_load_path', '/home/ajc348/rds/hpc-work/mopo/rollouts/D3RLPY-PEP1.npy'), ('pool_load_max_size', 101000), ('rollout_length', 5), ('penalty_coeff', 1.0), ('n_epochs', 500), ('n_initial_exploration_steps', 5000), ('reparameterize', True), ('lr', 0.0003), ('target_update_interval', 1), ('store_extra_policy_info', False), ('action_prior', 'uniform')])), ('domain', 'HalfCheetah'), ('task', 'v2'), ('exp_name', 'halfcheetah_d3rlpy')]), 'replay_pool_params': {'type': 'SimpleReplayPool', 'kwargs': {'max_size': 1000000}}, 'sampler_params': {'type': 'SimpleSampler', 'kwargs': {'max_path_length': 1000, 'min_pool_size': 1000, 'batch_size': 256}}, 'run_params': {'seed': 1443, 'checkpoint_at_end': True, 'checkpoint_frequency': 10, 'checkpoint_replay_pool': False}, 'restore': None}",1553.4781377315521,0,21
95.3887939453125,20.603445053100586,4.449771881103516,0.41862136125564575,0.28018954396247864,1.161008358001709,-0.6509013772010803,0.15659023821353912,-3.0277976989746094,2.877934455871582,0.28319838643074036,1.2978895902633667,0.18373799324035645,0.7415596842765808,-0.1275774508714676,-0.3858214735984803,-0.36296551749169825,-0.37313863039016726,0.3705563455820084,0.4215140189354544,4.5673895717307005,4.971949418148199,4.94119166950078,7.510022652390885,1000.0,1000,1000,0.0,4608.9833984375,4651.287109375,4575.1279296875,28.88797950744629,1.6409903764724731e-06,3.4271739423274994e-05,8.828296402934939,0.006875109858810902,20.546109538991004,0.00209827721118927,0.005250058136880398,14.259255517739803,0,0,-inf,101000,0,5.0,0.11965973675251007,21,1000,22000,22000,False,,22,e70dcb782c5a4d21a122288b7f76519f,2022-05-19_14-02-16,1652965336,43.677884101867676,1597.1560218334198,19432,gpu-e-17,10.43.6.17,"{'environment_params': {'training': {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}}, 'evaluation': {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}}}, 'policy_params': {'type': 'GaussianPolicy', 'kwargs': {'hidden_layer_sizes': (256, 256), 'squash': True}}, 'Q_params': {'type': 'double_feedforward_Q_function', 'kwargs': {'hidden_layer_sizes': (256, 256)}}, 'algorithm_params': OrderedDict([('type', 'MOPO'), ('universe', 'gym'), ('log_dir', './ray_mopo/'), ('kwargs', OrderedDict([('epoch_length', 1000), ('train_every_n_steps', 1), ('n_train_repeat', 1), ('eval_render_mode', None), ('eval_n_episodes', 10), ('eval_deterministic', True), ('discount', 0.99), ('tau', 0.005), ('reward_scale', 1.0), ('model_train_freq', 1000), ('model_retain_epochs', 5), ('rollout_batch_size', 50000.0), ('deterministic', False), ('num_networks', 7), ('num_elites', 5), ('real_ratio', 0.05), ('target_entropy', -3), ('max_model_t', None), ('separate_mean_var', True), ('penalty_learned_var', True), ('pool_load_path', '/home/ajc348/rds/hpc-work/mopo/rollouts/D3RLPY-PEP1.npy'), ('pool_load_max_size', 101000), ('rollout_length', 5), ('penalty_coeff', 1.0), ('n_epochs', 500), ('n_initial_exploration_steps', 5000), ('reparameterize', True), ('lr', 0.0003), ('target_update_interval', 1), ('store_extra_policy_info', False), ('action_prior', 'uniform')])), ('domain', 'HalfCheetah'), ('task', 'v2'), ('exp_name', 'halfcheetah_d3rlpy')]), 'replay_pool_params': {'type': 'SimpleReplayPool', 'kwargs': {'max_size': 1000000}}, 'sampler_params': {'type': 'SimpleSampler', 'kwargs': {'max_path_length': 1000, 'min_pool_size': 1000, 'batch_size': 256}}, 'run_params': {'seed': 1443, 'checkpoint_at_end': True, 'checkpoint_frequency': 10, 'checkpoint_replay_pool': False}, 'restore': None}",1597.1560218334198,0,22
98.79753112792969,17.98383331298828,3.3409056663513184,0.4244227409362793,0.2803681194782257,1.1527057886123657,-0.6451165080070496,0.1476358324289322,-2.391505002975464,3.001838207244873,0.25168371200561523,1.2547765970230103,0.16817975044250488,0.7310905456542969,-0.1507744699716568,-0.40288422822952275,-0.37500822290956976,-0.3830939495563507,0.35503280103206636,0.5215928277507648,4.609187490036618,5.019854562927229,4.988330360204054,7.562936009989772,1000.0,1000,1000,0.0,4644.84619140625,4752.8359375,4527.63671875,83.353515625,1.6670674085617065e-06,3.4782104194164276e-05,8.882313115987927,0.006986040156334639,20.46950750099495,0.0020503471605479717,0.0051258634775877,14.277131418697536,0,0,-inf,101000,0,5.0,0.11965973675251007,22,1000,23000,23000,False,,23,e70dcb782c5a4d21a122288b7f76519f,2022-05-19_14-03-00,1652965380,43.672884702682495,1640.8289065361023,19432,gpu-e-17,10.43.6.17,"{'environment_params': {'training': {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}}, 'evaluation': {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}}}, 'policy_params': {'type': 'GaussianPolicy', 'kwargs': {'hidden_layer_sizes': (256, 256), 'squash': True}}, 'Q_params': {'type': 'double_feedforward_Q_function', 'kwargs': {'hidden_layer_sizes': (256, 256)}}, 'algorithm_params': OrderedDict([('type', 'MOPO'), ('universe', 'gym'), ('log_dir', './ray_mopo/'), ('kwargs', OrderedDict([('epoch_length', 1000), ('train_every_n_steps', 1), ('n_train_repeat', 1), ('eval_render_mode', None), ('eval_n_episodes', 10), ('eval_deterministic', True), ('discount', 0.99), ('tau', 0.005), ('reward_scale', 1.0), ('model_train_freq', 1000), ('model_retain_epochs', 5), ('rollout_batch_size', 50000.0), ('deterministic', False), ('num_networks', 7), ('num_elites', 5), ('real_ratio', 0.05), ('target_entropy', -3), ('max_model_t', None), ('separate_mean_var', True), ('penalty_learned_var', True), ('pool_load_path', '/home/ajc348/rds/hpc-work/mopo/rollouts/D3RLPY-PEP1.npy'), ('pool_load_max_size', 101000), ('rollout_length', 5), ('penalty_coeff', 1.0), ('n_epochs', 500), ('n_initial_exploration_steps', 5000), ('reparameterize', True), ('lr', 0.0003), ('target_update_interval', 1), ('store_extra_policy_info', False), ('action_prior', 'uniform')])), ('domain', 'HalfCheetah'), ('task', 'v2'), ('exp_name', 'halfcheetah_d3rlpy')]), 'replay_pool_params': {'type': 'SimpleReplayPool', 'kwargs': {'max_size': 1000000}}, 'sampler_params': {'type': 'SimpleSampler', 'kwargs': {'max_path_length': 1000, 'min_pool_size': 1000, 'batch_size': 256}}, 'run_params': {'seed': 1443, 'checkpoint_at_end': True, 'checkpoint_frequency': 10, 'checkpoint_replay_pool': False}, 'restore': None}",1640.8289065361023,0,23
100.8416748046875,17.48439598083496,3.811328887939453,0.43428584933280945,0.3140469491481781,1.2236180305480957,-0.6342211365699768,0.14330796897411346,-3.264212131500244,2.901548385620117,0.3101021349430084,1.299612283706665,0.1899263709783554,0.7507380843162537,-0.21746848940849306,-0.3973648715019227,-0.38425179544568067,-0.38987285375595093,0.312451411485672,0.5872534625951296,4.034895115088773,5.056876125179422,5.1309948849227585,7.885982336198824,1000.0,1000,1000,0.0,4672.62451171875,5032.265625,3298.0244140625,472.7661437988281,1.58604234457016e-06,3.3532269299030304e-05,8.833401049021631,0.007098846137523651,20.544393393676728,0.0020762449130415916,0.005157739855349064,14.274012247100472,0,0,-inf,101000,0,5.0,0.11965973675251007,23,1000,24000,24000,False,,24,e70dcb782c5a4d21a122288b7f76519f,2022-05-19_14-03-43,1652965423,43.695934534072876,1684.5248410701752,19432,gpu-e-17,10.43.6.17,"{'environment_params': {'training': {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}}, 'evaluation': {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}}}, 'policy_params': {'type': 'GaussianPolicy', 'kwargs': {'hidden_layer_sizes': (256, 256), 'squash': True}}, 'Q_params': {'type': 'double_feedforward_Q_function', 'kwargs': {'hidden_layer_sizes': (256, 256)}}, 'algorithm_params': OrderedDict([('type', 'MOPO'), ('universe', 'gym'), ('log_dir', './ray_mopo/'), ('kwargs', OrderedDict([('epoch_length', 1000), ('train_every_n_steps', 1), ('n_train_repeat', 1), ('eval_render_mode', None), ('eval_n_episodes', 10), ('eval_deterministic', True), ('discount', 0.99), ('tau', 0.005), ('reward_scale', 1.0), ('model_train_freq', 1000), ('model_retain_epochs', 5), ('rollout_batch_size', 50000.0), ('deterministic', False), ('num_networks', 7), ('num_elites', 5), ('real_ratio', 0.05), ('target_entropy', -3), ('max_model_t', None), ('separate_mean_var', True), ('penalty_learned_var', True), ('pool_load_path', '/home/ajc348/rds/hpc-work/mopo/rollouts/D3RLPY-PEP1.npy'), ('pool_load_max_size', 101000), ('rollout_length', 5), ('penalty_coeff', 1.0), ('n_epochs', 500), ('n_initial_exploration_steps', 5000), ('reparameterize', True), ('lr', 0.0003), ('target_update_interval', 1), ('store_extra_policy_info', False), ('action_prior', 'uniform')])), ('domain', 'HalfCheetah'), ('task', 'v2'), ('exp_name', 'halfcheetah_d3rlpy')]), 'replay_pool_params': {'type': 'SimpleReplayPool', 'kwargs': {'max_size': 1000000}}, 'sampler_params': {'type': 'SimpleSampler', 'kwargs': {'max_path_length': 1000, 'min_pool_size': 1000, 'batch_size': 256}}, 'run_params': {'seed': 1443, 'checkpoint_at_end': True, 'checkpoint_frequency': 10, 'checkpoint_replay_pool': False}, 'restore': None}",1684.5248410701752,0,24
101.00547790527344,22.252849578857422,5.464313507080078,0.43067580461502075,0.3287930488586426,1.2161527872085571,-0.6494556069374084,0.1583656370639801,-3.2803289890289307,2.7069997787475586,0.3110560476779938,1.3139420747756958,0.19058658182621002,0.7446892857551575,-0.22053412437438963,-0.4475814175605774,-0.3998111365777255,-0.4099928498268127,0.328600646853447,0.4991442552110549,3.456492734727958,4.803963615794924,4.752192083837967,8.327927492706864,1000.0,1000,1000,0.0,4404.15283203125,5031.814453125,-282.9228210449219,1564.10107421875,1.6246922314167023e-06,6.584497168660164e-05,8.857426412869245,0.0071071479469537735,20.580545014701784,0.0020752581767737865,0.005147958640009165,14.288641273975372,0,0,-inf,101000,0,5.0,0.11965973675251007,24,1000,25000,25000,False,,25,e70dcb782c5a4d21a122288b7f76519f,2022-05-19_14-04-27,1652965467,43.77151393890381,1728.296355009079,19432,gpu-e-17,10.43.6.17,"{'environment_params': {'training': {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}}, 'evaluation': {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}}}, 'policy_params': {'type': 'GaussianPolicy', 'kwargs': {'hidden_layer_sizes': (256, 256), 'squash': True}}, 'Q_params': {'type': 'double_feedforward_Q_function', 'kwargs': {'hidden_layer_sizes': (256, 256)}}, 'algorithm_params': OrderedDict([('type', 'MOPO'), ('universe', 'gym'), ('log_dir', './ray_mopo/'), ('kwargs', OrderedDict([('epoch_length', 1000), ('train_every_n_steps', 1), ('n_train_repeat', 1), ('eval_render_mode', None), ('eval_n_episodes', 10), ('eval_deterministic', True), ('discount', 0.99), ('tau', 0.005), ('reward_scale', 1.0), ('model_train_freq', 1000), ('model_retain_epochs', 5), ('rollout_batch_size', 50000.0), ('deterministic', False), ('num_networks', 7), ('num_elites', 5), ('real_ratio', 0.05), ('target_entropy', -3), ('max_model_t', None), ('separate_mean_var', True), ('penalty_learned_var', True), ('pool_load_path', '/home/ajc348/rds/hpc-work/mopo/rollouts/D3RLPY-PEP1.npy'), ('pool_load_max_size', 101000), ('rollout_length', 5), ('penalty_coeff', 1.0), ('n_epochs', 500), ('n_initial_exploration_steps', 5000), ('reparameterize', True), ('lr', 0.0003), ('target_update_interval', 1), ('store_extra_policy_info', False), ('action_prior', 'uniform')])), ('domain', 'HalfCheetah'), ('task', 'v2'), ('exp_name', 'halfcheetah_d3rlpy')]), 'replay_pool_params': {'type': 'SimpleReplayPool', 'kwargs': {'max_size': 1000000}}, 'sampler_params': {'type': 'SimpleSampler', 'kwargs': {'max_path_length': 1000, 'min_pool_size': 1000, 'batch_size': 256}}, 'run_params': {'seed': 1443, 'checkpoint_at_end': True, 'checkpoint_frequency': 10, 'checkpoint_replay_pool': False}, 'restore': None}",1728.296355009079,0,25
102.81517028808594,19.07552146911621,3.024998664855957,0.43691202998161316,0.27566784620285034,1.1753000020980835,-0.6238701939582825,0.15704147517681122,-2.9425816535949707,2.895995616912842,0.2643604874610901,1.3183649778366089,0.1604914367198944,0.7496630549430847,-0.2334074902534485,-0.4087855744361878,-0.37021265663266184,-0.37688981413841255,0.3395420467853546,0.5108330113350494,4.611228571793504,5.3825596373088445,5.3826179009040604,7.774496928826016,1000.0,1000,1000,0.0,5012.3466796875,5168.1015625,4901.53125,84.73585510253906,1.6400590538978577e-06,3.446592018008232e-05,8.893107574433088,0.007119042798876762,20.56707506533712,0.002058636397123337,0.005068787839263678,14.282085862476379,0,0,-inf,101000,0,5.0,0.11965973675251007,25,1000,26000,26000,False,,26,e70dcb782c5a4d21a122288b7f76519f,2022-05-19_14-05-11,1652965511,43.78632044792175,1772.0826754570007,19432,gpu-e-17,10.43.6.17,"{'environment_params': {'training': {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}}, 'evaluation': {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}}}, 'policy_params': {'type': 'GaussianPolicy', 'kwargs': {'hidden_layer_sizes': (256, 256), 'squash': True}}, 'Q_params': {'type': 'double_feedforward_Q_function', 'kwargs': {'hidden_layer_sizes': (256, 256)}}, 'algorithm_params': OrderedDict([('type', 'MOPO'), ('universe', 'gym'), ('log_dir', './ray_mopo/'), ('kwargs', OrderedDict([('epoch_length', 1000), ('train_every_n_steps', 1), ('n_train_repeat', 1), ('eval_render_mode', None), ('eval_n_episodes', 10), ('eval_deterministic', True), ('discount', 0.99), ('tau', 0.005), ('reward_scale', 1.0), ('model_train_freq', 1000), ('model_retain_epochs', 5), ('rollout_batch_size', 50000.0), ('deterministic', False), ('num_networks', 7), ('num_elites', 5), ('real_ratio', 0.05), ('target_entropy', -3), ('max_model_t', None), ('separate_mean_var', True), ('penalty_learned_var', True), ('pool_load_path', '/home/ajc348/rds/hpc-work/mopo/rollouts/D3RLPY-PEP1.npy'), ('pool_load_max_size', 101000), ('rollout_length', 5), ('penalty_coeff', 1.0), ('n_epochs', 500), ('n_initial_exploration_steps', 5000), ('reparameterize', True), ('lr', 0.0003), ('target_update_interval', 1), ('store_extra_policy_info', False), ('action_prior', 'uniform')])), ('domain', 'HalfCheetah'), ('task', 'v2'), ('exp_name', 'halfcheetah_d3rlpy')]), 'replay_pool_params': {'type': 'SimpleReplayPool', 'kwargs': {'max_size': 1000000}}, 'sampler_params': {'type': 'SimpleSampler', 'kwargs': {'max_path_length': 1000, 'min_pool_size': 1000, 'batch_size': 256}}, 'run_params': {'seed': 1443, 'checkpoint_at_end': True, 'checkpoint_frequency': 10, 'checkpoint_replay_pool': False}, 'restore': None}",1772.0826754570007,0,26
103.33480072021484,23.69109344482422,3.9969642162323,0.43890970945358276,0.3459753096103668,1.1685150861740112,-0.6338338255882263,0.1561315804719925,-2.9294748306274414,2.981529951095581,0.3374474346637726,1.2773504257202148,0.201982781291008,0.7387869954109192,-0.26759129524230957,-0.4069616055488587,-0.3782055451714993,-0.3831209063529969,0.31515561580657964,0.6610310055399834,4.897584979114413,5.353165994198173,5.355611111533966,7.685939890992354,1000.0,1000,1000,0.0,4974.9599609375,5043.9072265625,4874.5888671875,67.12308502197266,1.753680408000946e-06,3.574555739760399e-05,8.89346052100882,0.006930431351065636,20.683331955689937,0.0020691240206360817,0.005037645809352398,14.288165119476616,0,0,-inf,101000,0,5.0,0.11965973675251007,26,1000,27000,27000,False,,27,e70dcb782c5a4d21a122288b7f76519f,2022-05-19_14-05-55,1652965555,43.90962243080139,1815.9922978878021,19432,gpu-e-17,10.43.6.17,"{'environment_params': {'training': {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}}, 'evaluation': {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}}}, 'policy_params': {'type': 'GaussianPolicy', 'kwargs': {'hidden_layer_sizes': (256, 256), 'squash': True}}, 'Q_params': {'type': 'double_feedforward_Q_function', 'kwargs': {'hidden_layer_sizes': (256, 256)}}, 'algorithm_params': OrderedDict([('type', 'MOPO'), ('universe', 'gym'), ('log_dir', './ray_mopo/'), ('kwargs', OrderedDict([('epoch_length', 1000), ('train_every_n_steps', 1), ('n_train_repeat', 1), ('eval_render_mode', None), ('eval_n_episodes', 10), ('eval_deterministic', True), ('discount', 0.99), ('tau', 0.005), ('reward_scale', 1.0), ('model_train_freq', 1000), ('model_retain_epochs', 5), ('rollout_batch_size', 50000.0), ('deterministic', False), ('num_networks', 7), ('num_elites', 5), ('real_ratio', 0.05), ('target_entropy', -3), ('max_model_t', None), ('separate_mean_var', True), ('penalty_learned_var', True), ('pool_load_path', '/home/ajc348/rds/hpc-work/mopo/rollouts/D3RLPY-PEP1.npy'), ('pool_load_max_size', 101000), ('rollout_length', 5), ('penalty_coeff', 1.0), ('n_epochs', 500), ('n_initial_exploration_steps', 5000), ('reparameterize', True), ('lr', 0.0003), ('target_update_interval', 1), ('store_extra_policy_info', False), ('action_prior', 'uniform')])), ('domain', 'HalfCheetah'), ('task', 'v2'), ('exp_name', 'halfcheetah_d3rlpy')]), 'replay_pool_params': {'type': 'SimpleReplayPool', 'kwargs': {'max_size': 1000000}}, 'sampler_params': {'type': 'SimpleSampler', 'kwargs': {'max_path_length': 1000, 'min_pool_size': 1000, 'batch_size': 256}}, 'run_params': {'seed': 1443, 'checkpoint_at_end': True, 'checkpoint_frequency': 10, 'checkpoint_replay_pool': False}, 'restore': None}",1815.9922978878021,0,27
104.60916137695312,21.38909339904785,4.6606903076171875,0.4405973255634308,0.35791972279548645,1.1829217672348022,-0.6311874985694885,0.16321830451488495,-3.072828769683838,2.9409677982330322,0.3709452152252197,1.3095628023147583,0.2109098881483078,0.741044819355011,-0.24830292940139773,-0.4189755082130432,-0.3849220639693737,-0.39049644231796266,0.32630169630050665,0.5808867277089543,3.9120418794857983,5.1317382753197816,5.177714448662812,8.112024645807479,1000.0,1000,1000,0.0,4746.81640625,5079.33740234375,2072.206787109375,892.3768310546875,1.8379651010036469e-06,3.4784432500600815e-05,8.838614751119167,0.0073202382773160934,20.535708615090698,0.0020571956411004066,0.005101843271404505,14.345502684824169,0,0,-inf,101000,0,5.0,0.11965973675251007,27,1000,28000,28000,False,,28,e70dcb782c5a4d21a122288b7f76519f,2022-05-19_14-06-39,1652965599,43.76440143585205,1859.7566993236542,19432,gpu-e-17,10.43.6.17,"{'environment_params': {'training': {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}}, 'evaluation': {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}}}, 'policy_params': {'type': 'GaussianPolicy', 'kwargs': {'hidden_layer_sizes': (256, 256), 'squash': True}}, 'Q_params': {'type': 'double_feedforward_Q_function', 'kwargs': {'hidden_layer_sizes': (256, 256)}}, 'algorithm_params': OrderedDict([('type', 'MOPO'), ('universe', 'gym'), ('log_dir', './ray_mopo/'), ('kwargs', OrderedDict([('epoch_length', 1000), ('train_every_n_steps', 1), ('n_train_repeat', 1), ('eval_render_mode', None), ('eval_n_episodes', 10), ('eval_deterministic', True), ('discount', 0.99), ('tau', 0.005), ('reward_scale', 1.0), ('model_train_freq', 1000), ('model_retain_epochs', 5), ('rollout_batch_size', 50000.0), ('deterministic', False), ('num_networks', 7), ('num_elites', 5), ('real_ratio', 0.05), ('target_entropy', -3), ('max_model_t', None), ('separate_mean_var', True), ('penalty_learned_var', True), ('pool_load_path', '/home/ajc348/rds/hpc-work/mopo/rollouts/D3RLPY-PEP1.npy'), ('pool_load_max_size', 101000), ('rollout_length', 5), ('penalty_coeff', 1.0), ('n_epochs', 500), ('n_initial_exploration_steps', 5000), ('reparameterize', True), ('lr', 0.0003), ('target_update_interval', 1), ('store_extra_policy_info', False), ('action_prior', 'uniform')])), ('domain', 'HalfCheetah'), ('task', 'v2'), ('exp_name', 'halfcheetah_d3rlpy')]), 'replay_pool_params': {'type': 'SimpleReplayPool', 'kwargs': {'max_size': 1000000}}, 'sampler_params': {'type': 'SimpleSampler', 'kwargs': {'max_path_length': 1000, 'min_pool_size': 1000, 'batch_size': 256}}, 'run_params': {'seed': 1443, 'checkpoint_at_end': True, 'checkpoint_frequency': 10, 'checkpoint_replay_pool': False}, 'restore': None}",1859.7566993236542,0,28
103.34432983398438,23.437389373779297,5.079100608825684,0.4440978169441223,0.22886638343334198,1.1863092184066772,-0.6200636029243469,0.1637401431798935,-2.9269626140594482,2.835216760635376,0.2364443987607956,1.3075741529464722,0.152048259973526,0.7526378035545349,-0.2567457342147827,-0.415755295753479,-0.3653536452960968,-0.37033491134643565,0.33803866267204286,0.55102266441062,4.782203724218903,5.414727767210172,5.420235248416493,7.863069702839174,1000.0,1000,1000,0.0,5049.3740234375,5121.8837890625,4927.39013671875,65.39041137695312,1.8388964235782623e-06,3.5575125366449356e-05,8.877348518930376,0.007912134286016226,20.480240684002638,0.0020515830256044865,0.00510786147788167,14.268089035525918,0,0,-inf,101000,0,5.0,0.11965973675251007,28,1000,29000,29000,False,,29,e70dcb782c5a4d21a122288b7f76519f,2022-05-19_14-07-22,1652965642,43.67190456390381,1903.428603887558,19432,gpu-e-17,10.43.6.17,"{'environment_params': {'training': {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}}, 'evaluation': {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}}}, 'policy_params': {'type': 'GaussianPolicy', 'kwargs': {'hidden_layer_sizes': (256, 256), 'squash': True}}, 'Q_params': {'type': 'double_feedforward_Q_function', 'kwargs': {'hidden_layer_sizes': (256, 256)}}, 'algorithm_params': OrderedDict([('type', 'MOPO'), ('universe', 'gym'), ('log_dir', './ray_mopo/'), ('kwargs', OrderedDict([('epoch_length', 1000), ('train_every_n_steps', 1), ('n_train_repeat', 1), ('eval_render_mode', None), ('eval_n_episodes', 10), ('eval_deterministic', True), ('discount', 0.99), ('tau', 0.005), ('reward_scale', 1.0), ('model_train_freq', 1000), ('model_retain_epochs', 5), ('rollout_batch_size', 50000.0), ('deterministic', False), ('num_networks', 7), ('num_elites', 5), ('real_ratio', 0.05), ('target_entropy', -3), ('max_model_t', None), ('separate_mean_var', True), ('penalty_learned_var', True), ('pool_load_path', '/home/ajc348/rds/hpc-work/mopo/rollouts/D3RLPY-PEP1.npy'), ('pool_load_max_size', 101000), ('rollout_length', 5), ('penalty_coeff', 1.0), ('n_epochs', 500), ('n_initial_exploration_steps', 5000), ('reparameterize', True), ('lr', 0.0003), ('target_update_interval', 1), ('store_extra_policy_info', False), ('action_prior', 'uniform')])), ('domain', 'HalfCheetah'), ('task', 'v2'), ('exp_name', 'halfcheetah_d3rlpy')]), 'replay_pool_params': {'type': 'SimpleReplayPool', 'kwargs': {'max_size': 1000000}}, 'sampler_params': {'type': 'SimpleSampler', 'kwargs': {'max_path_length': 1000, 'min_pool_size': 1000, 'batch_size': 256}}, 'run_params': {'seed': 1443, 'checkpoint_at_end': True, 'checkpoint_frequency': 10, 'checkpoint_replay_pool': False}, 'restore': None}",1903.428603887558,0,29
107.95541381835938,20.94184684753418,3.8555874824523926,0.44972220063209534,0.3835618197917938,1.201850414276123,-0.6353640556335449,0.16103029251098633,-3.3709375858306885,3.2061080932617188,0.38459160923957825,1.3155570030212402,0.22113321721553802,0.7479912042617798,-0.2595234322547913,-0.4372380566596985,-0.3943078988897801,-0.3980080246925354,0.326461728811264,0.5036387509910354,4.470861759201512,5.45565069095558,5.487033980435196,8.383242868407823,1000.0,1000,1000,0.0,5061.3427734375,5217.57421875,4120.953125,316.7312927246094,1.669861376285553e-06,3.5556964576244354e-05,8.831272983923554,0.0070684850215911865,20.50962797505781,0.002054027747362852,0.005161837209016085,14.265467971097678,0,0,-inf,101000,0,5.0,0.11965973675251007,29,1000,30000,30000,False,,30,e70dcb782c5a4d21a122288b7f76519f,2022-05-19_14-08-06,1652965686,43.65084791183472,1947.0794517993927,19432,gpu-e-17,10.43.6.17,"{'environment_params': {'training': {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}}, 'evaluation': {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}}}, 'policy_params': {'type': 'GaussianPolicy', 'kwargs': {'hidden_layer_sizes': (256, 256), 'squash': True}}, 'Q_params': {'type': 'double_feedforward_Q_function', 'kwargs': {'hidden_layer_sizes': (256, 256)}}, 'algorithm_params': OrderedDict([('type', 'MOPO'), ('universe', 'gym'), ('log_dir', './ray_mopo/'), ('kwargs', OrderedDict([('epoch_length', 1000), ('train_every_n_steps', 1), ('n_train_repeat', 1), ('eval_render_mode', None), ('eval_n_episodes', 10), ('eval_deterministic', True), ('discount', 0.99), ('tau', 0.005), ('reward_scale', 1.0), ('model_train_freq', 1000), ('model_retain_epochs', 5), ('rollout_batch_size', 50000.0), ('deterministic', False), ('num_networks', 7), ('num_elites', 5), ('real_ratio', 0.05), ('target_entropy', -3), ('max_model_t', None), ('separate_mean_var', True), ('penalty_learned_var', True), ('pool_load_path', '/home/ajc348/rds/hpc-work/mopo/rollouts/D3RLPY-PEP1.npy'), ('pool_load_max_size', 101000), ('rollout_length', 5), ('penalty_coeff', 1.0), ('n_epochs', 500), ('n_initial_exploration_steps', 5000), ('reparameterize', True), ('lr', 0.0003), ('target_update_interval', 1), ('store_extra_policy_info', False), ('action_prior', 'uniform')])), ('domain', 'HalfCheetah'), ('task', 'v2'), ('exp_name', 'halfcheetah_d3rlpy')]), 'replay_pool_params': {'type': 'SimpleReplayPool', 'kwargs': {'max_size': 1000000}}, 'sampler_params': {'type': 'SimpleSampler', 'kwargs': {'max_path_length': 1000, 'min_pool_size': 1000, 'batch_size': 256}}, 'run_params': {'seed': 1443, 'checkpoint_at_end': True, 'checkpoint_frequency': 10, 'checkpoint_replay_pool': False}, 'restore': None}",1947.0794517993927,0,30
110.7021484375,18.642810821533203,4.429722785949707,0.44891083240509033,0.36314448714256287,1.16848886013031,-0.6441940665245056,0.17190861701965332,-3.0492005348205566,2.806471586227417,0.3604491651058197,1.2834323644638062,0.21275830268859863,0.7393037676811218,-0.2688056254386902,-0.39670040130615236,-0.37128534514784817,-0.3750886654853821,0.34956372261047364,0.5286442894399113,4.8063216381957545,5.421031987310622,5.449823656419836,7.87119470888169,1000.0,1000,1000,0.0,5049.7470703125,5139.50927734375,4977.4228515625,43.27896499633789,1.6870908439159393e-06,5.040876567363739e-05,8.97692153789103,0.006886151619255543,20.56427865801379,0.0020753960125148296,0.005158751271665096,14.292791212443262,0,0,-inf,101000,0,5.0,0.11965973675251007,30,1000,31000,31000,False,,31,e70dcb782c5a4d21a122288b7f76519f,2022-05-19_14-08-50,1652965730,43.87824010848999,1990.9576919078827,19432,gpu-e-17,10.43.6.17,"{'environment_params': {'training': {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}}, 'evaluation': {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}}}, 'policy_params': {'type': 'GaussianPolicy', 'kwargs': {'hidden_layer_sizes': (256, 256), 'squash': True}}, 'Q_params': {'type': 'double_feedforward_Q_function', 'kwargs': {'hidden_layer_sizes': (256, 256)}}, 'algorithm_params': OrderedDict([('type', 'MOPO'), ('universe', 'gym'), ('log_dir', './ray_mopo/'), ('kwargs', OrderedDict([('epoch_length', 1000), ('train_every_n_steps', 1), ('n_train_repeat', 1), ('eval_render_mode', None), ('eval_n_episodes', 10), ('eval_deterministic', True), ('discount', 0.99), ('tau', 0.005), ('reward_scale', 1.0), ('model_train_freq', 1000), ('model_retain_epochs', 5), ('rollout_batch_size', 50000.0), ('deterministic', False), ('num_networks', 7), ('num_elites', 5), ('real_ratio', 0.05), ('target_entropy', -3), ('max_model_t', None), ('separate_mean_var', True), ('penalty_learned_var', True), ('pool_load_path', '/home/ajc348/rds/hpc-work/mopo/rollouts/D3RLPY-PEP1.npy'), ('pool_load_max_size', 101000), ('rollout_length', 5), ('penalty_coeff', 1.0), ('n_epochs', 500), ('n_initial_exploration_steps', 5000), ('reparameterize', True), ('lr', 0.0003), ('target_update_interval', 1), ('store_extra_policy_info', False), ('action_prior', 'uniform')])), ('domain', 'HalfCheetah'), ('task', 'v2'), ('exp_name', 'halfcheetah_d3rlpy')]), 'replay_pool_params': {'type': 'SimpleReplayPool', 'kwargs': {'max_size': 1000000}}, 'sampler_params': {'type': 'SimpleSampler', 'kwargs': {'max_path_length': 1000, 'min_pool_size': 1000, 'batch_size': 256}}, 'run_params': {'seed': 1443, 'checkpoint_at_end': True, 'checkpoint_frequency': 10, 'checkpoint_replay_pool': False}, 'restore': None}",1990.9576919078827,0,31
112.10972595214844,20.058090209960938,5.821758270263672,0.4577212929725647,0.357199102640152,1.17676842212677,-0.6286742687225342,0.17500941455364227,-2.928023338317871,3.023872137069702,0.3402293026447296,1.3002433776855469,0.19248951971530914,0.7427826523780823,-0.2732025933265686,-0.3910223484039307,-0.377203815459013,-0.37732526421546936,0.2909044516086578,0.6713668393604435,4.830294855582338,5.5664423534937315,5.570079983362932,7.95623638085757,1000.0,1000,1000,0.0,5189.23876953125,5327.130859375,5079.89599609375,75.83692169189453,1.7508864402770996e-06,3.51988710463047e-05,8.83197398390621,0.006981492042541504,20.579363918863237,0.002110863570123911,0.005115818697959185,14.248913840856403,0,0,-inf,101000,0,5.0,0.11965973675251007,31,1000,32000,32000,False,,32,e70dcb782c5a4d21a122288b7f76519f,2022-05-19_14-09-34,1652965774,43.70470905303955,2034.6624009609222,19432,gpu-e-17,10.43.6.17,"{'environment_params': {'training': {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}}, 'evaluation': {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}}}, 'policy_params': {'type': 'GaussianPolicy', 'kwargs': {'hidden_layer_sizes': (256, 256), 'squash': True}}, 'Q_params': {'type': 'double_feedforward_Q_function', 'kwargs': {'hidden_layer_sizes': (256, 256)}}, 'algorithm_params': OrderedDict([('type', 'MOPO'), ('universe', 'gym'), ('log_dir', './ray_mopo/'), ('kwargs', OrderedDict([('epoch_length', 1000), ('train_every_n_steps', 1), ('n_train_repeat', 1), ('eval_render_mode', None), ('eval_n_episodes', 10), ('eval_deterministic', True), ('discount', 0.99), ('tau', 0.005), ('reward_scale', 1.0), ('model_train_freq', 1000), ('model_retain_epochs', 5), ('rollout_batch_size', 50000.0), ('deterministic', False), ('num_networks', 7), ('num_elites', 5), ('real_ratio', 0.05), ('target_entropy', -3), ('max_model_t', None), ('separate_mean_var', True), ('penalty_learned_var', True), ('pool_load_path', '/home/ajc348/rds/hpc-work/mopo/rollouts/D3RLPY-PEP1.npy'), ('pool_load_max_size', 101000), ('rollout_length', 5), ('penalty_coeff', 1.0), ('n_epochs', 500), ('n_initial_exploration_steps', 5000), ('reparameterize', True), ('lr', 0.0003), ('target_update_interval', 1), ('store_extra_policy_info', False), ('action_prior', 'uniform')])), ('domain', 'HalfCheetah'), ('task', 'v2'), ('exp_name', 'halfcheetah_d3rlpy')]), 'replay_pool_params': {'type': 'SimpleReplayPool', 'kwargs': {'max_size': 1000000}}, 'sampler_params': {'type': 'SimpleSampler', 'kwargs': {'max_path_length': 1000, 'min_pool_size': 1000, 'batch_size': 256}}, 'run_params': {'seed': 1443, 'checkpoint_at_end': True, 'checkpoint_frequency': 10, 'checkpoint_replay_pool': False}, 'restore': None}",2034.6624009609222,0,32
114.72415161132812,19.219144821166992,3.303074359893799,0.45811882615089417,0.2835026979446411,1.189268708229065,-0.610037624835968,0.16981318593025208,-2.864405393600464,2.7487783432006836,0.2935987412929535,1.3042984008789062,0.1698407381772995,0.7461346387863159,-0.2896714186668396,-0.38216782808303834,-0.36229915427804,-0.3629877281188965,0.288630006313324,0.6266880213424781,4.899965894842467,5.5196418745142,5.546493069077503,7.878621149527346,1000.0,1000,1000,0.0,5157.3427734375,5252.1796875,5030.9931640625,67.20552825927734,1.6777776181697845e-06,3.727199509739876e-05,8.834211943205446,0.007001037709414959,20.512294897809625,0.002076024655252695,0.005131841637194157,14.312788968905807,0,0,-inf,101000,0,5.0,0.11965973675251007,32,1000,33000,33000,False,,33,e70dcb782c5a4d21a122288b7f76519f,2022-05-19_14-10-18,1652965818,43.70376968383789,2078.36617064476,19432,gpu-e-17,10.43.6.17,"{'environment_params': {'training': {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}}, 'evaluation': {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}}}, 'policy_params': {'type': 'GaussianPolicy', 'kwargs': {'hidden_layer_sizes': (256, 256), 'squash': True}}, 'Q_params': {'type': 'double_feedforward_Q_function', 'kwargs': {'hidden_layer_sizes': (256, 256)}}, 'algorithm_params': OrderedDict([('type', 'MOPO'), ('universe', 'gym'), ('log_dir', './ray_mopo/'), ('kwargs', OrderedDict([('epoch_length', 1000), ('train_every_n_steps', 1), ('n_train_repeat', 1), ('eval_render_mode', None), ('eval_n_episodes', 10), ('eval_deterministic', True), ('discount', 0.99), ('tau', 0.005), ('reward_scale', 1.0), ('model_train_freq', 1000), ('model_retain_epochs', 5), ('rollout_batch_size', 50000.0), ('deterministic', False), ('num_networks', 7), ('num_elites', 5), ('real_ratio', 0.05), ('target_entropy', -3), ('max_model_t', None), ('separate_mean_var', True), ('penalty_learned_var', True), ('pool_load_path', '/home/ajc348/rds/hpc-work/mopo/rollouts/D3RLPY-PEP1.npy'), ('pool_load_max_size', 101000), ('rollout_length', 5), ('penalty_coeff', 1.0), ('n_epochs', 500), ('n_initial_exploration_steps', 5000), ('reparameterize', True), ('lr', 0.0003), ('target_update_interval', 1), ('store_extra_policy_info', False), ('action_prior', 'uniform')])), ('domain', 'HalfCheetah'), ('task', 'v2'), ('exp_name', 'halfcheetah_d3rlpy')]), 'replay_pool_params': {'type': 'SimpleReplayPool', 'kwargs': {'max_size': 1000000}}, 'sampler_params': {'type': 'SimpleSampler', 'kwargs': {'max_path_length': 1000, 'min_pool_size': 1000, 'batch_size': 256}}, 'run_params': {'seed': 1443, 'checkpoint_at_end': True, 'checkpoint_frequency': 10, 'checkpoint_replay_pool': False}, 'restore': None}",2078.36617064476,0,33
117.90553283691406,18.580541610717773,3.8454108238220215,0.45531579852104187,0.32482969760894775,1.1993616819381714,-0.6368768811225891,0.1918223351240158,-3.365595817565918,2.640402317047119,0.34193167090415955,1.313962459564209,0.19549135863780975,0.753037691116333,-0.2837661385536194,-0.4069659614562989,-0.3732872281610966,-0.3747432589530945,0.3453815031051636,0.523688659032026,4.920810980932856,5.6922140711563385,5.716616188458878,8.139157905091256,1000.0,1000,1000,0.0,5318.92724609375,5430.1220703125,5218.3076171875,66.52448272705078,1.78581103682518e-06,5.415920168161392e-05,8.878759670071304,0.007535851094871759,20.582281534094363,0.0021019447594881058,0.005147837568074465,14.33027333393693,0,0,-inf,101000,0,5.0,0.11965973675251007,33,1000,34000,34000,False,,34,e70dcb782c5a4d21a122288b7f76519f,2022-05-19_14-11-02,1652965862,43.8364794254303,2122.2026500701904,19432,gpu-e-17,10.43.6.17,"{'environment_params': {'training': {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}}, 'evaluation': {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}}}, 'policy_params': {'type': 'GaussianPolicy', 'kwargs': {'hidden_layer_sizes': (256, 256), 'squash': True}}, 'Q_params': {'type': 'double_feedforward_Q_function', 'kwargs': {'hidden_layer_sizes': (256, 256)}}, 'algorithm_params': OrderedDict([('type', 'MOPO'), ('universe', 'gym'), ('log_dir', './ray_mopo/'), ('kwargs', OrderedDict([('epoch_length', 1000), ('train_every_n_steps', 1), ('n_train_repeat', 1), ('eval_render_mode', None), ('eval_n_episodes', 10), ('eval_deterministic', True), ('discount', 0.99), ('tau', 0.005), ('reward_scale', 1.0), ('model_train_freq', 1000), ('model_retain_epochs', 5), ('rollout_batch_size', 50000.0), ('deterministic', False), ('num_networks', 7), ('num_elites', 5), ('real_ratio', 0.05), ('target_entropy', -3), ('max_model_t', None), ('separate_mean_var', True), ('penalty_learned_var', True), ('pool_load_path', '/home/ajc348/rds/hpc-work/mopo/rollouts/D3RLPY-PEP1.npy'), ('pool_load_max_size', 101000), ('rollout_length', 5), ('penalty_coeff', 1.0), ('n_epochs', 500), ('n_initial_exploration_steps', 5000), ('reparameterize', True), ('lr', 0.0003), ('target_update_interval', 1), ('store_extra_policy_info', False), ('action_prior', 'uniform')])), ('domain', 'HalfCheetah'), ('task', 'v2'), ('exp_name', 'halfcheetah_d3rlpy')]), 'replay_pool_params': {'type': 'SimpleReplayPool', 'kwargs': {'max_size': 1000000}}, 'sampler_params': {'type': 'SimpleSampler', 'kwargs': {'max_path_length': 1000, 'min_pool_size': 1000, 'batch_size': 256}}, 'run_params': {'seed': 1443, 'checkpoint_at_end': True, 'checkpoint_frequency': 10, 'checkpoint_replay_pool': False}, 'restore': None}",2122.2026500701904,0,34
116.9580078125,18.12832260131836,4.087861061096191,0.46116602420806885,0.2549809515476227,1.2173855304718018,-0.6362349390983582,0.1777494102716446,-3.4938254356384277,2.705253839492798,0.2583453357219696,1.3550963401794434,0.14914847910404205,0.7663233280181885,-0.27182004928588865,-0.4249751949310303,-0.37936148694992067,-0.37881139755249027,0.31759037017822267,0.5253585726261364,4.813095971350663,5.603920193662576,5.607006930358595,8.167415307528575,1000.0,1000,1000,0.0,5224.55859375,5344.1708984375,5074.9169921875,78.0423583984375,1.6940757632255554e-06,3.75811941921711e-05,8.840436234138906,0.006976692005991936,20.552419933024794,0.002084702253341675,0.005081295035779476,14.334048856049776,0,0,-inf,101000,0,5.0,0.11965973675251007,34,1000,35000,35000,False,,35,e70dcb782c5a4d21a122288b7f76519f,2022-05-19_14-11-45,1652965905,43.77112054824829,2165.9737706184387,19432,gpu-e-17,10.43.6.17,"{'environment_params': {'training': {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}}, 'evaluation': {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}}}, 'policy_params': {'type': 'GaussianPolicy', 'kwargs': {'hidden_layer_sizes': (256, 256), 'squash': True}}, 'Q_params': {'type': 'double_feedforward_Q_function', 'kwargs': {'hidden_layer_sizes': (256, 256)}}, 'algorithm_params': OrderedDict([('type', 'MOPO'), ('universe', 'gym'), ('log_dir', './ray_mopo/'), ('kwargs', OrderedDict([('epoch_length', 1000), ('train_every_n_steps', 1), ('n_train_repeat', 1), ('eval_render_mode', None), ('eval_n_episodes', 10), ('eval_deterministic', True), ('discount', 0.99), ('tau', 0.005), ('reward_scale', 1.0), ('model_train_freq', 1000), ('model_retain_epochs', 5), ('rollout_batch_size', 50000.0), ('deterministic', False), ('num_networks', 7), ('num_elites', 5), ('real_ratio', 0.05), ('target_entropy', -3), ('max_model_t', None), ('separate_mean_var', True), ('penalty_learned_var', True), ('pool_load_path', '/home/ajc348/rds/hpc-work/mopo/rollouts/D3RLPY-PEP1.npy'), ('pool_load_max_size', 101000), ('rollout_length', 5), ('penalty_coeff', 1.0), ('n_epochs', 500), ('n_initial_exploration_steps', 5000), ('reparameterize', True), ('lr', 0.0003), ('target_update_interval', 1), ('store_extra_policy_info', False), ('action_prior', 'uniform')])), ('domain', 'HalfCheetah'), ('task', 'v2'), ('exp_name', 'halfcheetah_d3rlpy')]), 'replay_pool_params': {'type': 'SimpleReplayPool', 'kwargs': {'max_size': 1000000}}, 'sampler_params': {'type': 'SimpleSampler', 'kwargs': {'max_path_length': 1000, 'min_pool_size': 1000, 'batch_size': 256}}, 'run_params': {'seed': 1443, 'checkpoint_at_end': True, 'checkpoint_frequency': 10, 'checkpoint_replay_pool': False}, 'restore': None}",2165.9737706184387,0,35
115.71959686279297,19.28940200805664,4.61833381652832,0.461384654045105,0.308645099401474,1.22126305103302,-0.6254450082778931,0.1628926396369934,-3.100175380706787,2.9919111728668213,0.29904213547706604,1.3304858207702637,0.17400769889354706,0.7520775198936462,-0.2978261399269104,-0.43354053497314454,-0.39062299022912983,-0.39078873872756964,0.3133187305927277,0.5583175948061064,4.851364134622713,5.625549700226257,5.615629423110537,8.28319665263335,1000.0,1000,1000,0.0,5234.9267578125,5341.9140625,5136.33740234375,56.87691116333008,1.6177073121070862e-06,3.393273800611496e-05,8.861727969255298,0.00713206734508276,20.61825671000406,0.0020827618427574635,0.005119231063872576,14.309177512768656,0,0,-inf,101000,0,5.0,0.11965973675251007,35,1000,36000,36000,False,,36,e70dcb782c5a4d21a122288b7f76519f,2022-05-19_14-12-29,1652965949,43.83347749710083,2209.8072481155396,19432,gpu-e-17,10.43.6.17,"{'environment_params': {'training': {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}}, 'evaluation': {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}}}, 'policy_params': {'type': 'GaussianPolicy', 'kwargs': {'hidden_layer_sizes': (256, 256), 'squash': True}}, 'Q_params': {'type': 'double_feedforward_Q_function', 'kwargs': {'hidden_layer_sizes': (256, 256)}}, 'algorithm_params': OrderedDict([('type', 'MOPO'), ('universe', 'gym'), ('log_dir', './ray_mopo/'), ('kwargs', OrderedDict([('epoch_length', 1000), ('train_every_n_steps', 1), ('n_train_repeat', 1), ('eval_render_mode', None), ('eval_n_episodes', 10), ('eval_deterministic', True), ('discount', 0.99), ('tau', 0.005), ('reward_scale', 1.0), ('model_train_freq', 1000), ('model_retain_epochs', 5), ('rollout_batch_size', 50000.0), ('deterministic', False), ('num_networks', 7), ('num_elites', 5), ('real_ratio', 0.05), ('target_entropy', -3), ('max_model_t', None), ('separate_mean_var', True), ('penalty_learned_var', True), ('pool_load_path', '/home/ajc348/rds/hpc-work/mopo/rollouts/D3RLPY-PEP1.npy'), ('pool_load_max_size', 101000), ('rollout_length', 5), ('penalty_coeff', 1.0), ('n_epochs', 500), ('n_initial_exploration_steps', 5000), ('reparameterize', True), ('lr', 0.0003), ('target_update_interval', 1), ('store_extra_policy_info', False), ('action_prior', 'uniform')])), ('domain', 'HalfCheetah'), ('task', 'v2'), ('exp_name', 'halfcheetah_d3rlpy')]), 'replay_pool_params': {'type': 'SimpleReplayPool', 'kwargs': {'max_size': 1000000}}, 'sampler_params': {'type': 'SimpleSampler', 'kwargs': {'max_path_length': 1000, 'min_pool_size': 1000, 'batch_size': 256}}, 'run_params': {'seed': 1443, 'checkpoint_at_end': True, 'checkpoint_frequency': 10, 'checkpoint_replay_pool': False}, 'restore': None}",2209.8072481155396,0,36
121.58982849121094,15.844569206237793,4.575412750244141,0.4628840684890747,0.3178081512451172,1.2061249017715454,-0.6335294246673584,0.18733948469161987,-3.40154767036438,3.1188790798187256,0.3232080042362213,1.3515725135803223,0.18099445104599,0.7573452591896057,-0.3040074157714844,-0.4483228635787964,-0.3884691611647606,-0.38856127023696907,0.3441976130008698,0.5546523607585533,4.872626211569695,5.6166441960030555,5.586346485318882,8.066240991231945,1000.0,1000,1000,0.0,5228.1748046875,5314.7001953125,5108.85400390625,56.154354095458984,1.7308630049228668e-06,3.471178933978081e-05,8.811585764866322,0.007028962951153517,20.68898956477642,0.002079515717923641,0.005215959623456001,14.306337137706578,0,0,-inf,101000,0,5.0,0.11965973675251007,36,1000,37000,37000,False,,37,e70dcb782c5a4d21a122288b7f76519f,2022-05-19_14-13-13,1652965993,43.85141921043396,2253.6586673259735,19432,gpu-e-17,10.43.6.17,"{'environment_params': {'training': {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}}, 'evaluation': {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}}}, 'policy_params': {'type': 'GaussianPolicy', 'kwargs': {'hidden_layer_sizes': (256, 256), 'squash': True}}, 'Q_params': {'type': 'double_feedforward_Q_function', 'kwargs': {'hidden_layer_sizes': (256, 256)}}, 'algorithm_params': OrderedDict([('type', 'MOPO'), ('universe', 'gym'), ('log_dir', './ray_mopo/'), ('kwargs', OrderedDict([('epoch_length', 1000), ('train_every_n_steps', 1), ('n_train_repeat', 1), ('eval_render_mode', None), ('eval_n_episodes', 10), ('eval_deterministic', True), ('discount', 0.99), ('tau', 0.005), ('reward_scale', 1.0), ('model_train_freq', 1000), ('model_retain_epochs', 5), ('rollout_batch_size', 50000.0), ('deterministic', False), ('num_networks', 7), ('num_elites', 5), ('real_ratio', 0.05), ('target_entropy', -3), ('max_model_t', None), ('separate_mean_var', True), ('penalty_learned_var', True), ('pool_load_path', '/home/ajc348/rds/hpc-work/mopo/rollouts/D3RLPY-PEP1.npy'), ('pool_load_max_size', 101000), ('rollout_length', 5), ('penalty_coeff', 1.0), ('n_epochs', 500), ('n_initial_exploration_steps', 5000), ('reparameterize', True), ('lr', 0.0003), ('target_update_interval', 1), ('store_extra_policy_info', False), ('action_prior', 'uniform')])), ('domain', 'HalfCheetah'), ('task', 'v2'), ('exp_name', 'halfcheetah_d3rlpy')]), 'replay_pool_params': {'type': 'SimpleReplayPool', 'kwargs': {'max_size': 1000000}}, 'sampler_params': {'type': 'SimpleSampler', 'kwargs': {'max_path_length': 1000, 'min_pool_size': 1000, 'batch_size': 256}}, 'run_params': {'seed': 1443, 'checkpoint_at_end': True, 'checkpoint_frequency': 10, 'checkpoint_replay_pool': False}, 'restore': None}",2253.6586673259735,0,37
121.67279052734375,20.23064613342285,3.86905837059021,0.4692281186580658,0.3051551580429077,1.1802781820297241,-0.6214860081672668,0.18191935122013092,-2.945066452026367,3.156146764755249,0.28201231360435486,1.3051724433898926,0.1632920503616333,0.7460638880729675,-0.2806436634063721,-0.36730997085571293,-0.36264588919878005,-0.3630448031425476,0.3133486104011536,0.5039436929079647,4.920408710813263,5.460832521096748,5.476711438270875,7.743932497245301,1000.0,1000,1000,0.0,5098.18701171875,5148.92529296875,4980.3115234375,50.849212646484375,1.7499551177024841e-06,3.518024459481239e-05,8.899886571802199,0.0070001971907913685,20.567751815076917,0.0020962711423635483,0.005086117424070835,14.281914991792291,0,0,-inf,101000,0,5.0,0.11965973675251007,37,1000,38000,38000,False,,38,e70dcb782c5a4d21a122288b7f76519f,2022-05-19_14-13-57,1652966037,43.794097900390625,2297.452765226364,19432,gpu-e-17,10.43.6.17,"{'environment_params': {'training': {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}}, 'evaluation': {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}}}, 'policy_params': {'type': 'GaussianPolicy', 'kwargs': {'hidden_layer_sizes': (256, 256), 'squash': True}}, 'Q_params': {'type': 'double_feedforward_Q_function', 'kwargs': {'hidden_layer_sizes': (256, 256)}}, 'algorithm_params': OrderedDict([('type', 'MOPO'), ('universe', 'gym'), ('log_dir', './ray_mopo/'), ('kwargs', OrderedDict([('epoch_length', 1000), ('train_every_n_steps', 1), ('n_train_repeat', 1), ('eval_render_mode', None), ('eval_n_episodes', 10), ('eval_deterministic', True), ('discount', 0.99), ('tau', 0.005), ('reward_scale', 1.0), ('model_train_freq', 1000), ('model_retain_epochs', 5), ('rollout_batch_size', 50000.0), ('deterministic', False), ('num_networks', 7), ('num_elites', 5), ('real_ratio', 0.05), ('target_entropy', -3), ('max_model_t', None), ('separate_mean_var', True), ('penalty_learned_var', True), ('pool_load_path', '/home/ajc348/rds/hpc-work/mopo/rollouts/D3RLPY-PEP1.npy'), ('pool_load_max_size', 101000), ('rollout_length', 5), ('penalty_coeff', 1.0), ('n_epochs', 500), ('n_initial_exploration_steps', 5000), ('reparameterize', True), ('lr', 0.0003), ('target_update_interval', 1), ('store_extra_policy_info', False), ('action_prior', 'uniform')])), ('domain', 'HalfCheetah'), ('task', 'v2'), ('exp_name', 'halfcheetah_d3rlpy')]), 'replay_pool_params': {'type': 'SimpleReplayPool', 'kwargs': {'max_size': 1000000}}, 'sampler_params': {'type': 'SimpleSampler', 'kwargs': {'max_path_length': 1000, 'min_pool_size': 1000, 'batch_size': 256}}, 'run_params': {'seed': 1443, 'checkpoint_at_end': True, 'checkpoint_frequency': 10, 'checkpoint_replay_pool': False}, 'restore': None}",2297.452765226364,0,38
122.31517028808594,20.256160736083984,4.256765842437744,0.4745740294456482,0.2741442024707794,1.194799542427063,-0.6236900687217712,0.18439848721027374,-2.5816280841827393,2.7140204906463623,0.24180574715137482,1.2948873043060303,0.14616592228412628,0.741604208946228,-0.26980419158935554,-0.3830375623703003,-0.37826386101841936,-0.3805057775974273,0.33936756610870356,0.5171076968757256,5.061801818317349,5.6353611618098585,5.6325449278713124,8.192012126921682,1000.0,1000,1000,0.0,5257.09716796875,5369.4853515625,5112.76025390625,71.76966094970703,1.7601996660232544e-06,3.5521574318408966e-05,8.875831104815006,0.006905783899128437,20.527652968652546,0.0020925230346620083,0.005114562809467316,14.285117191728204,0,0,-inf,101000,0,5.0,0.11965973675251007,38,1000,39000,39000,False,,39,e70dcb782c5a4d21a122288b7f76519f,2022-05-19_14-14-41,1652966081,43.73299956321716,2341.1857647895813,19432,gpu-e-17,10.43.6.17,"{'environment_params': {'training': {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}}, 'evaluation': {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}}}, 'policy_params': {'type': 'GaussianPolicy', 'kwargs': {'hidden_layer_sizes': (256, 256), 'squash': True}}, 'Q_params': {'type': 'double_feedforward_Q_function', 'kwargs': {'hidden_layer_sizes': (256, 256)}}, 'algorithm_params': OrderedDict([('type', 'MOPO'), ('universe', 'gym'), ('log_dir', './ray_mopo/'), ('kwargs', OrderedDict([('epoch_length', 1000), ('train_every_n_steps', 1), ('n_train_repeat', 1), ('eval_render_mode', None), ('eval_n_episodes', 10), ('eval_deterministic', True), ('discount', 0.99), ('tau', 0.005), ('reward_scale', 1.0), ('model_train_freq', 1000), ('model_retain_epochs', 5), ('rollout_batch_size', 50000.0), ('deterministic', False), ('num_networks', 7), ('num_elites', 5), ('real_ratio', 0.05), ('target_entropy', -3), ('max_model_t', None), ('separate_mean_var', True), ('penalty_learned_var', True), ('pool_load_path', '/home/ajc348/rds/hpc-work/mopo/rollouts/D3RLPY-PEP1.npy'), ('pool_load_max_size', 101000), ('rollout_length', 5), ('penalty_coeff', 1.0), ('n_epochs', 500), ('n_initial_exploration_steps', 5000), ('reparameterize', True), ('lr', 0.0003), ('target_update_interval', 1), ('store_extra_policy_info', False), ('action_prior', 'uniform')])), ('domain', 'HalfCheetah'), ('task', 'v2'), ('exp_name', 'halfcheetah_d3rlpy')]), 'replay_pool_params': {'type': 'SimpleReplayPool', 'kwargs': {'max_size': 1000000}}, 'sampler_params': {'type': 'SimpleSampler', 'kwargs': {'max_path_length': 1000, 'min_pool_size': 1000, 'batch_size': 256}}, 'run_params': {'seed': 1443, 'checkpoint_at_end': True, 'checkpoint_frequency': 10, 'checkpoint_replay_pool': False}, 'restore': None}",2341.1857647895813,0,39
123.97108459472656,18.790931701660156,4.194840431213379,0.4779067933559418,0.23899374902248383,1.1837643384933472,-0.5903651714324951,0.17824657261371613,-2.858293294906616,2.725574254989624,0.22763828933238983,1.3246688842773438,0.13851076364517212,0.7556249499320984,-0.28770287752151485,-0.39511544704437257,-0.37330291702151297,-0.37532190561294554,0.3065042543411255,0.6424228984507578,4.965209699028264,5.651425694323495,5.661328961299745,8.146863679517315,1000.0,1000,1000,0.0,5278.12255859375,5362.5283203125,5194.2958984375,50.480133056640625,1.6069971024990082e-06,3.642542287707329e-05,8.878456236794591,0.006872206926345825,20.628538405988365,0.002117759082466364,0.005161303095519543,14.319128543138504,0,0,-inf,101000,0,5.0,0.11965973675251007,39,1000,40000,40000,False,,40,e70dcb782c5a4d21a122288b7f76519f,2022-05-19_14-15-24,1652966124,43.872196197509766,2385.057960987091,19432,gpu-e-17,10.43.6.17,"{'environment_params': {'training': {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}}, 'evaluation': {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}}}, 'policy_params': {'type': 'GaussianPolicy', 'kwargs': {'hidden_layer_sizes': (256, 256), 'squash': True}}, 'Q_params': {'type': 'double_feedforward_Q_function', 'kwargs': {'hidden_layer_sizes': (256, 256)}}, 'algorithm_params': OrderedDict([('type', 'MOPO'), ('universe', 'gym'), ('log_dir', './ray_mopo/'), ('kwargs', OrderedDict([('epoch_length', 1000), ('train_every_n_steps', 1), ('n_train_repeat', 1), ('eval_render_mode', None), ('eval_n_episodes', 10), ('eval_deterministic', True), ('discount', 0.99), ('tau', 0.005), ('reward_scale', 1.0), ('model_train_freq', 1000), ('model_retain_epochs', 5), ('rollout_batch_size', 50000.0), ('deterministic', False), ('num_networks', 7), ('num_elites', 5), ('real_ratio', 0.05), ('target_entropy', -3), ('max_model_t', None), ('separate_mean_var', True), ('penalty_learned_var', True), ('pool_load_path', '/home/ajc348/rds/hpc-work/mopo/rollouts/D3RLPY-PEP1.npy'), ('pool_load_max_size', 101000), ('rollout_length', 5), ('penalty_coeff', 1.0), ('n_epochs', 500), ('n_initial_exploration_steps', 5000), ('reparameterize', True), ('lr', 0.0003), ('target_update_interval', 1), ('store_extra_policy_info', False), ('action_prior', 'uniform')])), ('domain', 'HalfCheetah'), ('task', 'v2'), ('exp_name', 'halfcheetah_d3rlpy')]), 'replay_pool_params': {'type': 'SimpleReplayPool', 'kwargs': {'max_size': 1000000}}, 'sampler_params': {'type': 'SimpleSampler', 'kwargs': {'max_path_length': 1000, 'min_pool_size': 1000, 'batch_size': 256}}, 'run_params': {'seed': 1443, 'checkpoint_at_end': True, 'checkpoint_frequency': 10, 'checkpoint_replay_pool': False}, 'restore': None}",2385.057960987091,0,40
124.25381469726562,22.91628074645996,4.5044450759887695,0.4771115481853485,0.3040032684803009,1.1892869472503662,-0.6131812930107117,0.1872733235359192,-2.8965647220611572,2.7864019870758057,0.30725517868995667,1.2987747192382812,0.17592917382717133,0.7461897134780884,-0.27898188829422,-0.39485303878784184,-0.368963011379242,-0.37392916679382326,0.31204795837402344,0.5302651175132416,5.149646735373722,5.622274528867477,5.627464391156272,8.228381612369695,1000.0,1000,1000,0.0,5253.3115234375,5329.669921875,5203.2021484375,37.7779655456543,1.7010606825351715e-06,5.111983045935631e-05,8.97191681759432,0.00711738271638751,20.51579925371334,0.0020756027661263943,0.005188062321394682,14.189321051817387,0,0,-inf,101000,0,5.0,0.11965973675251007,40,1000,41000,41000,False,,41,e70dcb782c5a4d21a122288b7f76519f,2022-05-19_14-16-09,1652966169,43.72219204902649,2428.7801530361176,19432,gpu-e-17,10.43.6.17,"{'environment_params': {'training': {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}}, 'evaluation': {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}}}, 'policy_params': {'type': 'GaussianPolicy', 'kwargs': {'hidden_layer_sizes': (256, 256), 'squash': True}}, 'Q_params': {'type': 'double_feedforward_Q_function', 'kwargs': {'hidden_layer_sizes': (256, 256)}}, 'algorithm_params': OrderedDict([('type', 'MOPO'), ('universe', 'gym'), ('log_dir', './ray_mopo/'), ('kwargs', OrderedDict([('epoch_length', 1000), ('train_every_n_steps', 1), ('n_train_repeat', 1), ('eval_render_mode', None), ('eval_n_episodes', 10), ('eval_deterministic', True), ('discount', 0.99), ('tau', 0.005), ('reward_scale', 1.0), ('model_train_freq', 1000), ('model_retain_epochs', 5), ('rollout_batch_size', 50000.0), ('deterministic', False), ('num_networks', 7), ('num_elites', 5), ('real_ratio', 0.05), ('target_entropy', -3), ('max_model_t', None), ('separate_mean_var', True), ('penalty_learned_var', True), ('pool_load_path', '/home/ajc348/rds/hpc-work/mopo/rollouts/D3RLPY-PEP1.npy'), ('pool_load_max_size', 101000), ('rollout_length', 5), ('penalty_coeff', 1.0), ('n_epochs', 500), ('n_initial_exploration_steps', 5000), ('reparameterize', True), ('lr', 0.0003), ('target_update_interval', 1), ('store_extra_policy_info', False), ('action_prior', 'uniform')])), ('domain', 'HalfCheetah'), ('task', 'v2'), ('exp_name', 'halfcheetah_d3rlpy')]), 'replay_pool_params': {'type': 'SimpleReplayPool', 'kwargs': {'max_size': 1000000}}, 'sampler_params': {'type': 'SimpleSampler', 'kwargs': {'max_path_length': 1000, 'min_pool_size': 1000, 'batch_size': 256}}, 'run_params': {'seed': 1443, 'checkpoint_at_end': True, 'checkpoint_frequency': 10, 'checkpoint_replay_pool': False}, 'restore': None}",2428.7801530361176,0,41
125.60527038574219,19.10115623474121,3.5169942378997803,0.47596076130867004,0.2787690758705139,1.199508786201477,-0.6177809834480286,0.18592475354671478,-2.975259304046631,2.810694932937622,0.275034636259079,1.3236455917358398,0.15612095594406128,0.7499130368232727,-0.291483850479126,-0.4101654148101807,-0.37178373947978016,-0.3733315491676331,0.3303962349891663,0.6403969780197498,4.858934613244855,5.624546605319038,5.628278256656172,8.13745012373639,1000.0,1000,1000,0.0,5252.76318359375,5320.580078125,5134.89892578125,54.98247146606445,1.666136085987091e-06,3.507407382130623e-05,8.943891112226993,0.0070890034548938274,20.60384744592011,0.002094028051942587,0.005167656112462282,14.249080918263644,0,0,-inf,101000,0,5.0,0.11965973675251007,41,1000,42000,42000,False,,42,e70dcb782c5a4d21a122288b7f76519f,2022-05-19_14-16-53,1652966213,43.84157752990723,2472.621730566025,19432,gpu-e-17,10.43.6.17,"{'environment_params': {'training': {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}}, 'evaluation': {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}}}, 'policy_params': {'type': 'GaussianPolicy', 'kwargs': {'hidden_layer_sizes': (256, 256), 'squash': True}}, 'Q_params': {'type': 'double_feedforward_Q_function', 'kwargs': {'hidden_layer_sizes': (256, 256)}}, 'algorithm_params': OrderedDict([('type', 'MOPO'), ('universe', 'gym'), ('log_dir', './ray_mopo/'), ('kwargs', OrderedDict([('epoch_length', 1000), ('train_every_n_steps', 1), ('n_train_repeat', 1), ('eval_render_mode', None), ('eval_n_episodes', 10), ('eval_deterministic', True), ('discount', 0.99), ('tau', 0.005), ('reward_scale', 1.0), ('model_train_freq', 1000), ('model_retain_epochs', 5), ('rollout_batch_size', 50000.0), ('deterministic', False), ('num_networks', 7), ('num_elites', 5), ('real_ratio', 0.05), ('target_entropy', -3), ('max_model_t', None), ('separate_mean_var', True), ('penalty_learned_var', True), ('pool_load_path', '/home/ajc348/rds/hpc-work/mopo/rollouts/D3RLPY-PEP1.npy'), ('pool_load_max_size', 101000), ('rollout_length', 5), ('penalty_coeff', 1.0), ('n_epochs', 500), ('n_initial_exploration_steps', 5000), ('reparameterize', True), ('lr', 0.0003), ('target_update_interval', 1), ('store_extra_policy_info', False), ('action_prior', 'uniform')])), ('domain', 'HalfCheetah'), ('task', 'v2'), ('exp_name', 'halfcheetah_d3rlpy')]), 'replay_pool_params': {'type': 'SimpleReplayPool', 'kwargs': {'max_size': 1000000}}, 'sampler_params': {'type': 'SimpleSampler', 'kwargs': {'max_path_length': 1000, 'min_pool_size': 1000, 'batch_size': 256}}, 'run_params': {'seed': 1443, 'checkpoint_at_end': True, 'checkpoint_frequency': 10, 'checkpoint_replay_pool': False}, 'restore': None}",2472.621730566025,0,42
127.21253204345703,21.830894470214844,4.299947738647461,0.4743153154850006,0.335021048784256,1.2262611389160156,-0.6256517767906189,0.19938001036643982,-3.5487937927246094,2.9295663833618164,0.3348977863788605,1.3595829010009766,0.19083362817764282,0.757138729095459,-0.29443361997604367,-0.438653872013092,-0.38908875463604925,-0.3865800213813782,0.32287436246871953,0.5988151282838527,5.144220052846322,5.817693853560563,5.8065855270420315,8.366876963960763,1000.0,1000,1000,0.0,5428.60546875,5471.49853515625,5347.724609375,36.367767333984375,1.6549602150917053e-06,3.724219277501106e-05,8.856196761131287,0.0070283240638673306,20.545552261173725,0.0020663244649767876,0.005122154485434294,14.235452807042748,0,0,-inf,101000,0,5.0,0.11965973675251007,42,1000,43000,43000,False,,43,e70dcb782c5a4d21a122288b7f76519f,2022-05-19_14-17-36,1652966256,43.681395292282104,2516.303125858307,19432,gpu-e-17,10.43.6.17,"{'environment_params': {'training': {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}}, 'evaluation': {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}}}, 'policy_params': {'type': 'GaussianPolicy', 'kwargs': {'hidden_layer_sizes': (256, 256), 'squash': True}}, 'Q_params': {'type': 'double_feedforward_Q_function', 'kwargs': {'hidden_layer_sizes': (256, 256)}}, 'algorithm_params': OrderedDict([('type', 'MOPO'), ('universe', 'gym'), ('log_dir', './ray_mopo/'), ('kwargs', OrderedDict([('epoch_length', 1000), ('train_every_n_steps', 1), ('n_train_repeat', 1), ('eval_render_mode', None), ('eval_n_episodes', 10), ('eval_deterministic', True), ('discount', 0.99), ('tau', 0.005), ('reward_scale', 1.0), ('model_train_freq', 1000), ('model_retain_epochs', 5), ('rollout_batch_size', 50000.0), ('deterministic', False), ('num_networks', 7), ('num_elites', 5), ('real_ratio', 0.05), ('target_entropy', -3), ('max_model_t', None), ('separate_mean_var', True), ('penalty_learned_var', True), ('pool_load_path', '/home/ajc348/rds/hpc-work/mopo/rollouts/D3RLPY-PEP1.npy'), ('pool_load_max_size', 101000), ('rollout_length', 5), ('penalty_coeff', 1.0), ('n_epochs', 500), ('n_initial_exploration_steps', 5000), ('reparameterize', True), ('lr', 0.0003), ('target_update_interval', 1), ('store_extra_policy_info', False), ('action_prior', 'uniform')])), ('domain', 'HalfCheetah'), ('task', 'v2'), ('exp_name', 'halfcheetah_d3rlpy')]), 'replay_pool_params': {'type': 'SimpleReplayPool', 'kwargs': {'max_size': 1000000}}, 'sampler_params': {'type': 'SimpleSampler', 'kwargs': {'max_path_length': 1000, 'min_pool_size': 1000, 'batch_size': 256}}, 'run_params': {'seed': 1443, 'checkpoint_at_end': True, 'checkpoint_frequency': 10, 'checkpoint_replay_pool': False}, 'restore': None}",2516.303125858307,0,43
129.4830322265625,17.92919158935547,3.356569290161133,0.48542124032974243,0.30613014101982117,1.1849123239517212,-0.630901575088501,0.20223736763000488,-3.2551686763763428,2.8325862884521484,0.29289475083351135,1.3172967433929443,0.1672554612159729,0.752723217010498,-0.25662522554397577,-0.3878714728355408,-0.36231234902024273,-0.36373539924621584,0.33173163175582887,0.6317476023547121,5.136122069015528,5.669890627632149,5.670419252873817,8.082076894748306,1000.0,1000,1000,0.0,5307.578125,5433.34423828125,5191.5615234375,81.59620666503906,1.6489066183567047e-06,3.5244040191173553e-05,8.807817133143544,0.006842838134616613,20.548874999862164,0.0020681326277554035,0.005069091450423002,14.305235527921468,0,0,-inf,101000,0,5.0,0.11965973675251007,43,1000,44000,44000,False,,44,e70dcb782c5a4d21a122288b7f76519f,2022-05-19_14-18-20,1652966300,43.70595192909241,2560.0090777873993,19432,gpu-e-17,10.43.6.17,"{'environment_params': {'training': {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}}, 'evaluation': {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}}}, 'policy_params': {'type': 'GaussianPolicy', 'kwargs': {'hidden_layer_sizes': (256, 256), 'squash': True}}, 'Q_params': {'type': 'double_feedforward_Q_function', 'kwargs': {'hidden_layer_sizes': (256, 256)}}, 'algorithm_params': OrderedDict([('type', 'MOPO'), ('universe', 'gym'), ('log_dir', './ray_mopo/'), ('kwargs', OrderedDict([('epoch_length', 1000), ('train_every_n_steps', 1), ('n_train_repeat', 1), ('eval_render_mode', None), ('eval_n_episodes', 10), ('eval_deterministic', True), ('discount', 0.99), ('tau', 0.005), ('reward_scale', 1.0), ('model_train_freq', 1000), ('model_retain_epochs', 5), ('rollout_batch_size', 50000.0), ('deterministic', False), ('num_networks', 7), ('num_elites', 5), ('real_ratio', 0.05), ('target_entropy', -3), ('max_model_t', None), ('separate_mean_var', True), ('penalty_learned_var', True), ('pool_load_path', '/home/ajc348/rds/hpc-work/mopo/rollouts/D3RLPY-PEP1.npy'), ('pool_load_max_size', 101000), ('rollout_length', 5), ('penalty_coeff', 1.0), ('n_epochs', 500), ('n_initial_exploration_steps', 5000), ('reparameterize', True), ('lr', 0.0003), ('target_update_interval', 1), ('store_extra_policy_info', False), ('action_prior', 'uniform')])), ('domain', 'HalfCheetah'), ('task', 'v2'), ('exp_name', 'halfcheetah_d3rlpy')]), 'replay_pool_params': {'type': 'SimpleReplayPool', 'kwargs': {'max_size': 1000000}}, 'sampler_params': {'type': 'SimpleSampler', 'kwargs': {'max_path_length': 1000, 'min_pool_size': 1000, 'batch_size': 256}}, 'run_params': {'seed': 1443, 'checkpoint_at_end': True, 'checkpoint_frequency': 10, 'checkpoint_replay_pool': False}, 'restore': None}",2560.0090777873993,0,44
131.07289123535156,17.174245834350586,4.323740005493164,0.47812387347221375,0.32295095920562744,1.187925934791565,-0.6253919005393982,0.1977342814207077,-3.0297844409942627,2.808250665664673,0.327900230884552,1.328763484954834,0.18756942451000214,0.7462363839149475,-0.26423853397369385,-0.41026442527771,-0.3679205032777786,-0.3710689103603363,0.3146035885810852,0.675993112587854,5.227510481477452,5.7601848603090335,5.767643647683357,8.346606139199677,1000.0,1000,1000,0.0,5392.2646484375,5497.681640625,5248.12890625,68.56735229492188,1.7122365534305573e-06,3.555836156010628e-05,8.853891695849597,0.007060321047902107,20.576095833908767,0.0020831627771258354,0.00514692347496748,14.21298674819991,0,0,-inf,101000,0,5.0,0.11965973675251007,44,1000,45000,45000,False,,45,e70dcb782c5a4d21a122288b7f76519f,2022-05-19_14-19-04,1652966344,43.68799328804016,2603.6970710754395,19432,gpu-e-17,10.43.6.17,"{'environment_params': {'training': {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}}, 'evaluation': {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}}}, 'policy_params': {'type': 'GaussianPolicy', 'kwargs': {'hidden_layer_sizes': (256, 256), 'squash': True}}, 'Q_params': {'type': 'double_feedforward_Q_function', 'kwargs': {'hidden_layer_sizes': (256, 256)}}, 'algorithm_params': OrderedDict([('type', 'MOPO'), ('universe', 'gym'), ('log_dir', './ray_mopo/'), ('kwargs', OrderedDict([('epoch_length', 1000), ('train_every_n_steps', 1), ('n_train_repeat', 1), ('eval_render_mode', None), ('eval_n_episodes', 10), ('eval_deterministic', True), ('discount', 0.99), ('tau', 0.005), ('reward_scale', 1.0), ('model_train_freq', 1000), ('model_retain_epochs', 5), ('rollout_batch_size', 50000.0), ('deterministic', False), ('num_networks', 7), ('num_elites', 5), ('real_ratio', 0.05), ('target_entropy', -3), ('max_model_t', None), ('separate_mean_var', True), ('penalty_learned_var', True), ('pool_load_path', '/home/ajc348/rds/hpc-work/mopo/rollouts/D3RLPY-PEP1.npy'), ('pool_load_max_size', 101000), ('rollout_length', 5), ('penalty_coeff', 1.0), ('n_epochs', 500), ('n_initial_exploration_steps', 5000), ('reparameterize', True), ('lr', 0.0003), ('target_update_interval', 1), ('store_extra_policy_info', False), ('action_prior', 'uniform')])), ('domain', 'HalfCheetah'), ('task', 'v2'), ('exp_name', 'halfcheetah_d3rlpy')]), 'replay_pool_params': {'type': 'SimpleReplayPool', 'kwargs': {'max_size': 1000000}}, 'sampler_params': {'type': 'SimpleSampler', 'kwargs': {'max_path_length': 1000, 'min_pool_size': 1000, 'batch_size': 256}}, 'run_params': {'seed': 1443, 'checkpoint_at_end': True, 'checkpoint_frequency': 10, 'checkpoint_replay_pool': False}, 'restore': None}",2603.6970710754395,0,45
130.64309692382812,19.80953025817871,5.605382442474365,0.48116815090179443,0.31952404975891113,1.1851836442947388,-0.6183622479438782,0.19617778062820435,-2.943295955657959,2.865431070327759,0.331926167011261,1.3007771968841553,0.1807466745376587,0.7420789003372192,-0.274589900970459,-0.3850165700912476,-0.3677462553215027,-0.37108589529991154,0.33038549184799193,0.5623396479045562,5.467618574857511,5.757848231128264,5.793435178323872,8.308139884469004,1000.0,1000,1000,0.0,5390.1015625,5435.845703125,5239.798828125,54.93923568725586,1.6978010535240173e-06,3.666197881102562e-05,8.9123062659055,0.0068414341658353806,20.775144485291094,0.00211633974686265,0.005207913927733898,14.272109863813967,0,0,-inf,101000,0,5.0,0.11965973675251007,45,1000,46000,46000,False,,46,e70dcb782c5a4d21a122288b7f76519f,2022-05-19_14-19-48,1652966388,44.00414204597473,2647.701213121414,19432,gpu-e-17,10.43.6.17,"{'environment_params': {'training': {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}}, 'evaluation': {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}}}, 'policy_params': {'type': 'GaussianPolicy', 'kwargs': {'hidden_layer_sizes': (256, 256), 'squash': True}}, 'Q_params': {'type': 'double_feedforward_Q_function', 'kwargs': {'hidden_layer_sizes': (256, 256)}}, 'algorithm_params': OrderedDict([('type', 'MOPO'), ('universe', 'gym'), ('log_dir', './ray_mopo/'), ('kwargs', OrderedDict([('epoch_length', 1000), ('train_every_n_steps', 1), ('n_train_repeat', 1), ('eval_render_mode', None), ('eval_n_episodes', 10), ('eval_deterministic', True), ('discount', 0.99), ('tau', 0.005), ('reward_scale', 1.0), ('model_train_freq', 1000), ('model_retain_epochs', 5), ('rollout_batch_size', 50000.0), ('deterministic', False), ('num_networks', 7), ('num_elites', 5), ('real_ratio', 0.05), ('target_entropy', -3), ('max_model_t', None), ('separate_mean_var', True), ('penalty_learned_var', True), ('pool_load_path', '/home/ajc348/rds/hpc-work/mopo/rollouts/D3RLPY-PEP1.npy'), ('pool_load_max_size', 101000), ('rollout_length', 5), ('penalty_coeff', 1.0), ('n_epochs', 500), ('n_initial_exploration_steps', 5000), ('reparameterize', True), ('lr', 0.0003), ('target_update_interval', 1), ('store_extra_policy_info', False), ('action_prior', 'uniform')])), ('domain', 'HalfCheetah'), ('task', 'v2'), ('exp_name', 'halfcheetah_d3rlpy')]), 'replay_pool_params': {'type': 'SimpleReplayPool', 'kwargs': {'max_size': 1000000}}, 'sampler_params': {'type': 'SimpleSampler', 'kwargs': {'max_path_length': 1000, 'min_pool_size': 1000, 'batch_size': 256}}, 'run_params': {'seed': 1443, 'checkpoint_at_end': True, 'checkpoint_frequency': 10, 'checkpoint_replay_pool': False}, 'restore': None}",2647.701213121414,0,46
132.95407104492188,21.50658416748047,3.7960357666015625,0.48445066809654236,0.32847508788108826,1.1944489479064941,-0.6286709308624268,0.2051980197429657,-3.03482723236084,3.060129165649414,0.3207007646560669,1.3172624111175537,0.17294752597808838,0.749305248260498,-0.2935651326179504,-0.37314577102661134,-0.36930262875914577,-0.3709199321269989,0.31303482294082646,0.5977172187809654,5.27512766213863,5.694140009660995,5.7149445644751395,8.288780681807363,1000.0,1000,1000,0.0,5324.83740234375,5431.65234375,5253.6904296875,47.312103271484375,1.659151166677475e-06,3.646174445748329e-05,8.872774663381279,0.006939442828297615,20.499405477195978,0.002148932311683893,0.005123610142618418,14.254133185837418,0,0,-inf,101000,0,5.0,0.11965973675251007,46,1000,47000,47000,False,,47,e70dcb782c5a4d21a122288b7f76519f,2022-05-19_14-20-31,1652966431,43.671058893203735,2691.372272014618,19432,gpu-e-17,10.43.6.17,"{'environment_params': {'training': {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}}, 'evaluation': {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}}}, 'policy_params': {'type': 'GaussianPolicy', 'kwargs': {'hidden_layer_sizes': (256, 256), 'squash': True}}, 'Q_params': {'type': 'double_feedforward_Q_function', 'kwargs': {'hidden_layer_sizes': (256, 256)}}, 'algorithm_params': OrderedDict([('type', 'MOPO'), ('universe', 'gym'), ('log_dir', './ray_mopo/'), ('kwargs', OrderedDict([('epoch_length', 1000), ('train_every_n_steps', 1), ('n_train_repeat', 1), ('eval_render_mode', None), ('eval_n_episodes', 10), ('eval_deterministic', True), ('discount', 0.99), ('tau', 0.005), ('reward_scale', 1.0), ('model_train_freq', 1000), ('model_retain_epochs', 5), ('rollout_batch_size', 50000.0), ('deterministic', False), ('num_networks', 7), ('num_elites', 5), ('real_ratio', 0.05), ('target_entropy', -3), ('max_model_t', None), ('separate_mean_var', True), ('penalty_learned_var', True), ('pool_load_path', '/home/ajc348/rds/hpc-work/mopo/rollouts/D3RLPY-PEP1.npy'), ('pool_load_max_size', 101000), ('rollout_length', 5), ('penalty_coeff', 1.0), ('n_epochs', 500), ('n_initial_exploration_steps', 5000), ('reparameterize', True), ('lr', 0.0003), ('target_update_interval', 1), ('store_extra_policy_info', False), ('action_prior', 'uniform')])), ('domain', 'HalfCheetah'), ('task', 'v2'), ('exp_name', 'halfcheetah_d3rlpy')]), 'replay_pool_params': {'type': 'SimpleReplayPool', 'kwargs': {'max_size': 1000000}}, 'sampler_params': {'type': 'SimpleSampler', 'kwargs': {'max_path_length': 1000, 'min_pool_size': 1000, 'batch_size': 256}}, 'run_params': {'seed': 1443, 'checkpoint_at_end': True, 'checkpoint_frequency': 10, 'checkpoint_replay_pool': False}, 'restore': None}",2691.372272014618,0,47
133.54193115234375,19.647600173950195,3.8699302673339844,0.4840761423110962,0.2892235815525055,1.203040361404419,-0.6246502995491028,0.20144805312156677,-3.0943186283111572,2.713771104812622,0.2902509272098541,1.3176628351211548,0.16551537811756134,0.7493439316749573,-0.28743323564529416,-0.410097553730011,-0.372029317792654,-0.37495830059051516,0.3258338820934296,0.7446956938505365,5.00212657123177,5.777953646496147,5.802412456859091,8.236446628779955,1000.0,1000,1000,0.0,5405.9248046875,5455.32421875,5303.39599609375,40.07786560058594,1.6801059246063232e-06,3.586104139685631e-05,8.85241507878527,0.006891249679028988,20.540185655932873,0.0020787096582353115,0.005097700748592615,14.362086093053222,0,0,-inf,101000,0,5.0,0.11965973675251007,47,1000,48000,48000,False,,48,e70dcb782c5a4d21a122288b7f76519f,2022-05-19_14-21-15,1652966475,43.79909920692444,2735.1713712215424,19432,gpu-e-17,10.43.6.17,"{'environment_params': {'training': {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}}, 'evaluation': {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}}}, 'policy_params': {'type': 'GaussianPolicy', 'kwargs': {'hidden_layer_sizes': (256, 256), 'squash': True}}, 'Q_params': {'type': 'double_feedforward_Q_function', 'kwargs': {'hidden_layer_sizes': (256, 256)}}, 'algorithm_params': OrderedDict([('type', 'MOPO'), ('universe', 'gym'), ('log_dir', './ray_mopo/'), ('kwargs', OrderedDict([('epoch_length', 1000), ('train_every_n_steps', 1), ('n_train_repeat', 1), ('eval_render_mode', None), ('eval_n_episodes', 10), ('eval_deterministic', True), ('discount', 0.99), ('tau', 0.005), ('reward_scale', 1.0), ('model_train_freq', 1000), ('model_retain_epochs', 5), ('rollout_batch_size', 50000.0), ('deterministic', False), ('num_networks', 7), ('num_elites', 5), ('real_ratio', 0.05), ('target_entropy', -3), ('max_model_t', None), ('separate_mean_var', True), ('penalty_learned_var', True), ('pool_load_path', '/home/ajc348/rds/hpc-work/mopo/rollouts/D3RLPY-PEP1.npy'), ('pool_load_max_size', 101000), ('rollout_length', 5), ('penalty_coeff', 1.0), ('n_epochs', 500), ('n_initial_exploration_steps', 5000), ('reparameterize', True), ('lr', 0.0003), ('target_update_interval', 1), ('store_extra_policy_info', False), ('action_prior', 'uniform')])), ('domain', 'HalfCheetah'), ('task', 'v2'), ('exp_name', 'halfcheetah_d3rlpy')]), 'replay_pool_params': {'type': 'SimpleReplayPool', 'kwargs': {'max_size': 1000000}}, 'sampler_params': {'type': 'SimpleSampler', 'kwargs': {'max_path_length': 1000, 'min_pool_size': 1000, 'batch_size': 256}}, 'run_params': {'seed': 1443, 'checkpoint_at_end': True, 'checkpoint_frequency': 10, 'checkpoint_replay_pool': False}, 'restore': None}",2735.1713712215424,0,48
137.84075927734375,14.245386123657227,4.7158284187316895,0.480765163898468,0.34603413939476013,1.1884657144546509,-0.6308574676513672,0.20500627160072327,-2.991595506668091,2.9590723514556885,0.34133851528167725,1.3050999641418457,0.1909944862127304,0.7405972480773926,-0.28146366357803343,-0.3710430955886841,-0.3716271391940117,-0.37476912498474124,0.31712923288345335,0.6802669173233895,5.159937174742595,5.720204600918704,5.7306908586030385,8.361719349464588,1000.0,1000,1000,0.0,5348.5771484375,5462.697265625,5174.74609375,83.14068603515625,1.6316771507263184e-06,3.601890057325363e-05,8.924511634279042,0.007091894280165434,20.498772410210222,0.002091263886541128,0.0052238223142921925,14.282721269410104,0,0,-inf,101000,0,5.0,0.11965973675251007,48,1000,49000,49000,False,,49,e70dcb782c5a4d21a122288b7f76519f,2022-05-19_14-21-59,1652966519,43.750718116760254,2778.9220893383026,19432,gpu-e-17,10.43.6.17,"{'environment_params': {'training': {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}}, 'evaluation': {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}}}, 'policy_params': {'type': 'GaussianPolicy', 'kwargs': {'hidden_layer_sizes': (256, 256), 'squash': True}}, 'Q_params': {'type': 'double_feedforward_Q_function', 'kwargs': {'hidden_layer_sizes': (256, 256)}}, 'algorithm_params': OrderedDict([('type', 'MOPO'), ('universe', 'gym'), ('log_dir', './ray_mopo/'), ('kwargs', OrderedDict([('epoch_length', 1000), ('train_every_n_steps', 1), ('n_train_repeat', 1), ('eval_render_mode', None), ('eval_n_episodes', 10), ('eval_deterministic', True), ('discount', 0.99), ('tau', 0.005), ('reward_scale', 1.0), ('model_train_freq', 1000), ('model_retain_epochs', 5), ('rollout_batch_size', 50000.0), ('deterministic', False), ('num_networks', 7), ('num_elites', 5), ('real_ratio', 0.05), ('target_entropy', -3), ('max_model_t', None), ('separate_mean_var', True), ('penalty_learned_var', True), ('pool_load_path', '/home/ajc348/rds/hpc-work/mopo/rollouts/D3RLPY-PEP1.npy'), ('pool_load_max_size', 101000), ('rollout_length', 5), ('penalty_coeff', 1.0), ('n_epochs', 500), ('n_initial_exploration_steps', 5000), ('reparameterize', True), ('lr', 0.0003), ('target_update_interval', 1), ('store_extra_policy_info', False), ('action_prior', 'uniform')])), ('domain', 'HalfCheetah'), ('task', 'v2'), ('exp_name', 'halfcheetah_d3rlpy')]), 'replay_pool_params': {'type': 'SimpleReplayPool', 'kwargs': {'max_size': 1000000}}, 'sampler_params': {'type': 'SimpleSampler', 'kwargs': {'max_path_length': 1000, 'min_pool_size': 1000, 'batch_size': 256}}, 'run_params': {'seed': 1443, 'checkpoint_at_end': True, 'checkpoint_frequency': 10, 'checkpoint_replay_pool': False}, 'restore': None}",2778.9220893383026,0,49
136.28567504882812,21.998008728027344,4.9123125076293945,0.4747479259967804,0.3228188455104828,1.2119427919387817,-0.6358720064163208,0.20976953208446503,-3.452188014984131,2.7357656955718994,0.3363669812679291,1.3313111066818237,0.18161936104297638,0.7544059753417969,-0.27424310445785527,-0.3909413194656372,-0.37149874938130384,-0.3745766055583954,0.32519078373909,0.5672378371012063,5.261316613724034,5.883883764746683,5.910534895358758,8.53198551369071,1000.0,1000,1000,0.0,5512.38525390625,5611.81298828125,5408.0224609375,66.77119445800781,1.7830170691013336e-06,3.5144854336977005e-05,8.827980620320886,0.007079433649778366,20.577058508060873,0.002072816714644432,0.005190084222704172,14.310098103247583,0,0,-inf,101000,0,5.0,0.11965973675251007,49,1000,50000,50000,False,,50,e70dcb782c5a4d21a122288b7f76519f,2022-05-19_14-22-43,1652966563,43.75941038131714,2822.6814997196198,19432,gpu-e-17,10.43.6.17,"{'environment_params': {'training': {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}}, 'evaluation': {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}}}, 'policy_params': {'type': 'GaussianPolicy', 'kwargs': {'hidden_layer_sizes': (256, 256), 'squash': True}}, 'Q_params': {'type': 'double_feedforward_Q_function', 'kwargs': {'hidden_layer_sizes': (256, 256)}}, 'algorithm_params': OrderedDict([('type', 'MOPO'), ('universe', 'gym'), ('log_dir', './ray_mopo/'), ('kwargs', OrderedDict([('epoch_length', 1000), ('train_every_n_steps', 1), ('n_train_repeat', 1), ('eval_render_mode', None), ('eval_n_episodes', 10), ('eval_deterministic', True), ('discount', 0.99), ('tau', 0.005), ('reward_scale', 1.0), ('model_train_freq', 1000), ('model_retain_epochs', 5), ('rollout_batch_size', 50000.0), ('deterministic', False), ('num_networks', 7), ('num_elites', 5), ('real_ratio', 0.05), ('target_entropy', -3), ('max_model_t', None), ('separate_mean_var', True), ('penalty_learned_var', True), ('pool_load_path', '/home/ajc348/rds/hpc-work/mopo/rollouts/D3RLPY-PEP1.npy'), ('pool_load_max_size', 101000), ('rollout_length', 5), ('penalty_coeff', 1.0), ('n_epochs', 500), ('n_initial_exploration_steps', 5000), ('reparameterize', True), ('lr', 0.0003), ('target_update_interval', 1), ('store_extra_policy_info', False), ('action_prior', 'uniform')])), ('domain', 'HalfCheetah'), ('task', 'v2'), ('exp_name', 'halfcheetah_d3rlpy')]), 'replay_pool_params': {'type': 'SimpleReplayPool', 'kwargs': {'max_size': 1000000}}, 'sampler_params': {'type': 'SimpleSampler', 'kwargs': {'max_path_length': 1000, 'min_pool_size': 1000, 'batch_size': 256}}, 'run_params': {'seed': 1443, 'checkpoint_at_end': True, 'checkpoint_frequency': 10, 'checkpoint_replay_pool': False}, 'restore': None}",2822.6814997196198,0,50
140.490478515625,17.478099822998047,3.6889567375183105,0.480318546295166,0.30227723717689514,1.1803544759750366,-0.623764157295227,0.2062671035528183,-3.0135765075683594,2.897864818572998,0.3087947964668274,1.301996111869812,0.16923843324184418,0.7457611560821533,-0.29741376399993896,-0.3693015980720521,-0.36177307461977004,-0.3650869631767274,0.3247754633426666,0.7520431179535209,5.264206181344093,5.6371054962630165,5.634314377045284,8.213663698505865,1000.0,1000,1000,0.0,5275.33251953125,5388.9892578125,5167.283203125,68.94981384277344,1.632142812013626e-06,5.7184137403964996e-05,8.95300413807854,0.0068283528089523315,20.632575056981295,0.0020549879409372807,0.005124547518789768,14.279843385331333,0,0,-inf,101000,0,5.0,0.11965973675251007,50,1000,51000,51000,False,,51,e70dcb782c5a4d21a122288b7f76519f,2022-05-19_14-23-27,1652966607,43.90959644317627,2866.591096162796,19432,gpu-e-17,10.43.6.17,"{'environment_params': {'training': {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}}, 'evaluation': {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}}}, 'policy_params': {'type': 'GaussianPolicy', 'kwargs': {'hidden_layer_sizes': (256, 256), 'squash': True}}, 'Q_params': {'type': 'double_feedforward_Q_function', 'kwargs': {'hidden_layer_sizes': (256, 256)}}, 'algorithm_params': OrderedDict([('type', 'MOPO'), ('universe', 'gym'), ('log_dir', './ray_mopo/'), ('kwargs', OrderedDict([('epoch_length', 1000), ('train_every_n_steps', 1), ('n_train_repeat', 1), ('eval_render_mode', None), ('eval_n_episodes', 10), ('eval_deterministic', True), ('discount', 0.99), ('tau', 0.005), ('reward_scale', 1.0), ('model_train_freq', 1000), ('model_retain_epochs', 5), ('rollout_batch_size', 50000.0), ('deterministic', False), ('num_networks', 7), ('num_elites', 5), ('real_ratio', 0.05), ('target_entropy', -3), ('max_model_t', None), ('separate_mean_var', True), ('penalty_learned_var', True), ('pool_load_path', '/home/ajc348/rds/hpc-work/mopo/rollouts/D3RLPY-PEP1.npy'), ('pool_load_max_size', 101000), ('rollout_length', 5), ('penalty_coeff', 1.0), ('n_epochs', 500), ('n_initial_exploration_steps', 5000), ('reparameterize', True), ('lr', 0.0003), ('target_update_interval', 1), ('store_extra_policy_info', False), ('action_prior', 'uniform')])), ('domain', 'HalfCheetah'), ('task', 'v2'), ('exp_name', 'halfcheetah_d3rlpy')]), 'replay_pool_params': {'type': 'SimpleReplayPool', 'kwargs': {'max_size': 1000000}}, 'sampler_params': {'type': 'SimpleSampler', 'kwargs': {'max_path_length': 1000, 'min_pool_size': 1000, 'batch_size': 256}}, 'run_params': {'seed': 1443, 'checkpoint_at_end': True, 'checkpoint_frequency': 10, 'checkpoint_replay_pool': False}, 'restore': None}",2866.591096162796,0,51
138.34823608398438,24.09229850769043,5.172478675842285,0.4860611855983734,0.2782614529132843,1.2371103763580322,-0.6139999628067017,0.19314545392990112,-3.369025945663452,2.683173418045044,0.2617745101451874,1.3432916402816772,0.1520359367132187,0.7631127834320068,-0.2880768585205078,-0.4281321835517883,-0.3892799695789814,-0.3919800245761872,0.3255950653553009,0.5912788200742547,5.147705521262992,5.687148641746407,5.67274201686662,8.59478748342134,1000.0,1000,1000,0.0,5297.8681640625,5457.16015625,5186.3544921875,75.05355834960938,1.6330741345882416e-06,3.523193299770355e-05,8.820329500827938,0.00694059394299984,20.585136868990958,0.002080874051898718,0.005165545269846916,14.284280338790268,0,0,-inf,101000,0,5.0,0.11965973675251007,51,1000,52000,52000,False,,52,e70dcb782c5a4d21a122288b7f76519f,2022-05-19_14-24-11,1652966651,43.734729528427124,2910.325825691223,19432,gpu-e-17,10.43.6.17,"{'environment_params': {'training': {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}}, 'evaluation': {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}}}, 'policy_params': {'type': 'GaussianPolicy', 'kwargs': {'hidden_layer_sizes': (256, 256), 'squash': True}}, 'Q_params': {'type': 'double_feedforward_Q_function', 'kwargs': {'hidden_layer_sizes': (256, 256)}}, 'algorithm_params': OrderedDict([('type', 'MOPO'), ('universe', 'gym'), ('log_dir', './ray_mopo/'), ('kwargs', OrderedDict([('epoch_length', 1000), ('train_every_n_steps', 1), ('n_train_repeat', 1), ('eval_render_mode', None), ('eval_n_episodes', 10), ('eval_deterministic', True), ('discount', 0.99), ('tau', 0.005), ('reward_scale', 1.0), ('model_train_freq', 1000), ('model_retain_epochs', 5), ('rollout_batch_size', 50000.0), ('deterministic', False), ('num_networks', 7), ('num_elites', 5), ('real_ratio', 0.05), ('target_entropy', -3), ('max_model_t', None), ('separate_mean_var', True), ('penalty_learned_var', True), ('pool_load_path', '/home/ajc348/rds/hpc-work/mopo/rollouts/D3RLPY-PEP1.npy'), ('pool_load_max_size', 101000), ('rollout_length', 5), ('penalty_coeff', 1.0), ('n_epochs', 500), ('n_initial_exploration_steps', 5000), ('reparameterize', True), ('lr', 0.0003), ('target_update_interval', 1), ('store_extra_policy_info', False), ('action_prior', 'uniform')])), ('domain', 'HalfCheetah'), ('task', 'v2'), ('exp_name', 'halfcheetah_d3rlpy')]), 'replay_pool_params': {'type': 'SimpleReplayPool', 'kwargs': {'max_size': 1000000}}, 'sampler_params': {'type': 'SimpleSampler', 'kwargs': {'max_path_length': 1000, 'min_pool_size': 1000, 'batch_size': 256}}, 'run_params': {'seed': 1443, 'checkpoint_at_end': True, 'checkpoint_frequency': 10, 'checkpoint_replay_pool': False}, 'restore': None}",2910.325825691223,0,52
142.44744873046875,17.217330932617188,4.5105390548706055,0.48279669880867004,0.2952503263950348,1.1914469003677368,-0.6237139105796814,0.21829350292682648,-2.994626760482788,2.9227747917175293,0.31559428572654724,1.3156746625900269,0.17167921364307404,0.7440068125724792,-0.29188898563385013,-0.36464858770370484,-0.35414870977878576,-0.3580292940139771,0.32645233869552615,0.7774583627490903,5.291331707285508,5.693161721212675,5.718096920757901,8.413261843073776,1000.0,1000,1000,0.0,5339.0126953125,5453.5146484375,5226.12451171875,57.80888748168945,1.5818513929843903e-06,3.3357180655002594e-05,8.850329205859452,0.0069854408502578735,20.615574198309332,0.0020632329396903515,0.00513355853036046,14.212013626471162,0,0,-inf,101000,0,5.0,0.11965973675251007,52,1000,53000,53000,False,,53,e70dcb782c5a4d21a122288b7f76519f,2022-05-19_14-24-55,1652966695,43.722824811935425,2954.0486505031586,19432,gpu-e-17,10.43.6.17,"{'environment_params': {'training': {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}}, 'evaluation': {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}}}, 'policy_params': {'type': 'GaussianPolicy', 'kwargs': {'hidden_layer_sizes': (256, 256), 'squash': True}}, 'Q_params': {'type': 'double_feedforward_Q_function', 'kwargs': {'hidden_layer_sizes': (256, 256)}}, 'algorithm_params': OrderedDict([('type', 'MOPO'), ('universe', 'gym'), ('log_dir', './ray_mopo/'), ('kwargs', OrderedDict([('epoch_length', 1000), ('train_every_n_steps', 1), ('n_train_repeat', 1), ('eval_render_mode', None), ('eval_n_episodes', 10), ('eval_deterministic', True), ('discount', 0.99), ('tau', 0.005), ('reward_scale', 1.0), ('model_train_freq', 1000), ('model_retain_epochs', 5), ('rollout_batch_size', 50000.0), ('deterministic', False), ('num_networks', 7), ('num_elites', 5), ('real_ratio', 0.05), ('target_entropy', -3), ('max_model_t', None), ('separate_mean_var', True), ('penalty_learned_var', True), ('pool_load_path', '/home/ajc348/rds/hpc-work/mopo/rollouts/D3RLPY-PEP1.npy'), ('pool_load_max_size', 101000), ('rollout_length', 5), ('penalty_coeff', 1.0), ('n_epochs', 500), ('n_initial_exploration_steps', 5000), ('reparameterize', True), ('lr', 0.0003), ('target_update_interval', 1), ('store_extra_policy_info', False), ('action_prior', 'uniform')])), ('domain', 'HalfCheetah'), ('task', 'v2'), ('exp_name', 'halfcheetah_d3rlpy')]), 'replay_pool_params': {'type': 'SimpleReplayPool', 'kwargs': {'max_size': 1000000}}, 'sampler_params': {'type': 'SimpleSampler', 'kwargs': {'max_path_length': 1000, 'min_pool_size': 1000, 'batch_size': 256}}, 'run_params': {'seed': 1443, 'checkpoint_at_end': True, 'checkpoint_frequency': 10, 'checkpoint_replay_pool': False}, 'restore': None}",2954.0486505031586,0,53
143.38519287109375,18.15891456604004,3.4631733894348145,0.4844614863395691,0.3332846462726593,1.1885039806365967,-0.6200180649757385,0.21908146142959595,-2.923501968383789,2.6725127696990967,0.32442739605903625,1.3115549087524414,0.17838887870311737,0.7410582304000854,-0.2742181420326233,-0.34479919672012327,-0.36506194874167447,-0.3671097230911255,0.31088110208511355,0.7262947312906473,5.5279927997301,5.721013836637127,5.735173045326588,8.25709664981416,1000.0,1000,1000,0.0,5355.95166015625,5442.572265625,5245.78857421875,53.546791076660156,1.7741695046424866e-06,3.367103636264801e-05,8.875603989232332,0.007136139087378979,20.65816903533414,0.002067668829113245,0.005080254748463631,14.31923016300425,0,0,-inf,101000,0,5.0,0.11965973675251007,53,1000,54000,54000,False,,54,e70dcb782c5a4d21a122288b7f76519f,2022-05-19_14-25-38,1652966738,43.89798092842102,2997.9466314315796,19432,gpu-e-17,10.43.6.17,"{'environment_params': {'training': {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}}, 'evaluation': {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}}}, 'policy_params': {'type': 'GaussianPolicy', 'kwargs': {'hidden_layer_sizes': (256, 256), 'squash': True}}, 'Q_params': {'type': 'double_feedforward_Q_function', 'kwargs': {'hidden_layer_sizes': (256, 256)}}, 'algorithm_params': OrderedDict([('type', 'MOPO'), ('universe', 'gym'), ('log_dir', './ray_mopo/'), ('kwargs', OrderedDict([('epoch_length', 1000), ('train_every_n_steps', 1), ('n_train_repeat', 1), ('eval_render_mode', None), ('eval_n_episodes', 10), ('eval_deterministic', True), ('discount', 0.99), ('tau', 0.005), ('reward_scale', 1.0), ('model_train_freq', 1000), ('model_retain_epochs', 5), ('rollout_batch_size', 50000.0), ('deterministic', False), ('num_networks', 7), ('num_elites', 5), ('real_ratio', 0.05), ('target_entropy', -3), ('max_model_t', None), ('separate_mean_var', True), ('penalty_learned_var', True), ('pool_load_path', '/home/ajc348/rds/hpc-work/mopo/rollouts/D3RLPY-PEP1.npy'), ('pool_load_max_size', 101000), ('rollout_length', 5), ('penalty_coeff', 1.0), ('n_epochs', 500), ('n_initial_exploration_steps', 5000), ('reparameterize', True), ('lr', 0.0003), ('target_update_interval', 1), ('store_extra_policy_info', False), ('action_prior', 'uniform')])), ('domain', 'HalfCheetah'), ('task', 'v2'), ('exp_name', 'halfcheetah_d3rlpy')]), 'replay_pool_params': {'type': 'SimpleReplayPool', 'kwargs': {'max_size': 1000000}}, 'sampler_params': {'type': 'SimpleSampler', 'kwargs': {'max_path_length': 1000, 'min_pool_size': 1000, 'batch_size': 256}}, 'run_params': {'seed': 1443, 'checkpoint_at_end': True, 'checkpoint_frequency': 10, 'checkpoint_replay_pool': False}, 'restore': None}",2997.9466314315796,0,54
145.50473022460938,19.40250587463379,3.9995546340942383,0.48128044605255127,0.28451254963874817,1.2035412788391113,-0.6096348762512207,0.2084173709154129,-3.076803684234619,2.7290992736816406,0.30979084968566895,1.340045690536499,0.16759605705738068,0.7533715963363647,-0.3016243314743042,-0.36638648271560675,-0.3740958454632759,-0.37651925325393676,0.30777991414070127,0.739077717293499,5.265792378848914,5.745287337025948,5.759613768373306,8.300093385705432,1000.0,1000,1000,0.0,5371.19140625,5463.6826171875,5267.568359375,56.38740921020508,1.8766149878501892e-06,3.513414412736893e-05,8.91069118725136,0.0069126239977777,20.877332855947316,0.0020732260309159756,0.005139774642884731,14.260976216755807,0,0,-inf,101000,0,5.0,0.11965973675251007,54,1000,55000,55000,False,,55,e70dcb782c5a4d21a122288b7f76519f,2022-05-19_14-26-23,1652966783,44.094183683395386,3042.040815114975,19432,gpu-e-17,10.43.6.17,"{'environment_params': {'training': {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}}, 'evaluation': {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}}}, 'policy_params': {'type': 'GaussianPolicy', 'kwargs': {'hidden_layer_sizes': (256, 256), 'squash': True}}, 'Q_params': {'type': 'double_feedforward_Q_function', 'kwargs': {'hidden_layer_sizes': (256, 256)}}, 'algorithm_params': OrderedDict([('type', 'MOPO'), ('universe', 'gym'), ('log_dir', './ray_mopo/'), ('kwargs', OrderedDict([('epoch_length', 1000), ('train_every_n_steps', 1), ('n_train_repeat', 1), ('eval_render_mode', None), ('eval_n_episodes', 10), ('eval_deterministic', True), ('discount', 0.99), ('tau', 0.005), ('reward_scale', 1.0), ('model_train_freq', 1000), ('model_retain_epochs', 5), ('rollout_batch_size', 50000.0), ('deterministic', False), ('num_networks', 7), ('num_elites', 5), ('real_ratio', 0.05), ('target_entropy', -3), ('max_model_t', None), ('separate_mean_var', True), ('penalty_learned_var', True), ('pool_load_path', '/home/ajc348/rds/hpc-work/mopo/rollouts/D3RLPY-PEP1.npy'), ('pool_load_max_size', 101000), ('rollout_length', 5), ('penalty_coeff', 1.0), ('n_epochs', 500), ('n_initial_exploration_steps', 5000), ('reparameterize', True), ('lr', 0.0003), ('target_update_interval', 1), ('store_extra_policy_info', False), ('action_prior', 'uniform')])), ('domain', 'HalfCheetah'), ('task', 'v2'), ('exp_name', 'halfcheetah_d3rlpy')]), 'replay_pool_params': {'type': 'SimpleReplayPool', 'kwargs': {'max_size': 1000000}}, 'sampler_params': {'type': 'SimpleSampler', 'kwargs': {'max_path_length': 1000, 'min_pool_size': 1000, 'batch_size': 256}}, 'run_params': {'seed': 1443, 'checkpoint_at_end': True, 'checkpoint_frequency': 10, 'checkpoint_replay_pool': False}, 'restore': None}",3042.040815114975,0,55
144.16302490234375,19.90272331237793,2.975767135620117,0.48334091901779175,0.33470726013183594,1.2034729719161987,-0.6400130987167358,0.23465150594711304,-3.3283705711364746,2.8295836448669434,0.3317297101020813,1.3215938806533813,0.18669940531253815,0.7477164268493652,-0.2725287008285523,-0.419452133178711,-0.38214559935808184,-0.38512040972709655,0.3018169856071472,0.6254437952787711,5.507145862842776,5.906971686336795,5.93516995858576,8.57415743776128,1000.0,1000,1000,0.0,5524.826171875,5591.171875,5483.0087890625,38.23491287231445,1.7229467630386353e-06,3.3590011298656464e-05,8.973227424081415,0.006913270801305771,20.637260808609426,0.0021271049045026302,0.005090551450848579,14.36898965202272,0,0,-inf,101000,0,5.0,0.11965973675251007,55,1000,56000,56000,False,,56,e70dcb782c5a4d21a122288b7f76519f,2022-05-19_14-27-07,1652966827,44.02386450767517,3086.06467962265,19432,gpu-e-17,10.43.6.17,"{'environment_params': {'training': {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}}, 'evaluation': {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}}}, 'policy_params': {'type': 'GaussianPolicy', 'kwargs': {'hidden_layer_sizes': (256, 256), 'squash': True}}, 'Q_params': {'type': 'double_feedforward_Q_function', 'kwargs': {'hidden_layer_sizes': (256, 256)}}, 'algorithm_params': OrderedDict([('type', 'MOPO'), ('universe', 'gym'), ('log_dir', './ray_mopo/'), ('kwargs', OrderedDict([('epoch_length', 1000), ('train_every_n_steps', 1), ('n_train_repeat', 1), ('eval_render_mode', None), ('eval_n_episodes', 10), ('eval_deterministic', True), ('discount', 0.99), ('tau', 0.005), ('reward_scale', 1.0), ('model_train_freq', 1000), ('model_retain_epochs', 5), ('rollout_batch_size', 50000.0), ('deterministic', False), ('num_networks', 7), ('num_elites', 5), ('real_ratio', 0.05), ('target_entropy', -3), ('max_model_t', None), ('separate_mean_var', True), ('penalty_learned_var', True), ('pool_load_path', '/home/ajc348/rds/hpc-work/mopo/rollouts/D3RLPY-PEP1.npy'), ('pool_load_max_size', 101000), ('rollout_length', 5), ('penalty_coeff', 1.0), ('n_epochs', 500), ('n_initial_exploration_steps', 5000), ('reparameterize', True), ('lr', 0.0003), ('target_update_interval', 1), ('store_extra_policy_info', False), ('action_prior', 'uniform')])), ('domain', 'HalfCheetah'), ('task', 'v2'), ('exp_name', 'halfcheetah_d3rlpy')]), 'replay_pool_params': {'type': 'SimpleReplayPool', 'kwargs': {'max_size': 1000000}}, 'sampler_params': {'type': 'SimpleSampler', 'kwargs': {'max_path_length': 1000, 'min_pool_size': 1000, 'batch_size': 256}}, 'run_params': {'seed': 1443, 'checkpoint_at_end': True, 'checkpoint_frequency': 10, 'checkpoint_replay_pool': False}, 'restore': None}",3086.06467962265,0,56
147.02191162109375,18.792037963867188,3.6816232204437256,0.47745493054389954,0.2795087695121765,1.1958833932876587,-0.6357631087303162,0.23704856634140015,-3.1343770027160645,2.8501076698303223,0.27516496181488037,1.3096320629119873,0.1577260047197342,0.7506763935089111,-0.28936071872711183,-0.3850163245201111,-0.36130630139827724,-0.368882954120636,0.3400944983959199,0.7810507192672994,5.649846553485986,5.84883863619948,5.869256868405444,8.374887461851838,1000.0,1000,1000,0.0,5487.5322265625,5645.27734375,5381.998046875,80.19799041748047,1.6461126506328583e-06,3.34596261382103e-05,8.916228735819459,0.006985082756727934,20.57420115871355,0.002109568566083908,0.0051035331562161446,14.213360014837235,0,0,-inf,101000,0,5.0,0.11965973675251007,56,1000,57000,57000,False,,57,e70dcb782c5a4d21a122288b7f76519f,2022-05-19_14-27-50,1652966870,43.74831247329712,3129.8129920959473,19432,gpu-e-17,10.43.6.17,"{'environment_params': {'training': {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}}, 'evaluation': {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}}}, 'policy_params': {'type': 'GaussianPolicy', 'kwargs': {'hidden_layer_sizes': (256, 256), 'squash': True}}, 'Q_params': {'type': 'double_feedforward_Q_function', 'kwargs': {'hidden_layer_sizes': (256, 256)}}, 'algorithm_params': OrderedDict([('type', 'MOPO'), ('universe', 'gym'), ('log_dir', './ray_mopo/'), ('kwargs', OrderedDict([('epoch_length', 1000), ('train_every_n_steps', 1), ('n_train_repeat', 1), ('eval_render_mode', None), ('eval_n_episodes', 10), ('eval_deterministic', True), ('discount', 0.99), ('tau', 0.005), ('reward_scale', 1.0), ('model_train_freq', 1000), ('model_retain_epochs', 5), ('rollout_batch_size', 50000.0), ('deterministic', False), ('num_networks', 7), ('num_elites', 5), ('real_ratio', 0.05), ('target_entropy', -3), ('max_model_t', None), ('separate_mean_var', True), ('penalty_learned_var', True), ('pool_load_path', '/home/ajc348/rds/hpc-work/mopo/rollouts/D3RLPY-PEP1.npy'), ('pool_load_max_size', 101000), ('rollout_length', 5), ('penalty_coeff', 1.0), ('n_epochs', 500), ('n_initial_exploration_steps', 5000), ('reparameterize', True), ('lr', 0.0003), ('target_update_interval', 1), ('store_extra_policy_info', False), ('action_prior', 'uniform')])), ('domain', 'HalfCheetah'), ('task', 'v2'), ('exp_name', 'halfcheetah_d3rlpy')]), 'replay_pool_params': {'type': 'SimpleReplayPool', 'kwargs': {'max_size': 1000000}}, 'sampler_params': {'type': 'SimpleSampler', 'kwargs': {'max_path_length': 1000, 'min_pool_size': 1000, 'batch_size': 256}}, 'run_params': {'seed': 1443, 'checkpoint_at_end': True, 'checkpoint_frequency': 10, 'checkpoint_replay_pool': False}, 'restore': None}",3129.8129920959473,0,57
146.30386352539062,21.76531982421875,3.5060577392578125,0.4828713834285736,0.2708716094493866,1.186632513999939,-0.6210737824440002,0.2184857875108719,-2.9207935333251953,2.9589076042175293,0.2706172466278076,1.3103432655334473,0.14626598358154297,0.7469378709793091,-0.2762048220634461,-0.3720660543441773,-0.3585823260176182,-0.36328511595726015,0.3219112884998322,0.8099010289240024,5.463025139940669,5.898801768727348,5.9342983758693,8.388540786910117,1000.0,1000,1000,0.0,5540.21923828125,5614.7734375,5460.150390625,55.33378982543945,1.6521662473678589e-06,3.701215609908104e-05,8.840958431828767,0.007144489791244268,20.619158077053726,0.0021063671447336674,0.005223589017987251,14.28461827058345,0,0,-inf,101000,0,5.0,0.11965973675251007,57,1000,58000,58000,False,,58,e70dcb782c5a4d21a122288b7f76519f,2022-05-19_14-28-34,1652966914,43.789833545684814,3173.602825641632,19432,gpu-e-17,10.43.6.17,"{'environment_params': {'training': {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}}, 'evaluation': {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}}}, 'policy_params': {'type': 'GaussianPolicy', 'kwargs': {'hidden_layer_sizes': (256, 256), 'squash': True}}, 'Q_params': {'type': 'double_feedforward_Q_function', 'kwargs': {'hidden_layer_sizes': (256, 256)}}, 'algorithm_params': OrderedDict([('type', 'MOPO'), ('universe', 'gym'), ('log_dir', './ray_mopo/'), ('kwargs', OrderedDict([('epoch_length', 1000), ('train_every_n_steps', 1), ('n_train_repeat', 1), ('eval_render_mode', None), ('eval_n_episodes', 10), ('eval_deterministic', True), ('discount', 0.99), ('tau', 0.005), ('reward_scale', 1.0), ('model_train_freq', 1000), ('model_retain_epochs', 5), ('rollout_batch_size', 50000.0), ('deterministic', False), ('num_networks', 7), ('num_elites', 5), ('real_ratio', 0.05), ('target_entropy', -3), ('max_model_t', None), ('separate_mean_var', True), ('penalty_learned_var', True), ('pool_load_path', '/home/ajc348/rds/hpc-work/mopo/rollouts/D3RLPY-PEP1.npy'), ('pool_load_max_size', 101000), ('rollout_length', 5), ('penalty_coeff', 1.0), ('n_epochs', 500), ('n_initial_exploration_steps', 5000), ('reparameterize', True), ('lr', 0.0003), ('target_update_interval', 1), ('store_extra_policy_info', False), ('action_prior', 'uniform')])), ('domain', 'HalfCheetah'), ('task', 'v2'), ('exp_name', 'halfcheetah_d3rlpy')]), 'replay_pool_params': {'type': 'SimpleReplayPool', 'kwargs': {'max_size': 1000000}}, 'sampler_params': {'type': 'SimpleSampler', 'kwargs': {'max_path_length': 1000, 'min_pool_size': 1000, 'batch_size': 256}}, 'run_params': {'seed': 1443, 'checkpoint_at_end': True, 'checkpoint_frequency': 10, 'checkpoint_replay_pool': False}, 'restore': None}",3173.602825641632,0,58
148.55972290039062,19.084745407104492,3.548980712890625,0.4797874093055725,0.30572813749313354,1.1901837587356567,-0.6249764561653137,0.22294047474861145,-2.9946141242980957,2.960469961166382,0.31726184487342834,1.3237757682800293,0.17438368499279022,0.7479478716850281,-0.2863039445877075,-0.35476989030838013,-0.3773464348721504,-0.38072674036026005,0.33478123545646665,0.684720032008471,6.011360711337829,5.879789809555788,5.87875471645432,8.63860571897688,1000.0,1000,1000,0.0,5502.44384765625,5564.66796875,5402.33544921875,51.277320861816406,1.7187558114528656e-06,3.656884655356407e-05,8.878532554022968,0.007608496118336916,20.6254312437959,0.0020982539281249046,0.005102626513689756,14.21424916246906,0,0,-inf,101000,0,5.0,0.11965973675251007,58,1000,59000,59000,False,,59,e70dcb782c5a4d21a122288b7f76519f,2022-05-19_14-29-18,1652966958,43.76551365852356,3217.3683393001556,19432,gpu-e-17,10.43.6.17,"{'environment_params': {'training': {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}}, 'evaluation': {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}}}, 'policy_params': {'type': 'GaussianPolicy', 'kwargs': {'hidden_layer_sizes': (256, 256), 'squash': True}}, 'Q_params': {'type': 'double_feedforward_Q_function', 'kwargs': {'hidden_layer_sizes': (256, 256)}}, 'algorithm_params': OrderedDict([('type', 'MOPO'), ('universe', 'gym'), ('log_dir', './ray_mopo/'), ('kwargs', OrderedDict([('epoch_length', 1000), ('train_every_n_steps', 1), ('n_train_repeat', 1), ('eval_render_mode', None), ('eval_n_episodes', 10), ('eval_deterministic', True), ('discount', 0.99), ('tau', 0.005), ('reward_scale', 1.0), ('model_train_freq', 1000), ('model_retain_epochs', 5), ('rollout_batch_size', 50000.0), ('deterministic', False), ('num_networks', 7), ('num_elites', 5), ('real_ratio', 0.05), ('target_entropy', -3), ('max_model_t', None), ('separate_mean_var', True), ('penalty_learned_var', True), ('pool_load_path', '/home/ajc348/rds/hpc-work/mopo/rollouts/D3RLPY-PEP1.npy'), ('pool_load_max_size', 101000), ('rollout_length', 5), ('penalty_coeff', 1.0), ('n_epochs', 500), ('n_initial_exploration_steps', 5000), ('reparameterize', True), ('lr', 0.0003), ('target_update_interval', 1), ('store_extra_policy_info', False), ('action_prior', 'uniform')])), ('domain', 'HalfCheetah'), ('task', 'v2'), ('exp_name', 'halfcheetah_d3rlpy')]), 'replay_pool_params': {'type': 'SimpleReplayPool', 'kwargs': {'max_size': 1000000}}, 'sampler_params': {'type': 'SimpleSampler', 'kwargs': {'max_path_length': 1000, 'min_pool_size': 1000, 'batch_size': 256}}, 'run_params': {'seed': 1443, 'checkpoint_at_end': True, 'checkpoint_frequency': 10, 'checkpoint_replay_pool': False}, 'restore': None}",3217.3683393001556,0,59
151.5182342529297,18.507003784179688,3.20632266998291,0.482145220041275,0.33432626724243164,1.2123709917068481,-0.627718985080719,0.20356763899326324,-3.028426170349121,2.827571392059326,0.3038663864135742,1.332568645477295,0.1746961921453476,0.746107280254364,-0.2956794023513794,-0.3695102334022522,-0.3841244271934033,-0.38663379549980165,0.32901471614837646,0.7033339961059791,6.027926857644275,6.013587430530132,6.026957967085733,8.579100338583569,1000.0,1000,1000,0.0,5629.462890625,5700.04296875,5540.2666015625,42.01980972290039,1.9418075680732727e-06,4.064198583364487e-05,8.830681875348091,0.007020961027592421,20.607654265128076,0.002077250275760889,0.005130309611558914,14.34176313271746,0,0,-inf,101000,0,5.0,0.11965973675251007,59,1000,60000,60000,False,,60,e70dcb782c5a4d21a122288b7f76519f,2022-05-19_14-30-02,1652967002,43.826473236083984,3261.1948125362396,19432,gpu-e-17,10.43.6.17,"{'environment_params': {'training': {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}}, 'evaluation': {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}}}, 'policy_params': {'type': 'GaussianPolicy', 'kwargs': {'hidden_layer_sizes': (256, 256), 'squash': True}}, 'Q_params': {'type': 'double_feedforward_Q_function', 'kwargs': {'hidden_layer_sizes': (256, 256)}}, 'algorithm_params': OrderedDict([('type', 'MOPO'), ('universe', 'gym'), ('log_dir', './ray_mopo/'), ('kwargs', OrderedDict([('epoch_length', 1000), ('train_every_n_steps', 1), ('n_train_repeat', 1), ('eval_render_mode', None), ('eval_n_episodes', 10), ('eval_deterministic', True), ('discount', 0.99), ('tau', 0.005), ('reward_scale', 1.0), ('model_train_freq', 1000), ('model_retain_epochs', 5), ('rollout_batch_size', 50000.0), ('deterministic', False), ('num_networks', 7), ('num_elites', 5), ('real_ratio', 0.05), ('target_entropy', -3), ('max_model_t', None), ('separate_mean_var', True), ('penalty_learned_var', True), ('pool_load_path', '/home/ajc348/rds/hpc-work/mopo/rollouts/D3RLPY-PEP1.npy'), ('pool_load_max_size', 101000), ('rollout_length', 5), ('penalty_coeff', 1.0), ('n_epochs', 500), ('n_initial_exploration_steps', 5000), ('reparameterize', True), ('lr', 0.0003), ('target_update_interval', 1), ('store_extra_policy_info', False), ('action_prior', 'uniform')])), ('domain', 'HalfCheetah'), ('task', 'v2'), ('exp_name', 'halfcheetah_d3rlpy')]), 'replay_pool_params': {'type': 'SimpleReplayPool', 'kwargs': {'max_size': 1000000}}, 'sampler_params': {'type': 'SimpleSampler', 'kwargs': {'max_path_length': 1000, 'min_pool_size': 1000, 'batch_size': 256}}, 'run_params': {'seed': 1443, 'checkpoint_at_end': True, 'checkpoint_frequency': 10, 'checkpoint_replay_pool': False}, 'restore': None}",3261.1948125362396,0,60
