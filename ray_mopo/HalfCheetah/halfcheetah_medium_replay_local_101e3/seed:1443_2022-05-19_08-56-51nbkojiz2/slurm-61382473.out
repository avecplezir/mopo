Can't load '/usr/local/software/slurm/slurm-20.11.9-rhel8/lib64/perl5/auto/Slurm/Slurm.so' for module Slurm: libperl.so.5.26: cannot open shared object file: No such file or directory at /usr/lib64/perl5/DynaLoader.pm line 190, <DATA> line 602.
 at /usr/local/software/slurm/current-rhel8/bin/generate_pbs_nodefile line 18.
Compilation failed in require at /usr/local/software/slurm/current-rhel8/bin/generate_pbs_nodefile line 18, <DATA> line 602.
BEGIN failed--compilation aborted at /usr/local/software/slurm/current-rhel8/bin/generate_pbs_nodefile line 18, <DATA> line 602.
WARNING: Logging before flag parsing goes to stderr.
W0519 08:56:48.434600 47583951635328 lazy_loader.py:50] 
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

Warning: Flow failed to import. Set the environment variable D4RL_SUPPRESS_IMPORT_ERROR=1 to suppress this message.
No module named 'flow'
Warning: CARLA failed to import. Set the environment variable D4RL_SUPPRESS_IMPORT_ERROR=1 to suppress this message.
No module named 'carla'
2022-05-19 08:56:50,836	INFO node.py:498 -- Process STDOUT and STDERR is being redirected to /tmp/ray/session_2022-05-19_08-56-50_836761_10152/logs.
2022-05-19 08:56:50,945	INFO services.py:409 -- Waiting for redis server at 127.0.0.1:33164 to respond...
2022-05-19 08:56:51,057	INFO services.py:409 -- Waiting for redis server at 127.0.0.1:13726 to respond...
2022-05-19 08:56:51,058	INFO services.py:806 -- Starting Redis shard with 10.0 GB max memory.
2022-05-19 08:56:51,078	INFO node.py:512 -- Process STDOUT and STDERR is being redirected to /tmp/ray/session_2022-05-19_08-56-50_836761_10152/logs.
2022-05-19 08:56:51,079	WARNING services.py:1294 -- Warning: Capping object memory store to 20.0GB. To increase this further, specify `object_store_memory` when calling ray.init() or ray start.
2022-05-19 08:56:51,079	INFO services.py:1442 -- Starting the Plasma object store with 20.0 GB memory using /dev/shm.
2022-05-19 08:56:51,186	INFO tune.py:65 -- Did not find checkpoint file in ./ray_mopo/HalfCheetah/halfcheetah_medium_replay_local_101e3.
2022-05-19 08:56:51,186	INFO tune.py:232 -- Starting a new experiment.
W0519 08:56:51.282468 47583951635328 deprecation_wrapper.py:119] From /rds/user/ajc348/hpc-work/mopo/.env/lib/python3.6/site-packages/ray/tune/logger.py:131: The name tf.VERSION is deprecated. Please use tf.version.VERSION instead.

W0519 08:56:51.282832 47583951635328 deprecation_wrapper.py:119] From /rds/user/ajc348/hpc-work/mopo/.env/lib/python3.6/site-packages/ray/tune/logger.py:136: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.

2022-05-19 08:56:51,316	WARNING util.py:64 -- The `start_trial` operation took 0.11219263076782227 seconds to complete, which may be a performance bottleneck.
W0519 09:05:01.196125 47583951635328 deprecation_wrapper.py:119] From /rds/user/ajc348/hpc-work/mopo/.env/lib/python3.6/site-packages/ray/tune/logger.py:114: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.

2022-05-19 09:12:04,757	WARNING util.py:64 -- The `save_to_disk` operation took 0.7840919494628906 seconds to complete, which may be a performance bottleneck.
2022-05-19 09:12:04,760	WARNING util.py:64 -- The `process_trial` operation took 0.7961845397949219 seconds to complete, which may be a performance bottleneck.
2022-05-19 09:19:53,988	WARNING util.py:64 -- The `save_to_disk` operation took 0.5521790981292725 seconds to complete, which may be a performance bottleneck.
2022-05-19 09:19:53,991	WARNING util.py:64 -- The `process_trial` operation took 0.5638270378112793 seconds to complete, which may be a performance bottleneck.
2022-05-19 09:27:37,395	WARNING util.py:64 -- The `save_to_disk` operation took 0.5261571407318115 seconds to complete, which may be a performance bottleneck.
2022-05-19 09:27:37,399	WARNING util.py:64 -- The `process_trial` operation took 0.5392045974731445 seconds to complete, which may be a performance bottleneck.
2022-05-19 09:35:19,457	WARNING util.py:64 -- The `save_to_disk` operation took 0.5106792449951172 seconds to complete, which may be a performance bottleneck.
2022-05-19 09:35:19,460	WARNING util.py:64 -- The `process_trial` operation took 0.5230941772460938 seconds to complete, which may be a performance bottleneck.
2022-05-19 09:43:00,555	WARNING util.py:64 -- The `save_to_disk` operation took 0.511756420135498 seconds to complete, which may be a performance bottleneck.
2022-05-19 09:43:00,558	WARNING util.py:64 -- The `process_trial` operation took 0.5240118503570557 seconds to complete, which may be a performance bottleneck.
2022-05-19 09:50:42,854	WARNING util.py:64 -- The `save_to_disk` operation took 0.5527992248535156 seconds to complete, which may be a performance bottleneck.
2022-05-19 09:50:42,857	WARNING util.py:64 -- The `process_trial` operation took 0.5641982555389404 seconds to complete, which may be a performance bottleneck.
slurmstepd: error: *** JOB 61382473 ON gpu-e-17 CANCELLED AT 2022-05-19T09:56:44 DUE TO TIME LIMIT ***
