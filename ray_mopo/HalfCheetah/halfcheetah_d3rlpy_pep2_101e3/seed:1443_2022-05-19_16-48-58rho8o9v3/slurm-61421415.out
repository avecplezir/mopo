Can't load '/usr/local/software/slurm/slurm-20.11.9-rhel8/lib64/perl5/auto/Slurm/Slurm.so' for module Slurm: libperl.so.5.26: cannot open shared object file: No such file or directory at /usr/lib64/perl5/DynaLoader.pm line 190, <DATA> line 602.
 at /usr/local/software/slurm/current-rhel8/bin/generate_pbs_nodefile line 18.
Compilation failed in require at /usr/local/software/slurm/current-rhel8/bin/generate_pbs_nodefile line 18, <DATA> line 602.
BEGIN failed--compilation aborted at /usr/local/software/slurm/current-rhel8/bin/generate_pbs_nodefile line 18, <DATA> line 602.
WARNING: Logging before flag parsing goes to stderr.
W0519 16:48:48.903042 47382283404160 lazy_loader.py:50] 
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

Warning: Flow failed to import. Set the environment variable D4RL_SUPPRESS_IMPORT_ERROR=1 to suppress this message.
No module named 'flow'
Warning: CARLA failed to import. Set the environment variable D4RL_SUPPRESS_IMPORT_ERROR=1 to suppress this message.
No module named 'carla'
2022-05-19 16:48:56,377	INFO node.py:498 -- Process STDOUT and STDERR is being redirected to /tmp/ray/session_2022-05-19_16-48-56_377149_29523/logs.
2022-05-19 16:48:56,502	INFO services.py:409 -- Waiting for redis server at 127.0.0.1:23553 to respond...
2022-05-19 16:48:57,504	INFO services.py:414 -- Failed to connect to the redis server, retrying.
2022-05-19 16:48:57,504	INFO services.py:409 -- Waiting for redis server at 127.0.0.1:23553 to respond...
2022-05-19 16:48:57,616	INFO services.py:409 -- Waiting for redis server at 127.0.0.1:35089 to respond...
2022-05-19 16:48:57,617	INFO services.py:806 -- Starting Redis shard with 10.0 GB max memory.
2022-05-19 16:48:57,654	INFO node.py:512 -- Process STDOUT and STDERR is being redirected to /tmp/ray/session_2022-05-19_16-48-56_377149_29523/logs.
2022-05-19 16:48:57,655	WARNING services.py:1294 -- Warning: Capping object memory store to 20.0GB. To increase this further, specify `object_store_memory` when calling ray.init() or ray start.
2022-05-19 16:48:57,655	INFO services.py:1442 -- Starting the Plasma object store with 20.0 GB memory using /dev/shm.
WARNING: Logging before InitGoogleLogging() is written to STDERR
E0519 16:48:57.740554 29523 io.cc:168] Connection to IPC socket failed for pathname /tmp/ray/session_2022-05-19_16-48-56_377149_29523/sockets/plasma_store, retrying 300 more times
2022-05-19 16:48:58,291	INFO tune.py:65 -- Did not find checkpoint file in ./ray_mopo/HalfCheetah/halfcheetah_d3rlpy_pep2_101e3.
2022-05-19 16:48:58,291	INFO tune.py:232 -- Starting a new experiment.
W0519 16:48:58.335235 47382283404160 deprecation_wrapper.py:119] From /rds/user/ajc348/hpc-work/mopo/.env/lib/python3.6/site-packages/ray/tune/logger.py:131: The name tf.VERSION is deprecated. Please use tf.version.VERSION instead.

W0519 16:48:58.335596 47382283404160 deprecation_wrapper.py:119] From /rds/user/ajc348/hpc-work/mopo/.env/lib/python3.6/site-packages/ray/tune/logger.py:136: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.

2022-05-19 16:48:58,400	WARNING util.py:64 -- The `start_trial` operation took 0.10103321075439453 seconds to complete, which may be a performance bottleneck.
W0519 16:57:39.995191 47382283404160 deprecation_wrapper.py:119] From /rds/user/ajc348/hpc-work/mopo/.env/lib/python3.6/site-packages/ray/tune/logger.py:114: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.

2022-05-19 17:04:21,488	WARNING util.py:64 -- The `save_to_disk` operation took 1.1255314350128174 seconds to complete, which may be a performance bottleneck.
2022-05-19 17:04:21,491	WARNING util.py:64 -- The `process_trial` operation took 1.136925458908081 seconds to complete, which may be a performance bottleneck.
2022-05-19 17:11:43,482	WARNING util.py:64 -- The `save_to_disk` operation took 0.45871639251708984 seconds to complete, which may be a performance bottleneck.
2022-05-19 17:11:43,485	WARNING util.py:64 -- The `process_trial` operation took 0.46995115280151367 seconds to complete, which may be a performance bottleneck.
2022-05-19 17:19:04,722	WARNING util.py:64 -- The `save_to_disk` operation took 0.46601080894470215 seconds to complete, which may be a performance bottleneck.
2022-05-19 17:19:04,724	WARNING util.py:64 -- The `process_trial` operation took 0.47737693786621094 seconds to complete, which may be a performance bottleneck.
2022-05-19 17:26:25,280	WARNING util.py:64 -- The `save_to_disk` operation took 0.46753764152526855 seconds to complete, which may be a performance bottleneck.
2022-05-19 17:26:25,283	WARNING util.py:64 -- The `process_trial` operation took 0.4792187213897705 seconds to complete, which may be a performance bottleneck.
2022-05-19 17:33:45,237	WARNING util.py:64 -- The `save_to_disk` operation took 0.46915125846862793 seconds to complete, which may be a performance bottleneck.
2022-05-19 17:33:45,239	WARNING util.py:64 -- The `process_trial` operation took 0.48017024993896484 seconds to complete, which may be a performance bottleneck.
2022-05-19 17:41:06,414	WARNING util.py:64 -- The `save_to_disk` operation took 0.47667598724365234 seconds to complete, which may be a performance bottleneck.
2022-05-19 17:41:06,418	WARNING util.py:64 -- The `process_trial` operation took 0.48864150047302246 seconds to complete, which may be a performance bottleneck.
2022-05-19 17:44:47,411	WARNING util.py:64 -- The `experiment_checkpoint` operation took 0.11576461791992188 seconds to complete, which may be a performance bottleneck.
slurmstepd: error: *** JOB 61421415 ON gpu-e-15 CANCELLED AT 2022-05-19T17:47:38 DUE TO TIME LIMIT ***
